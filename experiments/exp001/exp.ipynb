{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from src.dataloader_ import *\n",
    "from src.network_ import *\n",
    "from src.utils import *\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train_series_dir = \"../../inputs/series_train.parquet/\"\n",
    "test_series_dir = \"../../inputs/series_test.parquet/\"\n",
    "\n",
    "data_dic_path = \"../../inputs/data_dictionary.csv\"\n",
    "sample_submission_path = \"../../inputs/sample_submission.csv\"\n",
    "train_path = \"../../inputs/train.csv\"\n",
    "test_path = \"../../inputs/test.csv\"\n",
    "\n",
    "train = pd.read_csv(train_path)\n",
    "test = pd.read_csv(test_path)\n",
    "sample_submission = pd.read_csv(sample_submission_path)\n",
    "data_dic = pd.read_csv(data_dic_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Basic_Demos-Enroll_Season</th>\n",
       "      <th>Basic_Demos-Age</th>\n",
       "      <th>Basic_Demos-Sex</th>\n",
       "      <th>CGAS-Season</th>\n",
       "      <th>CGAS-CGAS_Score</th>\n",
       "      <th>Physical-Season</th>\n",
       "      <th>Physical-BMI</th>\n",
       "      <th>Physical-Height</th>\n",
       "      <th>Physical-Weight</th>\n",
       "      <th>...</th>\n",
       "      <th>PCIAT-PCIAT_18</th>\n",
       "      <th>PCIAT-PCIAT_19</th>\n",
       "      <th>PCIAT-PCIAT_20</th>\n",
       "      <th>PCIAT-PCIAT_Total</th>\n",
       "      <th>SDS-Season</th>\n",
       "      <th>SDS-SDS_Total_Raw</th>\n",
       "      <th>SDS-SDS_Total_T</th>\n",
       "      <th>PreInt_EduHx-Season</th>\n",
       "      <th>PreInt_EduHx-computerinternet_hoursday</th>\n",
       "      <th>sii</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00008ff9</td>\n",
       "      <td>Fall</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>16.877316</td>\n",
       "      <td>46.0</td>\n",
       "      <td>50.8</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fall</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fd460</td>\n",
       "      <td>Summer</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fall</td>\n",
       "      <td>14.035590</td>\n",
       "      <td>48.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>46.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Summer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00105258</td>\n",
       "      <td>Summer</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Fall</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>16.648696</td>\n",
       "      <td>56.5</td>\n",
       "      <td>75.6</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>38.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00115b9f</td>\n",
       "      <td>Winter</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Summer</td>\n",
       "      <td>18.292347</td>\n",
       "      <td>56.0</td>\n",
       "      <td>81.6</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Summer</td>\n",
       "      <td>31.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0016bb22</td>\n",
       "      <td>Spring</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>Summer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id Basic_Demos-Enroll_Season  Basic_Demos-Age  Basic_Demos-Sex  \\\n",
       "0  00008ff9                      Fall                5                0   \n",
       "1  000fd460                    Summer                9                0   \n",
       "2  00105258                    Summer               10                1   \n",
       "3  00115b9f                    Winter                9                0   \n",
       "4  0016bb22                    Spring               18                1   \n",
       "\n",
       "  CGAS-Season  CGAS-CGAS_Score Physical-Season  Physical-BMI  Physical-Height  \\\n",
       "0      Winter             51.0            Fall     16.877316             46.0   \n",
       "1         NaN              NaN            Fall     14.035590             48.0   \n",
       "2        Fall             71.0            Fall     16.648696             56.5   \n",
       "3        Fall             71.0          Summer     18.292347             56.0   \n",
       "4      Summer              NaN             NaN           NaN              NaN   \n",
       "\n",
       "   Physical-Weight  ...  PCIAT-PCIAT_18  PCIAT-PCIAT_19  PCIAT-PCIAT_20  \\\n",
       "0             50.8  ...             4.0             2.0             4.0   \n",
       "1             46.0  ...             0.0             0.0             0.0   \n",
       "2             75.6  ...             2.0             1.0             1.0   \n",
       "3             81.6  ...             3.0             4.0             1.0   \n",
       "4              NaN  ...             NaN             NaN             NaN   \n",
       "\n",
       "   PCIAT-PCIAT_Total SDS-Season  SDS-SDS_Total_Raw  SDS-SDS_Total_T  \\\n",
       "0               55.0        NaN                NaN              NaN   \n",
       "1                0.0       Fall               46.0             64.0   \n",
       "2               28.0       Fall               38.0             54.0   \n",
       "3               44.0     Summer               31.0             45.0   \n",
       "4                NaN        NaN                NaN              NaN   \n",
       "\n",
       "   PreInt_EduHx-Season PreInt_EduHx-computerinternet_hoursday  sii  \n",
       "0                 Fall                                    3.0  2.0  \n",
       "1               Summer                                    0.0  0.0  \n",
       "2               Summer                                    2.0  0.0  \n",
       "3               Winter                                    0.0  1.0  \n",
       "4                  NaN                                    NaN  NaN  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatsuya/.pyenv/versions/3.9.16/envs/kaggle/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# onehotEncoderの作成\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "categorical_columns = [\n",
    "    \"Basic_Demos-Enroll_Season\",\n",
    "    \"CGAS-Season\",\n",
    "    \"Physical-Season\",\n",
    "    \"PAQ_C-Season\",\n",
    "    \"FGC-Season\",\n",
    "    \"Fitness_Endurance-Season\",\n",
    "    \"PAQ_A-Season\",\n",
    "    \"BIA-Season\",\n",
    "    \"SDS-Season\",\n",
    "    \"PreInt_EduHx-Season\",\n",
    "]\n",
    "\n",
    "double_columns = [\n",
    "    \"FGC-FGC_SRR_Zone\",\n",
    "    \"BIA-BIA_SMM\",\n",
    "    \"Physical-Waist_Circumference\",\n",
    "    \"BIA-BIA_FFMI\",\n",
    "    \"FGC-FGC_CU\",\n",
    "    \"PreInt_EduHx-computerinternet_hoursday\",\n",
    "    \"BIA-BIA_ECW\",\n",
    "    \"FGC-FGC_CU_Zone\",\n",
    "    \"FGC-FGC_SRL_Zone\",\n",
    "    \"BIA-BIA_DEE\",\n",
    "    \"Physical-Weight\",\n",
    "    \"Fitness_Endurance-Time_Mins\",\n",
    "    \"FGC-FGC_SRR\",\n",
    "    \"SDS-SDS_Total_T\",\n",
    "    \"FGC-FGC_PU\",\n",
    "    \"BIA-BIA_FFM\",\n",
    "    \"FGC-FGC_TL_Zone\",\n",
    "    \"Physical-BMI\",\n",
    "    \"Physical-Systolic_BP\",\n",
    "    \"Physical-HeartRate\",\n",
    "    \"BIA-BIA_ICW\",\n",
    "    \"Physical-Height\",\n",
    "    \"FGC-FGC_SRL\",\n",
    "    \"BIA-BIA_BMC\",\n",
    "    \"Fitness_Endurance-Time_Sec\",\n",
    "    \"BIA-BIA_Frame_num\",\n",
    "    \"Basic_Demos-Age\",\n",
    "    \"FGC-FGC_GSND_Zone\",\n",
    "    \"Basic_Demos-Sex\",\n",
    "    \"FGC-FGC_GSND\",\n",
    "    \"BIA-BIA_LST\",\n",
    "    \"FGC-FGC_TL\",\n",
    "    \"BIA-BIA_BMI\",\n",
    "    \"BIA-BIA_FMI\",\n",
    "    \"PAQ_C-PAQ_C_Total\",\n",
    "    \"BIA-BIA_Activity_Level_num\",\n",
    "    \"FGC-FGC_GSD\",\n",
    "    \"BIA-BIA_BMR\",\n",
    "    \"BIA-BIA_Fat\",\n",
    "    \"SDS-SDS_Total_Raw\",\n",
    "    \"CGAS-CGAS_Score\",\n",
    "    \"FGC-FGC_PU_Zone\",\n",
    "    \"BIA-BIA_LDM\",\n",
    "    \"Fitness_Endurance-Max_Stage\",\n",
    "    \"PAQ_A-PAQ_A_Total\",\n",
    "    \"BIA-BIA_TBW\",\n",
    "    \"FGC-FGC_GSD_Zone\",\n",
    "    \"Physical-Diastolic_BP\",\n",
    "]\n",
    "\n",
    "###################### categorical columns ######################\n",
    "# trainのtargetをonehot化\n",
    "onehot_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "onehot_encoder.fit(train[categorical_columns])\n",
    "\n",
    "with open(\"./assets/onehot_encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(onehot_encoder, f)\n",
    "\n",
    "categorical_feature = onehot_encoder.transform(train[categorical_columns])\n",
    "\n",
    "###################### double columns ######################\n",
    "# trainのtargetを標準化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train[double_columns])\n",
    "scaler.transform(train[double_columns])\n",
    "\n",
    "with open(\"./assets/scaler.pkl\", \"wb\") as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "double_feature = scaler.transform(train[double_columns])\n",
    "# double_feature = train[double_columns].values\n",
    "\n",
    "# 欠損値の補完\n",
    "double_feature = np.nan_to_num(double_feature)\n",
    "\n",
    "###################### inputの作成 ######################\n",
    "\n",
    "X = np.concatenate([categorical_feature, double_feature], axis=1)\n",
    "y = train[\"sii\"].fillna(-1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoEncoderの学習\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "model = TableAutoEncoder(num_items=X.shape[1], embedding_dim=32)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_dataset = TableAutoEncoderDataset(X)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.2092577964067459\n",
      "epoch: 1, loss: 0.21601088345050812\n",
      "epoch: 2, loss: 0.18041060864925385\n",
      "epoch: 3, loss: 0.13794930279254913\n",
      "epoch: 4, loss: 0.11821821331977844\n",
      "epoch: 5, loss: 0.11648336052894592\n",
      "epoch: 6, loss: 0.1272527575492859\n",
      "epoch: 7, loss: 0.09799154102802277\n",
      "epoch: 8, loss: 0.1133531704545021\n",
      "epoch: 9, loss: 0.09383285790681839\n",
      "epoch: 10, loss: 0.09178228676319122\n",
      "epoch: 11, loss: 0.1045646145939827\n",
      "epoch: 12, loss: 0.09052885323762894\n",
      "epoch: 13, loss: 0.10242121666669846\n",
      "epoch: 14, loss: 0.09037310630083084\n",
      "epoch: 15, loss: 0.08754543215036392\n",
      "epoch: 16, loss: 0.0799224004149437\n",
      "epoch: 17, loss: 0.0736144408583641\n",
      "epoch: 18, loss: 0.07157250493764877\n",
      "epoch: 19, loss: 0.08299994468688965\n",
      "epoch: 20, loss: 0.07940196245908737\n",
      "epoch: 21, loss: 0.07140784710645676\n",
      "epoch: 22, loss: 0.08187949657440186\n",
      "epoch: 23, loss: 0.0886145681142807\n",
      "epoch: 24, loss: 0.07061388343572617\n",
      "epoch: 25, loss: 0.0779246836900711\n",
      "epoch: 26, loss: 0.07802388817071915\n",
      "epoch: 27, loss: 0.1866711527109146\n",
      "epoch: 28, loss: 0.07668935507535934\n",
      "epoch: 29, loss: 0.08764351904392242\n",
      "epoch: 30, loss: 0.07236693054437637\n",
      "epoch: 31, loss: 0.0770050659775734\n",
      "epoch: 32, loss: 0.0648055151104927\n",
      "epoch: 33, loss: 0.06963539123535156\n",
      "epoch: 34, loss: 0.06307650357484818\n",
      "epoch: 35, loss: 0.06733345985412598\n",
      "epoch: 36, loss: 0.06549623608589172\n",
      "epoch: 37, loss: 0.06668983399868011\n",
      "epoch: 38, loss: 0.059276778250932693\n",
      "epoch: 39, loss: 0.07132004201412201\n",
      "epoch: 40, loss: 0.060215674340724945\n",
      "epoch: 41, loss: 0.07454422861337662\n",
      "epoch: 42, loss: 0.07093652337789536\n",
      "epoch: 43, loss: 0.060553740710020065\n",
      "epoch: 44, loss: 0.06300549954175949\n",
      "epoch: 45, loss: 0.21513482928276062\n",
      "epoch: 46, loss: 0.06934058666229248\n",
      "epoch: 47, loss: 0.05951324850320816\n",
      "epoch: 48, loss: 0.06858751177787781\n",
      "epoch: 49, loss: 0.0801025778055191\n",
      "epoch: 50, loss: 0.060366012156009674\n",
      "epoch: 51, loss: 0.063941091299057\n",
      "epoch: 52, loss: 0.06873134523630142\n",
      "epoch: 53, loss: 0.06122706085443497\n",
      "epoch: 54, loss: 0.060248080641031265\n",
      "epoch: 55, loss: 0.06569690257310867\n",
      "epoch: 56, loss: 0.06871182471513748\n",
      "epoch: 57, loss: 0.05657418072223663\n",
      "epoch: 58, loss: 0.0629802793264389\n",
      "epoch: 59, loss: 0.06083177402615547\n",
      "epoch: 60, loss: 0.05666961893439293\n",
      "epoch: 61, loss: 0.05696478486061096\n",
      "epoch: 62, loss: 0.06590632349252701\n",
      "epoch: 63, loss: 0.0614018440246582\n",
      "epoch: 64, loss: 0.05411287397146225\n",
      "epoch: 65, loss: 0.06039672717452049\n",
      "epoch: 66, loss: 0.05617240071296692\n",
      "epoch: 67, loss: 0.06320009380578995\n",
      "epoch: 68, loss: 0.05671342462301254\n",
      "epoch: 69, loss: 0.17917324602603912\n",
      "epoch: 70, loss: 0.0713159367442131\n",
      "epoch: 71, loss: 0.06292764097452164\n",
      "epoch: 72, loss: 0.05755024775862694\n",
      "epoch: 73, loss: 0.06400629132986069\n",
      "epoch: 74, loss: 0.05988875404000282\n",
      "epoch: 75, loss: 0.05941547825932503\n",
      "epoch: 76, loss: 0.054531294852495193\n",
      "epoch: 77, loss: 0.0587533675134182\n",
      "epoch: 78, loss: 0.054103102535009384\n",
      "epoch: 79, loss: 0.06295816600322723\n",
      "epoch: 80, loss: 0.059381768107414246\n",
      "epoch: 81, loss: 0.062415044754743576\n",
      "epoch: 82, loss: 0.05872058495879173\n",
      "epoch: 83, loss: 0.0540783666074276\n",
      "epoch: 84, loss: 0.06509493291378021\n",
      "epoch: 85, loss: 0.053872834891080856\n",
      "epoch: 86, loss: 0.06059615686535835\n",
      "epoch: 87, loss: 0.06209958717226982\n",
      "epoch: 88, loss: 0.055339470505714417\n",
      "epoch: 89, loss: 0.06235801428556442\n",
      "epoch: 90, loss: 0.05592016875743866\n",
      "epoch: 91, loss: 0.05848177149891853\n",
      "epoch: 92, loss: 0.05799857899546623\n",
      "epoch: 93, loss: 0.05586259067058563\n",
      "epoch: 94, loss: 0.05587274581193924\n",
      "epoch: 95, loss: 0.06419035792350769\n",
      "epoch: 96, loss: 0.05350425839424133\n",
      "epoch: 97, loss: 0.061251867562532425\n",
      "epoch: 98, loss: 0.05741698667407036\n",
      "epoch: 99, loss: 0.06296870112419128\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        data = data.float()\n",
    "        output = model(data, mode=\"encode-decode\")\n",
    "        loss = criterion(output, data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"epoch: {epoch}, loss: {loss.item()}\")\n",
    "\n",
    "\n",
    "def create_embedding(model, feature):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        feature = torch.tensor(feature).float()\n",
    "        embedding = model(feature, mode=\"encode\")\n",
    "    # numpyに変換\n",
    "    embedding = embedding.numpy()\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "\n",
    "\n",
    "def quadratic_weighted_kappa(y_true, y_pred):\n",
    "    return cohen_kappa_score(y_true, y_pred, weights=\"quadratic\")\n",
    "\n",
    "\n",
    "def threshold_Rounder(oof_non_rounded, thresholds):\n",
    "    return np.where(\n",
    "        oof_non_rounded < thresholds[0],\n",
    "        0,\n",
    "        np.where(\n",
    "            oof_non_rounded < thresholds[1],\n",
    "            1,\n",
    "            np.where(oof_non_rounded < thresholds[2], 2, 3),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "def evaluate_predictions(thresholds, y_true, oof_non_rounded):\n",
    "    rounded_p = threshold_Rounder(oof_non_rounded, thresholds)\n",
    "    return -quadratic_weighted_kappa(y_true, rounded_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=4.735462555910575, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.735462555910575\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7602261703576205, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7602261703576205\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.735028557007343e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.735028557007343e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7987976913702801, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7987976913702801\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's l2: 0.557193\n",
      "[20]\tvalid_0's l2: 0.523545\n",
      "[30]\tvalid_0's l2: 0.503658\n",
      "[40]\tvalid_0's l2: 0.493892\n",
      "[50]\tvalid_0's l2: 0.485666\n",
      "[60]\tvalid_0's l2: 0.480531\n",
      "[70]\tvalid_0's l2: 0.47754\n",
      "[80]\tvalid_0's l2: 0.476645\n",
      "Early stopping, best iteration is:\n",
      "[75]\tvalid_0's l2: 0.476453\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(bagging_fraction=0.7602261703576205, bagging_freq=2,\n",
       "              feature_fraction=0.7987976913702801, lambda_l1=4.735462555910575,\n",
       "              lambda_l2=4.735028557007343e-06,\n",
       "              learning_rate=0.03884249148676395, max_depth=12,\n",
       "              min_data_in_leaf=14, n_estimators=200, num_leaves=413,\n",
       "              verbose=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(bagging_fraction=0.7602261703576205, bagging_freq=2,\n",
       "              feature_fraction=0.7987976913702801, lambda_l1=4.735462555910575,\n",
       "              lambda_l2=4.735028557007343e-06,\n",
       "              learning_rate=0.03884249148676395, max_depth=12,\n",
       "              min_data_in_leaf=14, n_estimators=200, num_leaves=413,\n",
       "              verbose=-1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMRegressor(bagging_fraction=0.7602261703576205, bagging_freq=2,\n",
       "              feature_fraction=0.7987976913702801, lambda_l1=4.735462555910575,\n",
       "              lambda_l2=4.735028557007343e-06,\n",
       "              learning_rate=0.03884249148676395, max_depth=12,\n",
       "              min_data_in_leaf=14, n_estimators=200, num_leaves=413,\n",
       "              verbose=-1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_features = create_embedding(model, X)\n",
    "# embedding_features = X\n",
    "embedding_features.shape\n",
    "\n",
    "# yとconcat\n",
    "dataset = np.concatenate([embedding_features, y.reshape(-1, 1)], axis=1)\n",
    "# dataset[:, -1]が-1以外のものだけを取得\n",
    "\n",
    "dataset = dataset[dataset[:, -1] != -1]\n",
    "\n",
    "X, y = dataset[:, :-1], dataset[:, -1]\n",
    "\n",
    "# train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# モデルの学習\n",
    "import lightgbm as lgb\n",
    "\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_valid = lgb.Dataset(X_valid, y_valid)\n",
    "\n",
    "Params7 = {\n",
    "    \"learning_rate\": 0.03884249148676395,\n",
    "    \"max_depth\": 12,\n",
    "    \"num_leaves\": 413,\n",
    "    \"min_data_in_leaf\": 14,\n",
    "    \"feature_fraction\": 0.7987976913702801,\n",
    "    \"bagging_fraction\": 0.7602261703576205,\n",
    "    \"bagging_freq\": 2,\n",
    "    \"lambda_l1\": 4.735462555910575,\n",
    "    \"lambda_l2\": 4.735028557007343e-06,\n",
    "}\n",
    "\n",
    "\n",
    "# lgb_model = lgb.LGBMClassifier(**Params7)\n",
    "lgb_model = lgb.LGBMRegressor(**Params7, verbose=-1, n_estimators=200)\n",
    "\n",
    "lgb_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    eval_set=[(X_valid, y_valid)],\n",
    "    early_stopping_rounds=10,\n",
    "    verbose=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_score: 0.6224396472882263, valid_score: 0.34173037364526726\n"
     ]
    }
   ],
   "source": [
    "train_score = quadratic_weighted_kappa(\n",
    "    y_train, lgb_model.predict(X_train).round(0).astype(int)\n",
    ")\n",
    "valid_score = quadratic_weighted_kappa(\n",
    "    y_valid, lgb_model.predict(X_valid).round(0).astype(int)\n",
    ")\n",
    "\n",
    "print(f\"train_score: {train_score}, valid_score: {valid_score}\")\n",
    "\n",
    "# original-feature : train_score: 0.5867837902742401, valid_score: 0.36020517531771556\n",
    "# embedding-feature : train_score: 0.7461982276735281, valid_score: 0.32452859350850083"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Column_0</td>\n",
       "      <td>115.554890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Column_1</td>\n",
       "      <td>88.176112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Column_2</td>\n",
       "      <td>101.483800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Column_3</td>\n",
       "      <td>79.177335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Column_4</td>\n",
       "      <td>121.659096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Column_5</td>\n",
       "      <td>153.446836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Column_6</td>\n",
       "      <td>97.578291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Column_7</td>\n",
       "      <td>192.837301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Column_8</td>\n",
       "      <td>176.062377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Column_9</td>\n",
       "      <td>166.507213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Column_10</td>\n",
       "      <td>129.795320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Column_11</td>\n",
       "      <td>434.202231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Column_12</td>\n",
       "      <td>180.398694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Column_13</td>\n",
       "      <td>442.929736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Column_14</td>\n",
       "      <td>144.009092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Column_15</td>\n",
       "      <td>383.155061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Column_16</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Column_17</td>\n",
       "      <td>98.090222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Column_18</td>\n",
       "      <td>190.567577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Column_19</td>\n",
       "      <td>558.430714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Column_20</td>\n",
       "      <td>165.898616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Column_21</td>\n",
       "      <td>585.299260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Column_22</td>\n",
       "      <td>135.680758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Column_23</td>\n",
       "      <td>99.866630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Column_24</td>\n",
       "      <td>163.847824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Column_25</td>\n",
       "      <td>77.739610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Column_26</td>\n",
       "      <td>127.711571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Column_27</td>\n",
       "      <td>232.906693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Column_28</td>\n",
       "      <td>57.655753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Column_29</td>\n",
       "      <td>150.052492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Column_30</td>\n",
       "      <td>138.858900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Column_31</td>\n",
       "      <td>1021.786379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Feature   Importance\n",
       "0    Column_0   115.554890\n",
       "1    Column_1    88.176112\n",
       "2    Column_2   101.483800\n",
       "3    Column_3    79.177335\n",
       "4    Column_4   121.659096\n",
       "5    Column_5   153.446836\n",
       "6    Column_6    97.578291\n",
       "7    Column_7   192.837301\n",
       "8    Column_8   176.062377\n",
       "9    Column_9   166.507213\n",
       "10  Column_10   129.795320\n",
       "11  Column_11   434.202231\n",
       "12  Column_12   180.398694\n",
       "13  Column_13   442.929736\n",
       "14  Column_14   144.009092\n",
       "15  Column_15   383.155061\n",
       "16  Column_16     0.000000\n",
       "17  Column_17    98.090222\n",
       "18  Column_18   190.567577\n",
       "19  Column_19   558.430714\n",
       "20  Column_20   165.898616\n",
       "21  Column_21   585.299260\n",
       "22  Column_22   135.680758\n",
       "23  Column_23    99.866630\n",
       "24  Column_24   163.847824\n",
       "25  Column_25    77.739610\n",
       "26  Column_26   127.711571\n",
       "27  Column_27   232.906693\n",
       "28  Column_28    57.655753\n",
       "29  Column_29   150.052492\n",
       "30  Column_30   138.858900\n",
       "31  Column_31  1021.786379"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Feature\": lgb_model.booster_.feature_name(),\n",
    "        \"Importance\": lgb_model.booster_.feature_importance(importance_type=\"gain\"),\n",
    "    }\n",
    ")\n",
    "\n",
    "feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\tFeature\\tImportance\\n0\\tColumn_0\\t0.000000\\n1\\tColumn_1\\t380.774703\\n2\\tColumn_2\\t93.412222\\n3\\tColumn_3\\t59.987604\\n4\\tColumn_4\\t1022.835918\\n...\\t...\\t...\\n59\\tColumn_59\\t244.442884\\n60\\tColumn_60\\t62.446166\\n61\\tColumn_61\\t76.901441\\n62\\tColumn_62\\t0.000000\\n63\\tColumn_63\\t88.173296\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\tFeature\tImportance\n",
    "0\tColumn_0\t0.000000\n",
    "1\tColumn_1\t380.774703\n",
    "2\tColumn_2\t93.412222\n",
    "3\tColumn_3\t59.987604\n",
    "4\tColumn_4\t1022.835918\n",
    "...\t...\t...\n",
    "59\tColumn_59\t244.442884\n",
    "60\tColumn_60\t62.446166\n",
    "61\tColumn_61\t76.901441\n",
    "62\tColumn_62\t0.000000\n",
    "63\tColumn_63\t88.173296\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
