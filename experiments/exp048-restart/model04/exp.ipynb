{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from src.dataloader_ import *\n",
    "from src.network_ import *\n",
    "from src.utils import *\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "\n",
    "train_series_dir = \"../../../inputs/series_train.parquet/\"\n",
    "test_series_dir = \"../../../inputs/series_test.parquet/\"\n",
    "\n",
    "data_dic_path = \"../../../inputs/data_dictionary.csv\"\n",
    "sample_submission_path = \"../../../inputs/sample_submission.csv\"\n",
    "train_path = \"../../../inputs/train.csv\"\n",
    "test_path = \"../../../inputs/test.csv\"\n",
    "\n",
    "train = pd.read_csv(train_path)\n",
    "test = pd.read_csv(test_path)\n",
    "sample_submission = pd.read_csv(sample_submission_path)\n",
    "data_dic = pd.read_csv(data_dic_path)\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def seed_torch(seed=1029):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "nb_name = os.path.basename(os.getcwd())  # notebook name\n",
    "seed_torch(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Basic_Demos-Enroll_Season</th>\n",
       "      <th>Basic_Demos-Age</th>\n",
       "      <th>Basic_Demos-Sex</th>\n",
       "      <th>CGAS-Season</th>\n",
       "      <th>CGAS-CGAS_Score</th>\n",
       "      <th>Physical-Season</th>\n",
       "      <th>Physical-BMI</th>\n",
       "      <th>Physical-Height</th>\n",
       "      <th>Physical-Weight</th>\n",
       "      <th>...</th>\n",
       "      <th>PCIAT-PCIAT_18</th>\n",
       "      <th>PCIAT-PCIAT_19</th>\n",
       "      <th>PCIAT-PCIAT_20</th>\n",
       "      <th>PCIAT-PCIAT_Total</th>\n",
       "      <th>SDS-Season</th>\n",
       "      <th>SDS-SDS_Total_Raw</th>\n",
       "      <th>SDS-SDS_Total_T</th>\n",
       "      <th>PreInt_EduHx-Season</th>\n",
       "      <th>PreInt_EduHx-computerinternet_hoursday</th>\n",
       "      <th>sii</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00008ff9</td>\n",
       "      <td>Fall</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>16.877316</td>\n",
       "      <td>46.0</td>\n",
       "      <td>50.8</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fall</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fd460</td>\n",
       "      <td>Summer</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fall</td>\n",
       "      <td>14.035590</td>\n",
       "      <td>48.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>46.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Summer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00105258</td>\n",
       "      <td>Summer</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Fall</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>16.648696</td>\n",
       "      <td>56.5</td>\n",
       "      <td>75.6</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>38.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00115b9f</td>\n",
       "      <td>Winter</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Summer</td>\n",
       "      <td>18.292347</td>\n",
       "      <td>56.0</td>\n",
       "      <td>81.6</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Summer</td>\n",
       "      <td>31.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0016bb22</td>\n",
       "      <td>Spring</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>Summer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3955</th>\n",
       "      <td>ff8a2de4</td>\n",
       "      <td>Fall</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>Spring</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>16.362460</td>\n",
       "      <td>59.5</td>\n",
       "      <td>82.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>35.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3956</th>\n",
       "      <td>ffa9794a</td>\n",
       "      <td>Winter</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spring</td>\n",
       "      <td>18.764678</td>\n",
       "      <td>53.5</td>\n",
       "      <td>76.4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Winter</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3957</th>\n",
       "      <td>ffcd4dbd</td>\n",
       "      <td>Fall</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>Spring</td>\n",
       "      <td>68.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>21.441500</td>\n",
       "      <td>60.0</td>\n",
       "      <td>109.8</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>56.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3958</th>\n",
       "      <td>ffed1dd5</td>\n",
       "      <td>Spring</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>Spring</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>12.235895</td>\n",
       "      <td>70.7</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Spring</td>\n",
       "      <td>33.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>Spring</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3959</th>\n",
       "      <td>ffef538e</td>\n",
       "      <td>Spring</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Winter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spring</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3960 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id Basic_Demos-Enroll_Season  Basic_Demos-Age  Basic_Demos-Sex  \\\n",
       "0     00008ff9                      Fall                5                0   \n",
       "1     000fd460                    Summer                9                0   \n",
       "2     00105258                    Summer               10                1   \n",
       "3     00115b9f                    Winter                9                0   \n",
       "4     0016bb22                    Spring               18                1   \n",
       "...        ...                       ...              ...              ...   \n",
       "3955  ff8a2de4                      Fall               13                0   \n",
       "3956  ffa9794a                    Winter               10                0   \n",
       "3957  ffcd4dbd                      Fall               11                0   \n",
       "3958  ffed1dd5                    Spring               13                0   \n",
       "3959  ffef538e                    Spring               11                0   \n",
       "\n",
       "     CGAS-Season  CGAS-CGAS_Score Physical-Season  Physical-BMI  \\\n",
       "0         Winter             51.0            Fall     16.877316   \n",
       "1            NaN              NaN            Fall     14.035590   \n",
       "2           Fall             71.0            Fall     16.648696   \n",
       "3           Fall             71.0          Summer     18.292347   \n",
       "4         Summer              NaN             NaN           NaN   \n",
       "...          ...              ...             ...           ...   \n",
       "3955      Spring             60.0            Fall     16.362460   \n",
       "3956         NaN              NaN          Spring     18.764678   \n",
       "3957      Spring             68.0          Winter     21.441500   \n",
       "3958      Spring             70.0          Winter     12.235895   \n",
       "3959         NaN              NaN          Winter           NaN   \n",
       "\n",
       "      Physical-Height  Physical-Weight  ...  PCIAT-PCIAT_18  PCIAT-PCIAT_19  \\\n",
       "0                46.0             50.8  ...             4.0             2.0   \n",
       "1                48.0             46.0  ...             0.0             0.0   \n",
       "2                56.5             75.6  ...             2.0             1.0   \n",
       "3                56.0             81.6  ...             3.0             4.0   \n",
       "4                 NaN              NaN  ...             NaN             NaN   \n",
       "...               ...              ...  ...             ...             ...   \n",
       "3955             59.5             82.4  ...             1.0             1.0   \n",
       "3956             53.5             76.4  ...             NaN             NaN   \n",
       "3957             60.0            109.8  ...             1.0             0.0   \n",
       "3958             70.7             87.0  ...             1.0             1.0   \n",
       "3959              NaN              NaN  ...             NaN             NaN   \n",
       "\n",
       "      PCIAT-PCIAT_20  PCIAT-PCIAT_Total SDS-Season  SDS-SDS_Total_Raw  \\\n",
       "0                4.0               55.0        NaN                NaN   \n",
       "1                0.0                0.0       Fall               46.0   \n",
       "2                1.0               28.0       Fall               38.0   \n",
       "3                1.0               44.0     Summer               31.0   \n",
       "4                NaN                NaN        NaN                NaN   \n",
       "...              ...                ...        ...                ...   \n",
       "3955             0.0               32.0     Winter               35.0   \n",
       "3956             NaN                NaN        NaN                NaN   \n",
       "3957             1.0               31.0     Winter               56.0   \n",
       "3958             1.0               19.0     Spring               33.0   \n",
       "3959             NaN                NaN        NaN                NaN   \n",
       "\n",
       "      SDS-SDS_Total_T  PreInt_EduHx-Season  \\\n",
       "0                 NaN                 Fall   \n",
       "1                64.0               Summer   \n",
       "2                54.0               Summer   \n",
       "3                45.0               Winter   \n",
       "4                 NaN                  NaN   \n",
       "...               ...                  ...   \n",
       "3955             50.0                 Fall   \n",
       "3956              NaN               Winter   \n",
       "3957             77.0                 Fall   \n",
       "3958             47.0               Spring   \n",
       "3959              NaN               Spring   \n",
       "\n",
       "     PreInt_EduHx-computerinternet_hoursday  sii  \n",
       "0                                       3.0  2.0  \n",
       "1                                       0.0  0.0  \n",
       "2                                       2.0  0.0  \n",
       "3                                       0.0  1.0  \n",
       "4                                       NaN  NaN  \n",
       "...                                     ...  ...  \n",
       "3955                                    1.0  1.0  \n",
       "3956                                    0.0  NaN  \n",
       "3957                                    0.0  1.0  \n",
       "3958                                    1.0  0.0  \n",
       "3959                                    1.0  NaN  \n",
       "\n",
       "[3960 rows x 82 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テーブルデータセット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_features = [\n",
    "    \"BMI_Age\",\n",
    "    \"Internet_Hours_Age\",\n",
    "    \"BMI_Internet_Hours\",\n",
    "    \"BFP_BMI\",\n",
    "    \"FFMI_BFP\",\n",
    "    \"FMI_BFP\",\n",
    "    \"LST_TBW\",\n",
    "    \"BFP_BMR\",\n",
    "    \"BFP_DEE\",\n",
    "    \"BMR_Weight\",\n",
    "    \"DEE_Weight\",\n",
    "    \"SMM_Height\",\n",
    "    \"Muscle_to_Fat\",\n",
    "    \"Hydration_Status\",\n",
    "    \"ICW_TBW\",\n",
    "]\n",
    "\n",
    "\n",
    "def feature_engineering(df):\n",
    "    # season_cols = [col for col in df.columns if \"Season\" in col]\n",
    "    # df = df.drop(season_cols, axis=1)\n",
    "    df[\"BMI_Age\"] = df[\"Physical-BMI\"] * df[\"Basic_Demos-Age\"]\n",
    "    df[\"Internet_Hours_Age\"] = (\n",
    "        df[\"PreInt_EduHx-computerinternet_hoursday\"] * df[\"Basic_Demos-Age\"]\n",
    "    )\n",
    "    df[\"BMI_Internet_Hours\"] = (\n",
    "        df[\"Physical-BMI\"] * df[\"PreInt_EduHx-computerinternet_hoursday\"]\n",
    "    )\n",
    "    df[\"BFP_BMI\"] = df[\"BIA-BIA_Fat\"] / df[\"BIA-BIA_BMI\"]\n",
    "    df[\"FFMI_BFP\"] = df[\"BIA-BIA_FFMI\"] / df[\"BIA-BIA_Fat\"]\n",
    "    df[\"FMI_BFP\"] = df[\"BIA-BIA_FMI\"] / df[\"BIA-BIA_Fat\"]\n",
    "    df[\"LST_TBW\"] = df[\"BIA-BIA_LST\"] / df[\"BIA-BIA_TBW\"]\n",
    "    df[\"BFP_BMR\"] = df[\"BIA-BIA_Fat\"] * df[\"BIA-BIA_BMR\"]\n",
    "    df[\"BFP_DEE\"] = df[\"BIA-BIA_Fat\"] * df[\"BIA-BIA_DEE\"]\n",
    "    df[\"BMR_Weight\"] = df[\"BIA-BIA_BMR\"] / df[\"Physical-Weight\"]\n",
    "    df[\"DEE_Weight\"] = df[\"BIA-BIA_DEE\"] / df[\"Physical-Weight\"]\n",
    "    df[\"SMM_Height\"] = df[\"BIA-BIA_SMM\"] / df[\"Physical-Height\"]\n",
    "    df[\"Muscle_to_Fat\"] = df[\"BIA-BIA_SMM\"] / df[\"BIA-BIA_FMI\"]\n",
    "    df[\"Hydration_Status\"] = df[\"BIA-BIA_TBW\"] / df[\"Physical-Weight\"]\n",
    "    df[\"ICW_TBW\"] = df[\"BIA-BIA_ICW\"] / df[\"BIA-BIA_TBW\"]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "train = feature_engineering(train)\n",
    "train = train.replace([np.inf, -np.inf], np.nan)\n",
    "for add_ in add_features:\n",
    "    train[add_] = train[add_].fillna(0.0)\n",
    "train = train.dropna(thresh=10, axis=0)\n",
    "\n",
    "test = feature_engineering(test)\n",
    "test = test.replace([np.inf, -np.inf], np.nan)\n",
    "for add_ in add_features:\n",
    "    test[add_] = test[add_].fillna(0.0)\n",
    "test = test.dropna(thresh=10, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create new scaler\n"
     ]
    }
   ],
   "source": [
    "# onehotEncoderの作成\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "double_columns = [\n",
    "    \"FGC-FGC_SRR_Zone\",\n",
    "    \"BIA-BIA_SMM\",\n",
    "    \"Physical-Waist_Circumference\",\n",
    "    \"BIA-BIA_FFMI\",\n",
    "    \"FGC-FGC_CU\",\n",
    "    \"PreInt_EduHx-computerinternet_hoursday\",\n",
    "    \"BIA-BIA_ECW\",\n",
    "    \"FGC-FGC_CU_Zone\",\n",
    "    \"FGC-FGC_SRL_Zone\",\n",
    "    \"BIA-BIA_DEE\",\n",
    "    \"Physical-Weight\",\n",
    "    \"Fitness_Endurance-Time_Mins\",\n",
    "    \"FGC-FGC_SRR\",\n",
    "    \"SDS-SDS_Total_T\",\n",
    "    \"FGC-FGC_PU\",\n",
    "    \"BIA-BIA_FFM\",\n",
    "    \"FGC-FGC_TL_Zone\",\n",
    "    \"Physical-BMI\",\n",
    "    \"Physical-Systolic_BP\",\n",
    "    \"Physical-HeartRate\",\n",
    "    \"BIA-BIA_ICW\",\n",
    "    \"Physical-Height\",\n",
    "    \"FGC-FGC_SRL\",\n",
    "    \"BIA-BIA_BMC\",\n",
    "    \"Fitness_Endurance-Time_Sec\",\n",
    "    \"BIA-BIA_Frame_num\",\n",
    "    \"Basic_Demos-Age\",\n",
    "    \"FGC-FGC_GSND_Zone\",\n",
    "    \"Basic_Demos-Sex\",\n",
    "    \"FGC-FGC_GSND\",\n",
    "    \"BIA-BIA_LST\",\n",
    "    \"FGC-FGC_TL\",\n",
    "    \"BIA-BIA_BMI\",\n",
    "    \"BIA-BIA_FMI\",\n",
    "    \"PAQ_C-PAQ_C_Total\",\n",
    "    \"BIA-BIA_Activity_Level_num\",\n",
    "    \"FGC-FGC_GSD\",\n",
    "    \"BIA-BIA_BMR\",\n",
    "    \"BIA-BIA_Fat\",\n",
    "    \"SDS-SDS_Total_Raw\",\n",
    "    \"CGAS-CGAS_Score\",\n",
    "    \"FGC-FGC_PU_Zone\",\n",
    "    \"BIA-BIA_LDM\",\n",
    "    \"Fitness_Endurance-Max_Stage\",\n",
    "    \"PAQ_A-PAQ_A_Total\",\n",
    "    \"BIA-BIA_TBW\",\n",
    "    \"FGC-FGC_GSD_Zone\",\n",
    "    \"Physical-Diastolic_BP\",\n",
    "]\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def create_dataset_(df, scaler=None, train=True):\n",
    "\n",
    "    if scaler is None:\n",
    "        print(\"create new scaler\")\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(df[double_columns + add_features])\n",
    "        with open(\"./assets/scaler.pkl\", \"wb\") as f:\n",
    "            pickle.dump(scaler, f)\n",
    "\n",
    "    double_feature = scaler.transform(df[double_columns + add_features])\n",
    "    # 欠損値の補完\n",
    "    double_feature = np.nan_to_num(double_feature)\n",
    "\n",
    "    ids = df[\"id\"].values.reshape(-1, 1)\n",
    "    X = double_feature\n",
    "\n",
    "    # DataFrameの作成\n",
    "    ids_df = pd.DataFrame(ids, columns=[\"id\"])\n",
    "    X_df = pd.DataFrame(X, columns=[f\"feature_{i}\" for i in range(X.shape[1])])\n",
    "\n",
    "    if train:\n",
    "        y = df[\"sii\"].fillna(-1).values.reshape(-1, 1)\n",
    "        y_df = pd.DataFrame(y, columns=[\"sii\"])\n",
    "        df = pd.concat([ids_df, X_df, y_df], axis=1)\n",
    "        df = df[df[\"sii\"] != -1].reset_index(drop=True)\n",
    "    else:\n",
    "        df = pd.concat([ids_df, X_df], axis=1)\n",
    "    return df, scaler\n",
    "\n",
    "\n",
    "train, scaler = create_dataset_(train)\n",
    "test = create_dataset_(test, scaler=scaler, train=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_parquet(base_dir, id_):\n",
    "    path = os.path.join(base_dir, f\"id={id_}\", \"part-0.parquet\")\n",
    "    return pd.read_parquet(path)\n",
    "\n",
    "\n",
    "def get_valid_ids(base_dir):\n",
    "    return [f.split(\"=\")[1].split(\".\")[0] for f in os.listdir(base_dir)]\n",
    "\n",
    "\n",
    "# p = read_parquet(base_dir=\"../../inputs/series_train.parquet/\", id_=\"ffcd4dbd\")\n",
    "# p = read_parquet(base_dir=\"../../inputs/series_train.parquet/\", id_=\"10e46254\")\n",
    "# p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "# len(glob(\"../../normalized/*\"))\n",
    "len(glob(\"../../inputs/series_train.parquet/*\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "\n",
    "\n",
    "def quadratic_weighted_kappa(y_true, y_pred):\n",
    "    return cohen_kappa_score(y_true, y_pred, weights=\"quadratic\")\n",
    "\n",
    "\n",
    "def threshold_Rounder(oof_non_rounded, thresholds):\n",
    "    return np.where(\n",
    "        oof_non_rounded < thresholds[0],\n",
    "        0,\n",
    "        np.where(\n",
    "            oof_non_rounded < thresholds[1],\n",
    "            1,\n",
    "            np.where(oof_non_rounded < thresholds[2], 2, 3),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "def evaluate_predictions(thresholds, y_true, oof_non_rounded):\n",
    "    rounded_p = threshold_Rounder(oof_non_rounded, thresholds)\n",
    "    return -quadratic_weighted_kappa(y_true, rounded_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_54</th>\n",
       "      <th>feature_55</th>\n",
       "      <th>feature_56</th>\n",
       "      <th>feature_57</th>\n",
       "      <th>feature_58</th>\n",
       "      <th>feature_59</th>\n",
       "      <th>feature_60</th>\n",
       "      <th>feature_61</th>\n",
       "      <th>feature_62</th>\n",
       "      <th>sii</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00008ff9</td>\n",
       "      <td>-1.277596</td>\n",
       "      <td>-0.176702</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.209436</td>\n",
       "      <td>-0.953788</td>\n",
       "      <td>1.771623</td>\n",
       "      <td>-0.171600</td>\n",
       "      <td>-0.953742</td>\n",
       "      <td>-1.274301</td>\n",
       "      <td>...</td>\n",
       "      <td>0.865342</td>\n",
       "      <td>0.015691</td>\n",
       "      <td>0.015630</td>\n",
       "      <td>0.531031</td>\n",
       "      <td>0.540327</td>\n",
       "      <td>0.113954</td>\n",
       "      <td>0.083339</td>\n",
       "      <td>0.251650</td>\n",
       "      <td>1.296492</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fd460</td>\n",
       "      <td>0.782720</td>\n",
       "      <td>-0.225858</td>\n",
       "      <td>-0.948658</td>\n",
       "      <td>-0.380787</td>\n",
       "      <td>-0.699663</td>\n",
       "      <td>-0.968830</td>\n",
       "      <td>-0.202128</td>\n",
       "      <td>-0.953742</td>\n",
       "      <td>0.784744</td>\n",
       "      <td>...</td>\n",
       "      <td>1.284690</td>\n",
       "      <td>0.015270</td>\n",
       "      <td>0.015181</td>\n",
       "      <td>0.629987</td>\n",
       "      <td>0.643793</td>\n",
       "      <td>0.021863</td>\n",
       "      <td>0.304658</td>\n",
       "      <td>0.209698</td>\n",
       "      <td>1.388511</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00105258</td>\n",
       "      <td>0.782720</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.740376</td>\n",
       "      <td>0.858138</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.048502</td>\n",
       "      <td>0.784744</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999909</td>\n",
       "      <td>0.014948</td>\n",
       "      <td>0.014837</td>\n",
       "      <td>-0.374560</td>\n",
       "      <td>-0.406553</td>\n",
       "      <td>-0.263102</td>\n",
       "      <td>-0.139659</td>\n",
       "      <td>-0.235959</td>\n",
       "      <td>-0.993169</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00115b9f</td>\n",
       "      <td>-1.277596</td>\n",
       "      <td>-0.094130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.165178</td>\n",
       "      <td>0.570959</td>\n",
       "      <td>-0.968830</td>\n",
       "      <td>-0.071440</td>\n",
       "      <td>1.048502</td>\n",
       "      <td>-1.274301</td>\n",
       "      <td>...</td>\n",
       "      <td>1.007592</td>\n",
       "      <td>0.016791</td>\n",
       "      <td>0.016926</td>\n",
       "      <td>0.309486</td>\n",
       "      <td>0.353385</td>\n",
       "      <td>0.156596</td>\n",
       "      <td>0.079541</td>\n",
       "      <td>0.191155</td>\n",
       "      <td>1.031686</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001f3379</td>\n",
       "      <td>0.782720</td>\n",
       "      <td>0.011793</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.286156</td>\n",
       "      <td>0.062710</td>\n",
       "      <td>-0.968830</td>\n",
       "      <td>0.128155</td>\n",
       "      <td>-0.953742</td>\n",
       "      <td>0.784744</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978217</td>\n",
       "      <td>0.022777</td>\n",
       "      <td>0.022666</td>\n",
       "      <td>0.210665</td>\n",
       "      <td>0.167108</td>\n",
       "      <td>0.264681</td>\n",
       "      <td>-0.048092</td>\n",
       "      <td>0.190353</td>\n",
       "      <td>0.604025</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2731</th>\n",
       "      <td>ff6c2bb8</td>\n",
       "      <td>0.782720</td>\n",
       "      <td>-0.168095</td>\n",
       "      <td>-0.409495</td>\n",
       "      <td>-0.281495</td>\n",
       "      <td>-0.953788</td>\n",
       "      <td>0.858138</td>\n",
       "      <td>-0.134052</td>\n",
       "      <td>-0.953742</td>\n",
       "      <td>0.784744</td>\n",
       "      <td>...</td>\n",
       "      <td>1.105075</td>\n",
       "      <td>0.016262</td>\n",
       "      <td>0.016326</td>\n",
       "      <td>0.385473</td>\n",
       "      <td>0.437799</td>\n",
       "      <td>0.079497</td>\n",
       "      <td>0.049569</td>\n",
       "      <td>0.178059</td>\n",
       "      <td>1.151893</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>ff759544</td>\n",
       "      <td>-1.277596</td>\n",
       "      <td>-0.193929</td>\n",
       "      <td>-0.768937</td>\n",
       "      <td>-0.310661</td>\n",
       "      <td>-0.953788</td>\n",
       "      <td>-0.968830</td>\n",
       "      <td>-0.147954</td>\n",
       "      <td>-0.953742</td>\n",
       "      <td>-1.274301</td>\n",
       "      <td>...</td>\n",
       "      <td>1.233005</td>\n",
       "      <td>0.015066</td>\n",
       "      <td>0.014940</td>\n",
       "      <td>0.648422</td>\n",
       "      <td>0.462512</td>\n",
       "      <td>0.068026</td>\n",
       "      <td>1.386235</td>\n",
       "      <td>0.252580</td>\n",
       "      <td>1.051774</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2733</th>\n",
       "      <td>ff8a2de4</td>\n",
       "      <td>0.782720</td>\n",
       "      <td>-0.054867</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.167095</td>\n",
       "      <td>0.401543</td>\n",
       "      <td>-0.055346</td>\n",
       "      <td>-0.018625</td>\n",
       "      <td>-0.953742</td>\n",
       "      <td>0.784744</td>\n",
       "      <td>...</td>\n",
       "      <td>0.965988</td>\n",
       "      <td>0.016158</td>\n",
       "      <td>0.016209</td>\n",
       "      <td>0.348018</td>\n",
       "      <td>0.396190</td>\n",
       "      <td>0.181123</td>\n",
       "      <td>0.312400</td>\n",
       "      <td>0.249864</td>\n",
       "      <td>0.941730</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2734</th>\n",
       "      <td>ffcd4dbd</td>\n",
       "      <td>0.782720</td>\n",
       "      <td>-0.066765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.039070</td>\n",
       "      <td>0.316835</td>\n",
       "      <td>-0.968830</td>\n",
       "      <td>-0.004681</td>\n",
       "      <td>1.048502</td>\n",
       "      <td>0.784744</td>\n",
       "      <td>...</td>\n",
       "      <td>1.053875</td>\n",
       "      <td>0.018636</td>\n",
       "      <td>0.018772</td>\n",
       "      <td>0.188757</td>\n",
       "      <td>0.182448</td>\n",
       "      <td>0.162631</td>\n",
       "      <td>0.011772</td>\n",
       "      <td>0.139885</td>\n",
       "      <td>0.918073</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2735</th>\n",
       "      <td>ffed1dd5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.131436</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.338825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.055346</td>\n",
       "      <td>0.077913</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.990166</td>\n",
       "      <td>0.014225</td>\n",
       "      <td>0.013825</td>\n",
       "      <td>0.427455</td>\n",
       "      <td>0.694085</td>\n",
       "      <td>0.307287</td>\n",
       "      <td>-2.049356</td>\n",
       "      <td>0.355443</td>\n",
       "      <td>0.873188</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2736 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  feature_0  feature_1  feature_2  feature_3  feature_4  \\\n",
       "0     00008ff9  -1.277596  -0.176702   0.000000  -0.209436  -0.953788   \n",
       "1     000fd460   0.782720  -0.225858  -0.948658  -0.380787  -0.699663   \n",
       "2     00105258   0.782720   0.000000   0.000000   0.000000   0.740376   \n",
       "3     00115b9f  -1.277596  -0.094130   0.000000  -0.165178   0.570959   \n",
       "4     001f3379   0.782720   0.011793   0.000000   0.286156   0.062710   \n",
       "...        ...        ...        ...        ...        ...        ...   \n",
       "2731  ff6c2bb8   0.782720  -0.168095  -0.409495  -0.281495  -0.953788   \n",
       "2732  ff759544  -1.277596  -0.193929  -0.768937  -0.310661  -0.953788   \n",
       "2733  ff8a2de4   0.782720  -0.054867   0.000000  -0.167095   0.401543   \n",
       "2734  ffcd4dbd   0.782720  -0.066765   0.000000  -0.039070   0.316835   \n",
       "2735  ffed1dd5   0.000000   0.131436   0.000000  -0.338825   0.000000   \n",
       "\n",
       "      feature_5  feature_6  feature_7  feature_8  ...  feature_54  feature_55  \\\n",
       "0      1.771623  -0.171600  -0.953742  -1.274301  ...    0.865342    0.015691   \n",
       "1     -0.968830  -0.202128  -0.953742   0.784744  ...    1.284690    0.015270   \n",
       "2      0.858138   0.000000   1.048502   0.784744  ...   -0.999909    0.014948   \n",
       "3     -0.968830  -0.071440   1.048502  -1.274301  ...    1.007592    0.016791   \n",
       "4     -0.968830   0.128155  -0.953742   0.784744  ...    0.978217    0.022777   \n",
       "...         ...        ...        ...        ...  ...         ...         ...   \n",
       "2731   0.858138  -0.134052  -0.953742   0.784744  ...    1.105075    0.016262   \n",
       "2732  -0.968830  -0.147954  -0.953742  -1.274301  ...    1.233005    0.015066   \n",
       "2733  -0.055346  -0.018625  -0.953742   0.784744  ...    0.965988    0.016158   \n",
       "2734  -0.968830  -0.004681   1.048502   0.784744  ...    1.053875    0.018636   \n",
       "2735  -0.055346   0.077913   0.000000   0.000000  ...    0.990166    0.014225   \n",
       "\n",
       "      feature_56  feature_57  feature_58  feature_59  feature_60  feature_61  \\\n",
       "0       0.015630    0.531031    0.540327    0.113954    0.083339    0.251650   \n",
       "1       0.015181    0.629987    0.643793    0.021863    0.304658    0.209698   \n",
       "2       0.014837   -0.374560   -0.406553   -0.263102   -0.139659   -0.235959   \n",
       "3       0.016926    0.309486    0.353385    0.156596    0.079541    0.191155   \n",
       "4       0.022666    0.210665    0.167108    0.264681   -0.048092    0.190353   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "2731    0.016326    0.385473    0.437799    0.079497    0.049569    0.178059   \n",
       "2732    0.014940    0.648422    0.462512    0.068026    1.386235    0.252580   \n",
       "2733    0.016209    0.348018    0.396190    0.181123    0.312400    0.249864   \n",
       "2734    0.018772    0.188757    0.182448    0.162631    0.011772    0.139885   \n",
       "2735    0.013825    0.427455    0.694085    0.307287   -2.049356    0.355443   \n",
       "\n",
       "      feature_62  sii  \n",
       "0       1.296492  2.0  \n",
       "1       1.388511  0.0  \n",
       "2      -0.993169  0.0  \n",
       "3       1.031686  1.0  \n",
       "4       0.604025  1.0  \n",
       "...          ...  ...  \n",
       "2731    1.151893  0.0  \n",
       "2732    1.051774  1.0  \n",
       "2733    0.941730  1.0  \n",
       "2734    0.918073  1.0  \n",
       "2735    0.873188  0.0  \n",
       "\n",
       "[2736 rows x 65 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2736"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "use_ids = list(\n",
    "    train[train[\"sii\"] != -1][\"id\"].unique()\n",
    ")  # get_valid_ids(base_dir=\"../../normalized/\")\n",
    "\n",
    "len(use_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "use_ids = np.array(use_ids)\n",
    "for train_index, valid_index in kf.split(use_ids):\n",
    "    train_ids = [use_ids[i] for i in train_index]\n",
    "    valid_ids = [use_ids[i] for i in valid_index]\n",
    "\n",
    "    train_dataset = CMIDataset(\n",
    "        table_df=train,\n",
    "        valid_ids=use_ids,\n",
    "        base_dir=\"../../inputs/series_train.parquet/\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################### fold:0 ###################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2188 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/tatsuya/.pyenv/versions/3.9.16/envs/kaggle/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/tatsuya/.pyenv/versions/3.9.16/envs/kaggle/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/tatsuya/.pyenv/versions/3.9.16/envs/kaggle/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/tatsuya/code/projects/kaggle/ChildMindInstitute2024/experiments/exp048-restart/model04/src/dataloader_.py\", line 58, in __getitem__\n    p = read_parquet(self.base_dir, self.valid_ids[idx])\n  File \"/home/tatsuya/code/projects/kaggle/ChildMindInstitute2024/experiments/exp048-restart/model04/src/dataloader_.py\", line 114, in read_parquet\n    return pd.read_parquet(path)\n  File \"/home/tatsuya/.pyenv/versions/3.9.16/envs/kaggle/lib/python3.9/site-packages/pandas/io/parquet.py\", line 509, in read_parquet\n    return impl.read(\n  File \"/home/tatsuya/.pyenv/versions/3.9.16/envs/kaggle/lib/python3.9/site-packages/pandas/io/parquet.py\", line 220, in read\n    path_or_handle, handles, kwargs[\"filesystem\"] = _get_path_or_handle(\n  File \"/home/tatsuya/.pyenv/versions/3.9.16/envs/kaggle/lib/python3.9/site-packages/pandas/io/parquet.py\", line 110, in _get_path_or_handle\n    handles = get_handle(\n  File \"/home/tatsuya/.pyenv/versions/3.9.16/envs/kaggle/lib/python3.9/site-packages/pandas/io/common.py\", line 868, in get_handle\n    handle = open(handle, ioargs.mode)\nFileNotFoundError: [Errno 2] No such file or directory: '../../../inputs/series_train.parquet/id=81394e0e/part-0.parquet'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 83\u001b[0m\n\u001b[1;32m     80\u001b[0m valid_gt \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     82\u001b[0m tq \u001b[38;5;241m=\u001b[39m tqdm(train_loader)\n\u001b[0;32m---> 83\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m     84\u001b[0m     table_input \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable_input\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     85\u001b[0m     time_input \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_input\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/envs/kaggle/lib/python3.9/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/envs/kaggle/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1346\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1345\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/envs/kaggle/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1372\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1372\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/envs/kaggle/lib/python3.9/site-packages/torch/_utils.py:644\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 644\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/tatsuya/.pyenv/versions/3.9.16/envs/kaggle/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/tatsuya/.pyenv/versions/3.9.16/envs/kaggle/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/tatsuya/.pyenv/versions/3.9.16/envs/kaggle/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/tatsuya/code/projects/kaggle/ChildMindInstitute2024/experiments/exp048-restart/model04/src/dataloader_.py\", line 58, in __getitem__\n    p = read_parquet(self.base_dir, self.valid_ids[idx])\n  File \"/home/tatsuya/code/projects/kaggle/ChildMindInstitute2024/experiments/exp048-restart/model04/src/dataloader_.py\", line 114, in read_parquet\n    return pd.read_parquet(path)\n  File \"/home/tatsuya/.pyenv/versions/3.9.16/envs/kaggle/lib/python3.9/site-packages/pandas/io/parquet.py\", line 509, in read_parquet\n    return impl.read(\n  File \"/home/tatsuya/.pyenv/versions/3.9.16/envs/kaggle/lib/python3.9/site-packages/pandas/io/parquet.py\", line 220, in read\n    path_or_handle, handles, kwargs[\"filesystem\"] = _get_path_or_handle(\n  File \"/home/tatsuya/.pyenv/versions/3.9.16/envs/kaggle/lib/python3.9/site-packages/pandas/io/parquet.py\", line 110, in _get_path_or_handle\n    handles = get_handle(\n  File \"/home/tatsuya/.pyenv/versions/3.9.16/envs/kaggle/lib/python3.9/site-packages/pandas/io/common.py\", line 868, in get_handle\n    handle = open(handle, ioargs.mode)\nFileNotFoundError: [Errno 2] No such file or directory: '../../../inputs/series_train.parquet/id=81394e0e/part-0.parquet'\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "CV = []\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "# use_ids = np.array(use_ids[:30]) # debug\n",
    "use_ids = np.array(use_ids)\n",
    "\n",
    "extract_df = train[train[\"id\"].isin(use_ids)].reset_index(drop=True)\n",
    "\n",
    "test_df = train[[\"id\", \"sii\"]].copy()\n",
    "# test_df[\"pred_sii\"] = 0\n",
    "oof_preds = []\n",
    "\n",
    "for fold in range(5):\n",
    "    print(f\"################### fold:{fold} ###################\")\n",
    "    best_valid_score = -100\n",
    "\n",
    "    with open(f\"../divided-datasets/fold_train_ids_{fold}.pkl\", \"rb\") as f:\n",
    "        fold_train_ids = pickle.load(f)\n",
    "\n",
    "    with open(f\"../divided-datasets/fold_valid_ids_{fold}.pkl\", \"rb\") as f:\n",
    "        fold_valid_ids = pickle.load(f)\n",
    "\n",
    "    train_ids = fold_train_ids  # [:100]\n",
    "    valid_ids = fold_valid_ids  # [:100]\n",
    "\n",
    "    train_fold = train[train[\"id\"].isin(fold_train_ids)].reset_index(drop=True)\n",
    "    valid_fold = train[train[\"id\"].isin(fold_valid_ids)].reset_index(drop=True)\n",
    "\n",
    "    train_ids = train_fold[\"id\"].values\n",
    "    valid_ids = valid_fold[\"id\"].values\n",
    "\n",
    "    mode = \"drop\"\n",
    "\n",
    "    if mode == \"impute\":\n",
    "        numeric_cols = train.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
    "        imputer = KNNImputer(n_neighbors=5)\n",
    "        train_fold[numeric_cols] = imputer.fit_transform(train_fold[numeric_cols])\n",
    "        test[numeric_cols] = imputer.transform(test[numeric_cols])\n",
    "    elif mode == \"drop\":\n",
    "        train_fold = train_fold[train_fold[\"sii\"].notnull()].reset_index(drop=True)\n",
    "\n",
    "    train_dataset = CMIDataset(\n",
    "        table_df=train_fold,\n",
    "        valid_ids=train_ids,\n",
    "        base_dir=\"../../../inputs/series_train.parquet/\",\n",
    "    )\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, num_workers=30\n",
    "    )\n",
    "\n",
    "    vlaid_dataset = CMIDataset(\n",
    "        table_df=valid_fold,\n",
    "        valid_ids=valid_ids,\n",
    "        base_dir=\"../../../inputs/series_train.parquet/\",\n",
    "    )\n",
    "\n",
    "    valid_loader = DataLoader(\n",
    "        vlaid_dataset, batch_size=batch_size, shuffle=False, num_workers=30\n",
    "    )\n",
    "\n",
    "    model = CMIModel(input_size=26, hidden_size=13, num_layers=2).to(\"cuda\")\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    spot_oof_preds = []\n",
    "\n",
    "    for epoch in range(5):\n",
    "        total_train_loss = 0\n",
    "        total_valid_loss = 0\n",
    "\n",
    "        train_pred = []\n",
    "        valid_pred = []\n",
    "        trian_gt = []\n",
    "        valid_gt = []\n",
    "\n",
    "        tq = tqdm(train_loader)\n",
    "        for i, data in enumerate(train_loader):\n",
    "            table_input = data[\"table_input\"].to(\"cuda\")\n",
    "            time_input = data[\"time_input\"].to(\"cuda\")\n",
    "            mask = data[\"mask\"].to(\"cuda\").to(torch.float32)\n",
    "            target_ = data[\"output\"].to(\"cuda\")\n",
    "            optimizer.zero_grad()\n",
    "            output, attention_weight = model(table_input, time_input, active_mask=mask)\n",
    "            loss = criterion(output, target_)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "            train_pred.append(output.detach().cpu().numpy())\n",
    "            trian_gt.append(target_.detach().cpu().numpy())\n",
    "\n",
    "            tq.set_postfix(loss=total_train_loss / (i + 1))\n",
    "            tq.update()\n",
    "        tq.close()\n",
    "\n",
    "        tq = tqdm(valid_loader)\n",
    "        for i, data in enumerate(valid_loader):\n",
    "            table_input = data[\"table_input\"].to(\"cuda\")\n",
    "            time_input = data[\"time_input\"].to(\"cuda\")\n",
    "            mask = data[\"mask\"].to(\"cuda\").to(torch.float32)\n",
    "            target_ = data[\"output\"].to(\"cuda\")\n",
    "            output, attention_weight = model(table_input, time_input, active_mask=mask)\n",
    "            loss = criterion(output, target_)\n",
    "            total_valid_loss += loss.item()\n",
    "\n",
    "            valid_pred.append(output.detach().cpu().numpy())\n",
    "            valid_gt.append(target_.detach().cpu().numpy())\n",
    "\n",
    "            tq.set_postfix(loss=total_valid_loss / (i + 1))\n",
    "            tq.update()\n",
    "        tq.close()\n",
    "\n",
    "        metric_train_pred = np.concatenate(train_pred)\n",
    "        metric_valid_pred = np.concatenate(valid_pred)\n",
    "        metric_train_gt = np.concatenate(trian_gt)\n",
    "        metric_valid_gt = np.concatenate(valid_gt)\n",
    "\n",
    "        train_score = quadratic_weighted_kappa(\n",
    "            metric_train_gt, metric_train_pred.round(0).astype(int)\n",
    "        )\n",
    "\n",
    "        valid_score = quadratic_weighted_kappa(\n",
    "            metric_valid_gt, metric_valid_pred.round(0).astype(int)\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"epoch: {epoch}, loss: {total_train_loss / len(train_loader)}, valid_loss: {total_valid_loss / len(valid_loader)}, train_score: {train_score}, valid_score: {valid_score}\"\n",
    "        )\n",
    "\n",
    "        if valid_score > best_valid_score:\n",
    "            best_valid_score = valid_score\n",
    "            torch.save(model.state_dict(), f\"./assets/model04_{fold}.pth\")\n",
    "\n",
    "            spot_oof_preds = []\n",
    "            for i, id_ in enumerate(valid_ids):\n",
    "                spot_oof_preds.append({\"id\": id_, \"pred_sii\": valid_pred[i][0][0]})\n",
    "\n",
    "    oof_preds.append(spot_oof_preds)\n",
    "    CV.append(best_valid_score)\n",
    "\n",
    "print(f\"CV: {np.mean(CV)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_preds_df = pd.concat([pd.DataFrame(p) for p in oof_preds], axis=0).reset_index(\n",
    "    drop=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_preds_df.to_csv(\"./oof/oof.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../assets/lstm_oof_preds.pkl\", \"wb\") as f:\n",
    "    pickle.dump(oof_preds_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_df = test_df.merge(oof_preds_df, on=\"id\", how=\"inner\")\n",
    "test_pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "KappaOPtimizer = minimize(\n",
    "    evaluate_predictions,\n",
    "    x0=[0.5, 1.5, 2.5],\n",
    "    args=(test_pred_df[\"sii\"], test_pred_df[\"pred_sii\"]),\n",
    "    method=\"Nelder-Mead\",\n",
    ")\n",
    "assert KappaOPtimizer.success, \"Optimization did not converge.\"\n",
    "\n",
    "oof_tuned = threshold_Rounder(test_pred_df[\"pred_sii\"], KappaOPtimizer.x)\n",
    "tKappa = quadratic_weighted_kappa(test_pred_df[\"sii\"], oof_tuned)\n",
    "print(f\"tuned Kappa: {tKappa}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(KappaOPtimizer.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
