{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from src.dataloader_ import *\n",
    "from src.network_ import *\n",
    "from src.utils import *\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "\n",
    "train_series_dir = \"../../inputs/series_train.parquet/\"\n",
    "test_series_dir = \"../../inputs/series_test.parquet/\"\n",
    "\n",
    "data_dic_path = \"../../inputs/data_dictionary.csv\"\n",
    "sample_submission_path = \"../../inputs/sample_submission.csv\"\n",
    "train_path = \"../../inputs/train.csv\"\n",
    "test_path = \"../../inputs/test.csv\"\n",
    "\n",
    "train = pd.read_csv(train_path)\n",
    "test = pd.read_csv(test_path)\n",
    "sample_submission = pd.read_csv(sample_submission_path)\n",
    "data_dic = pd.read_csv(data_dic_path)\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def seed_torch(seed=1029):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "nb_name = os.path.basename(os.getcwd())  # notebook name\n",
    "seed_torch(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 24, 60, 15) (31, 24, 60, 15)\n",
      "(31, 24, 15) (31, 24, 15) (31, 24, 30)\n",
      "(744, 30)\n",
      "torch.Size([1, 744, 30])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def read_parquet(base_dir, id_):\n",
    "    path = os.path.join(base_dir, f\"id={id_}\", \"part-0.parquet\")\n",
    "    return pd.read_parquet(path)\n",
    "\n",
    "\n",
    "def get_valid_ids(base_dir):\n",
    "    return [f.split(\"=\")[1].split(\".\")[0] for f in os.listdir(base_dir)]\n",
    "\n",
    "\n",
    "p = read_parquet(base_dir=\"../../inputs/series_train.parquet/\", id_=\"ffcd4dbd\")\n",
    "# p = read_parquet(base_dir=\"../../inputs/series_train.parquet/\", id_=\"10e46254\")\n",
    "\n",
    "scale_columns = [\n",
    "    \"X\",\n",
    "    \"Y\",\n",
    "    \"Z\",\n",
    "    \"enmo\",\n",
    "    \"anglez\",\n",
    "    \"light\",\n",
    "    \"battery_voltage\",\n",
    "]\n",
    "\n",
    "masked_columns = [\n",
    "    \"masked_X\",\n",
    "    \"masked_Y\",\n",
    "    \"masked_Z\",\n",
    "    \"masked_enmo\",\n",
    "    \"masked_anglez\",\n",
    "    \"masked_light\",\n",
    "]\n",
    "\n",
    "original_columns = [\"battery_voltage\", \"non-wear_flag\"]\n",
    "\n",
    "p[\"non-wear_flag\"] = 1 - p[\"non-wear_flag\"]\n",
    "scaler_features = p[scale_columns].values\n",
    "scaler = StandardScaler()\n",
    "p[scale_columns] = scaler.fit_transform(scaler_features)\n",
    "\n",
    "for mask_col in masked_columns:\n",
    "    p[mask_col] = p[mask_col.replace(\"masked_\", \"\")] * p[\"non-wear_flag\"]\n",
    "\n",
    "p = p.fillna(0.0)\n",
    "\n",
    "groups = p.groupby(\"relative_date_PCIAT\")\n",
    "# グループごとにデータフレームのリストに分割\n",
    "chunks = [group.reset_index(drop=True) for _, group in groups]\n",
    "\n",
    "use_cols = masked_columns + original_columns + scale_columns\n",
    "watch_day = len(chunks)\n",
    "active_logs = np.zeros((31, 17280, len(use_cols)), dtype=np.float32)\n",
    "active_mask = np.zeros((31), dtype=np.int32)\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    if i == 0:  #\n",
    "        active_logs[i, -len(chunk) :, :] = chunk[use_cols].values\n",
    "    elif i == watch_day:\n",
    "        active_logs[i, : len(chunk), :] = chunk[use_cols].values\n",
    "    else:\n",
    "        array = chunk[use_cols].values\n",
    "        active_logs[i, : len(array), :] = array\n",
    "\n",
    "    active_mask[i] = 1\n",
    "\n",
    "    if i == 30:\n",
    "        break\n",
    "\n",
    "active_logs = active_logs.reshape(31, 24, 60, 12, 15)  # 12は1時間の分割数\n",
    "active_logs_mean = active_logs.mean(axis=3)  # 1時間の分割数で平均を取る # 31, 1440, 15\n",
    "# active_logs_var = active_logs.var(axis=3)  # 1時間の分割数で分散を取る # 31, 1440, 15\n",
    "active_logs = np.concatenate([active_logs_mean], axis=-1)  # (31, 24, 30)\n",
    "# print(active_logs_mean.shape, active_logs_var.shape, active_logs.shape)\n",
    "\n",
    "print(active_logs_mean.shape, active_logs.shape)\n",
    "\n",
    "active_logs_mean = active_logs.mean(axis=2)  # 1時間の分割数で平均を取る # 31, 1440, 15\n",
    "active_logs_var = active_logs.var(axis=2)  # 1時間の分割数で分散を取る # 31, 1440, 15\n",
    "active_logs = np.concatenate(\n",
    "    [active_logs_mean, active_logs_var], axis=-1\n",
    ")  # (31, 24, 30)\n",
    "print(active_logs_mean.shape, active_logs_var.shape, active_logs.shape)\n",
    "active_logs = active_logs.reshape(-1, 30)\n",
    "print(active_logs.shape)\n",
    "\n",
    "# active_logs = active_logs.unsqueeze(0)\n",
    "active_logs = torch.tensor(active_logs, dtype=torch.float32).unsqueeze(0).to(\"cuda\")\n",
    "print(active_logs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM AutoEncoder output shape: torch.Size([1, 744, 30]) torch.Size([1, 64])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class TransformerAutoEncoder(nn.Module):\n",
    "    def __init__(self, d_model=128, nhead=4, num_layers=2):\n",
    "        super(TransformerAutoEncoder, self).__init__()\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead)\n",
    "        self.encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "        self.decoder_layer = nn.TransformerDecoderLayer(d_model=d_model, nhead=nhead)\n",
    "        self.decoder = nn.TransformerDecoder(self.decoder_layer, num_layers=num_layers)\n",
    "        self.embedding = nn.Linear(30, d_model)\n",
    "        self.output_layer = nn.Linear(d_model, 30)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  # (batch, day*time, d_model)\n",
    "        encoded = self.encoder(x.permute(1, 0, 2))  # (day*time, batch, d_model)\n",
    "        decoded = self.decoder(encoded, encoded)  # (day*time, batch, d_model)\n",
    "        return (\n",
    "            self.output_layer(decoded.permute(1, 0, 2)),\n",
    "            encoded,\n",
    "        )  # (batch, day*time, hidden)\n",
    "\n",
    "\n",
    "# Example\n",
    "model = TransformerAutoEncoder().to(\"cuda\")\n",
    "input_data = torch.randn(1, 744, 30).to(\"cuda\")\n",
    "output = model(input_data)\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class LSTMAutoEncoder(nn.Module):\n",
    "    def __init__(self, input_size=30, hidden_size=64, num_layers=2):\n",
    "        super(LSTMAutoEncoder, self).__init__()\n",
    "        # Encoder LSTM\n",
    "        self.encoder_lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        # Decoder LSTM\n",
    "        self.decoder_lstm = nn.LSTM(\n",
    "            input_size=hidden_size,\n",
    "            hidden_size=input_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encode\n",
    "        _, (h, _) = self.encoder_lstm(x)\n",
    "        embedding = h[-1]\n",
    "        # Decode\n",
    "        h = (\n",
    "            h[-1].unsqueeze(1).repeat(1, x.size(1), 1)\n",
    "        )  # Repeat hidden state for each timestep\n",
    "        decoded, _ = self.decoder_lstm(h)\n",
    "        return decoded, embedding\n",
    "\n",
    "\n",
    "# 実行例\n",
    "model = LSTMAutoEncoder()\n",
    "input_data = torch.randn(1, 744, 30)\n",
    "output, embedding = model(input_data)\n",
    "print(\"LSTM AutoEncoder output shape:\", output.shape, embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各モデルのインスタンス化\n",
    "# transformer_model = TransformerAutoEncoder()\n",
    "\n",
    "# # 正規分布からランダムに(1, 31, 17280, 15)の形状でデータを生成\n",
    "# input_data = torch.randn(1, 31, 17280, 15)\n",
    "\n",
    "# # 各モデルにデータを入力し、出力形状を確認\n",
    "# print(\"Input shape:\", input_data.shape)\n",
    "\n",
    "# # Transformerモデル\n",
    "# transformer_output = transformer_model(input_data)\n",
    "# print(\"Transformer Model output shape:\", transformer_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Basic_Demos-Enroll_Season</th>\n",
       "      <th>Basic_Demos-Age</th>\n",
       "      <th>Basic_Demos-Sex</th>\n",
       "      <th>CGAS-Season</th>\n",
       "      <th>CGAS-CGAS_Score</th>\n",
       "      <th>Physical-Season</th>\n",
       "      <th>Physical-BMI</th>\n",
       "      <th>Physical-Height</th>\n",
       "      <th>Physical-Weight</th>\n",
       "      <th>...</th>\n",
       "      <th>PCIAT-PCIAT_18</th>\n",
       "      <th>PCIAT-PCIAT_19</th>\n",
       "      <th>PCIAT-PCIAT_20</th>\n",
       "      <th>PCIAT-PCIAT_Total</th>\n",
       "      <th>SDS-Season</th>\n",
       "      <th>SDS-SDS_Total_Raw</th>\n",
       "      <th>SDS-SDS_Total_T</th>\n",
       "      <th>PreInt_EduHx-Season</th>\n",
       "      <th>PreInt_EduHx-computerinternet_hoursday</th>\n",
       "      <th>sii</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00008ff9</td>\n",
       "      <td>Fall</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>16.877316</td>\n",
       "      <td>46.0</td>\n",
       "      <td>50.8</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fall</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fd460</td>\n",
       "      <td>Summer</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fall</td>\n",
       "      <td>14.035590</td>\n",
       "      <td>48.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>46.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Summer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00105258</td>\n",
       "      <td>Summer</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Fall</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>16.648696</td>\n",
       "      <td>56.5</td>\n",
       "      <td>75.6</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>38.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00115b9f</td>\n",
       "      <td>Winter</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Summer</td>\n",
       "      <td>18.292347</td>\n",
       "      <td>56.0</td>\n",
       "      <td>81.6</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Summer</td>\n",
       "      <td>31.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0016bb22</td>\n",
       "      <td>Spring</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>Summer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3955</th>\n",
       "      <td>ff8a2de4</td>\n",
       "      <td>Fall</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>Spring</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>16.362460</td>\n",
       "      <td>59.5</td>\n",
       "      <td>82.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>35.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3956</th>\n",
       "      <td>ffa9794a</td>\n",
       "      <td>Winter</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spring</td>\n",
       "      <td>18.764678</td>\n",
       "      <td>53.5</td>\n",
       "      <td>76.4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Winter</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3957</th>\n",
       "      <td>ffcd4dbd</td>\n",
       "      <td>Fall</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>Spring</td>\n",
       "      <td>68.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>21.441500</td>\n",
       "      <td>60.0</td>\n",
       "      <td>109.8</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>56.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3958</th>\n",
       "      <td>ffed1dd5</td>\n",
       "      <td>Spring</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>Spring</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>12.235895</td>\n",
       "      <td>70.7</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Spring</td>\n",
       "      <td>33.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>Spring</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3959</th>\n",
       "      <td>ffef538e</td>\n",
       "      <td>Spring</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Winter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spring</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3960 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id Basic_Demos-Enroll_Season  Basic_Demos-Age  Basic_Demos-Sex  \\\n",
       "0     00008ff9                      Fall                5                0   \n",
       "1     000fd460                    Summer                9                0   \n",
       "2     00105258                    Summer               10                1   \n",
       "3     00115b9f                    Winter                9                0   \n",
       "4     0016bb22                    Spring               18                1   \n",
       "...        ...                       ...              ...              ...   \n",
       "3955  ff8a2de4                      Fall               13                0   \n",
       "3956  ffa9794a                    Winter               10                0   \n",
       "3957  ffcd4dbd                      Fall               11                0   \n",
       "3958  ffed1dd5                    Spring               13                0   \n",
       "3959  ffef538e                    Spring               11                0   \n",
       "\n",
       "     CGAS-Season  CGAS-CGAS_Score Physical-Season  Physical-BMI  \\\n",
       "0         Winter             51.0            Fall     16.877316   \n",
       "1            NaN              NaN            Fall     14.035590   \n",
       "2           Fall             71.0            Fall     16.648696   \n",
       "3           Fall             71.0          Summer     18.292347   \n",
       "4         Summer              NaN             NaN           NaN   \n",
       "...          ...              ...             ...           ...   \n",
       "3955      Spring             60.0            Fall     16.362460   \n",
       "3956         NaN              NaN          Spring     18.764678   \n",
       "3957      Spring             68.0          Winter     21.441500   \n",
       "3958      Spring             70.0          Winter     12.235895   \n",
       "3959         NaN              NaN          Winter           NaN   \n",
       "\n",
       "      Physical-Height  Physical-Weight  ...  PCIAT-PCIAT_18  PCIAT-PCIAT_19  \\\n",
       "0                46.0             50.8  ...             4.0             2.0   \n",
       "1                48.0             46.0  ...             0.0             0.0   \n",
       "2                56.5             75.6  ...             2.0             1.0   \n",
       "3                56.0             81.6  ...             3.0             4.0   \n",
       "4                 NaN              NaN  ...             NaN             NaN   \n",
       "...               ...              ...  ...             ...             ...   \n",
       "3955             59.5             82.4  ...             1.0             1.0   \n",
       "3956             53.5             76.4  ...             NaN             NaN   \n",
       "3957             60.0            109.8  ...             1.0             0.0   \n",
       "3958             70.7             87.0  ...             1.0             1.0   \n",
       "3959              NaN              NaN  ...             NaN             NaN   \n",
       "\n",
       "      PCIAT-PCIAT_20  PCIAT-PCIAT_Total SDS-Season  SDS-SDS_Total_Raw  \\\n",
       "0                4.0               55.0        NaN                NaN   \n",
       "1                0.0                0.0       Fall               46.0   \n",
       "2                1.0               28.0       Fall               38.0   \n",
       "3                1.0               44.0     Summer               31.0   \n",
       "4                NaN                NaN        NaN                NaN   \n",
       "...              ...                ...        ...                ...   \n",
       "3955             0.0               32.0     Winter               35.0   \n",
       "3956             NaN                NaN        NaN                NaN   \n",
       "3957             1.0               31.0     Winter               56.0   \n",
       "3958             1.0               19.0     Spring               33.0   \n",
       "3959             NaN                NaN        NaN                NaN   \n",
       "\n",
       "      SDS-SDS_Total_T  PreInt_EduHx-Season  \\\n",
       "0                 NaN                 Fall   \n",
       "1                64.0               Summer   \n",
       "2                54.0               Summer   \n",
       "3                45.0               Winter   \n",
       "4                 NaN                  NaN   \n",
       "...               ...                  ...   \n",
       "3955             50.0                 Fall   \n",
       "3956              NaN               Winter   \n",
       "3957             77.0                 Fall   \n",
       "3958             47.0               Spring   \n",
       "3959              NaN               Spring   \n",
       "\n",
       "     PreInt_EduHx-computerinternet_hoursday  sii  \n",
       "0                                       3.0  2.0  \n",
       "1                                       0.0  0.0  \n",
       "2                                       2.0  0.0  \n",
       "3                                       0.0  1.0  \n",
       "4                                       NaN  NaN  \n",
       "...                                     ...  ...  \n",
       "3955                                    1.0  1.0  \n",
       "3956                                    0.0  NaN  \n",
       "3957                                    0.0  1.0  \n",
       "3958                                    1.0  0.0  \n",
       "3959                                    1.0  NaN  \n",
       "\n",
       "[3960 rows x 82 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テーブルデータセット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_features = [\n",
    "    \"BMI_Age\",\n",
    "    \"Internet_Hours_Age\",\n",
    "    \"BMI_Internet_Hours\",\n",
    "    \"BFP_BMI\",\n",
    "    \"FFMI_BFP\",\n",
    "    \"FMI_BFP\",\n",
    "    \"LST_TBW\",\n",
    "    \"BFP_BMR\",\n",
    "    \"BFP_DEE\",\n",
    "    \"BMR_Weight\",\n",
    "    \"DEE_Weight\",\n",
    "    \"SMM_Height\",\n",
    "    \"Muscle_to_Fat\",\n",
    "    \"Hydration_Status\",\n",
    "    \"ICW_TBW\",\n",
    "]\n",
    "\n",
    "\n",
    "def feature_engineering(df):\n",
    "    # season_cols = [col for col in df.columns if \"Season\" in col]\n",
    "    # df = df.drop(season_cols, axis=1)\n",
    "    df[\"BMI_Age\"] = df[\"Physical-BMI\"] * df[\"Basic_Demos-Age\"]\n",
    "    df[\"Internet_Hours_Age\"] = (\n",
    "        df[\"PreInt_EduHx-computerinternet_hoursday\"] * df[\"Basic_Demos-Age\"]\n",
    "    )\n",
    "    df[\"BMI_Internet_Hours\"] = (\n",
    "        df[\"Physical-BMI\"] * df[\"PreInt_EduHx-computerinternet_hoursday\"]\n",
    "    )\n",
    "    df[\"BFP_BMI\"] = df[\"BIA-BIA_Fat\"] / df[\"BIA-BIA_BMI\"]\n",
    "    df[\"FFMI_BFP\"] = df[\"BIA-BIA_FFMI\"] / df[\"BIA-BIA_Fat\"]\n",
    "    df[\"FMI_BFP\"] = df[\"BIA-BIA_FMI\"] / df[\"BIA-BIA_Fat\"]\n",
    "    df[\"LST_TBW\"] = df[\"BIA-BIA_LST\"] / df[\"BIA-BIA_TBW\"]\n",
    "    df[\"BFP_BMR\"] = df[\"BIA-BIA_Fat\"] * df[\"BIA-BIA_BMR\"]\n",
    "    df[\"BFP_DEE\"] = df[\"BIA-BIA_Fat\"] * df[\"BIA-BIA_DEE\"]\n",
    "    df[\"BMR_Weight\"] = df[\"BIA-BIA_BMR\"] / df[\"Physical-Weight\"]\n",
    "    df[\"DEE_Weight\"] = df[\"BIA-BIA_DEE\"] / df[\"Physical-Weight\"]\n",
    "    df[\"SMM_Height\"] = df[\"BIA-BIA_SMM\"] / df[\"Physical-Height\"]\n",
    "    df[\"Muscle_to_Fat\"] = df[\"BIA-BIA_SMM\"] / df[\"BIA-BIA_FMI\"]\n",
    "    df[\"Hydration_Status\"] = df[\"BIA-BIA_TBW\"] / df[\"Physical-Weight\"]\n",
    "    df[\"ICW_TBW\"] = df[\"BIA-BIA_ICW\"] / df[\"BIA-BIA_TBW\"]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "train = feature_engineering(train)\n",
    "train = train.replace([np.inf, -np.inf], np.nan)\n",
    "for add_ in add_features:\n",
    "    train[add_] = train[add_].fillna(0.0)\n",
    "train = train.dropna(thresh=10, axis=0)\n",
    "\n",
    "test = feature_engineering(test)\n",
    "test = test.replace([np.inf, -np.inf], np.nan)\n",
    "for add_ in add_features:\n",
    "    test[add_] = test[add_].fillna(0.0)\n",
    "test = test.dropna(thresh=10, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create new scaler\n"
     ]
    }
   ],
   "source": [
    "# onehotEncoderの作成\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "double_columns = [\n",
    "    \"FGC-FGC_SRR_Zone\",\n",
    "    \"BIA-BIA_SMM\",\n",
    "    \"Physical-Waist_Circumference\",\n",
    "    \"BIA-BIA_FFMI\",\n",
    "    \"FGC-FGC_CU\",\n",
    "    \"PreInt_EduHx-computerinternet_hoursday\",\n",
    "    \"BIA-BIA_ECW\",\n",
    "    \"FGC-FGC_CU_Zone\",\n",
    "    \"FGC-FGC_SRL_Zone\",\n",
    "    \"BIA-BIA_DEE\",\n",
    "    \"Physical-Weight\",\n",
    "    \"Fitness_Endurance-Time_Mins\",\n",
    "    \"FGC-FGC_SRR\",\n",
    "    \"SDS-SDS_Total_T\",\n",
    "    \"FGC-FGC_PU\",\n",
    "    \"BIA-BIA_FFM\",\n",
    "    \"FGC-FGC_TL_Zone\",\n",
    "    \"Physical-BMI\",\n",
    "    \"Physical-Systolic_BP\",\n",
    "    \"Physical-HeartRate\",\n",
    "    \"BIA-BIA_ICW\",\n",
    "    \"Physical-Height\",\n",
    "    \"FGC-FGC_SRL\",\n",
    "    \"BIA-BIA_BMC\",\n",
    "    \"Fitness_Endurance-Time_Sec\",\n",
    "    \"BIA-BIA_Frame_num\",\n",
    "    \"Basic_Demos-Age\",\n",
    "    \"FGC-FGC_GSND_Zone\",\n",
    "    \"Basic_Demos-Sex\",\n",
    "    \"FGC-FGC_GSND\",\n",
    "    \"BIA-BIA_LST\",\n",
    "    \"FGC-FGC_TL\",\n",
    "    \"BIA-BIA_BMI\",\n",
    "    \"BIA-BIA_FMI\",\n",
    "    \"PAQ_C-PAQ_C_Total\",\n",
    "    \"BIA-BIA_Activity_Level_num\",\n",
    "    \"FGC-FGC_GSD\",\n",
    "    \"BIA-BIA_BMR\",\n",
    "    \"BIA-BIA_Fat\",\n",
    "    \"SDS-SDS_Total_Raw\",\n",
    "    \"CGAS-CGAS_Score\",\n",
    "    \"FGC-FGC_PU_Zone\",\n",
    "    \"BIA-BIA_LDM\",\n",
    "    \"Fitness_Endurance-Max_Stage\",\n",
    "    \"PAQ_A-PAQ_A_Total\",\n",
    "    \"BIA-BIA_TBW\",\n",
    "    \"FGC-FGC_GSD_Zone\",\n",
    "    \"Physical-Diastolic_BP\",\n",
    "]\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def create_dataset_(df, scaler=None, train=True):\n",
    "\n",
    "    if scaler is None:\n",
    "        print(\"create new scaler\")\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(df[double_columns + add_features])\n",
    "        with open(\"./assets/scaler.pkl\", \"wb\") as f:\n",
    "            pickle.dump(scaler, f)\n",
    "\n",
    "    double_feature = scaler.transform(df[double_columns + add_features])\n",
    "    # 欠損値の補完\n",
    "    double_feature = np.nan_to_num(double_feature)\n",
    "\n",
    "    ids = df[\"id\"].values.reshape(-1, 1)\n",
    "    X = double_feature\n",
    "\n",
    "    # DataFrameの作成\n",
    "    ids_df = pd.DataFrame(ids, columns=[\"id\"])\n",
    "    X_df = pd.DataFrame(X, columns=[f\"feature_{i}\" for i in range(X.shape[1])])\n",
    "\n",
    "    if train:\n",
    "        y = df[\"sii\"].fillna(-1).values.reshape(-1, 1)\n",
    "        y_df = pd.DataFrame(y, columns=[\"sii\"])\n",
    "        df = pd.concat([ids_df, X_df, y_df], axis=1)\n",
    "    else:\n",
    "        df = pd.concat([ids_df, X_df], axis=1)\n",
    "    return df, scaler\n",
    "\n",
    "\n",
    "train, scaler = create_dataset_(train)\n",
    "test = create_dataset_(test, scaler=scaler, train=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_55</th>\n",
       "      <th>feature_56</th>\n",
       "      <th>feature_57</th>\n",
       "      <th>feature_58</th>\n",
       "      <th>feature_59</th>\n",
       "      <th>feature_60</th>\n",
       "      <th>feature_61</th>\n",
       "      <th>feature_62</th>\n",
       "      <th>id</th>\n",
       "      <th>sii</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.277596</td>\n",
       "      <td>-0.176702</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.209436</td>\n",
       "      <td>-0.953788</td>\n",
       "      <td>1.771623</td>\n",
       "      <td>-0.171600</td>\n",
       "      <td>-0.953742</td>\n",
       "      <td>-1.274301</td>\n",
       "      <td>-0.201970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015691</td>\n",
       "      <td>0.015630</td>\n",
       "      <td>0.531031</td>\n",
       "      <td>0.540327</td>\n",
       "      <td>0.113954</td>\n",
       "      <td>0.083339</td>\n",
       "      <td>0.251650</td>\n",
       "      <td>1.296492</td>\n",
       "      <td>00008ff9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.782720</td>\n",
       "      <td>-0.225858</td>\n",
       "      <td>-0.948658</td>\n",
       "      <td>-0.380787</td>\n",
       "      <td>-0.699663</td>\n",
       "      <td>-0.968830</td>\n",
       "      <td>-0.202128</td>\n",
       "      <td>-0.953742</td>\n",
       "      <td>0.784744</td>\n",
       "      <td>-0.199625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015270</td>\n",
       "      <td>0.015181</td>\n",
       "      <td>0.629987</td>\n",
       "      <td>0.643793</td>\n",
       "      <td>0.021863</td>\n",
       "      <td>0.304658</td>\n",
       "      <td>0.209698</td>\n",
       "      <td>1.388511</td>\n",
       "      <td>000fd460</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.782720</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.740376</td>\n",
       "      <td>0.858138</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.048502</td>\n",
       "      <td>0.784744</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014948</td>\n",
       "      <td>0.014837</td>\n",
       "      <td>-0.374560</td>\n",
       "      <td>-0.406553</td>\n",
       "      <td>-0.263102</td>\n",
       "      <td>-0.139659</td>\n",
       "      <td>-0.235959</td>\n",
       "      <td>-0.993169</td>\n",
       "      <td>00105258</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.277596</td>\n",
       "      <td>-0.094130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.165178</td>\n",
       "      <td>0.570959</td>\n",
       "      <td>-0.968830</td>\n",
       "      <td>-0.071440</td>\n",
       "      <td>1.048502</td>\n",
       "      <td>-1.274301</td>\n",
       "      <td>-0.049816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016791</td>\n",
       "      <td>0.016926</td>\n",
       "      <td>0.309486</td>\n",
       "      <td>0.353385</td>\n",
       "      <td>0.156596</td>\n",
       "      <td>0.079541</td>\n",
       "      <td>0.191155</td>\n",
       "      <td>1.031686</td>\n",
       "      <td>00115b9f</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014948</td>\n",
       "      <td>0.014837</td>\n",
       "      <td>-0.374560</td>\n",
       "      <td>-0.406553</td>\n",
       "      <td>-0.263102</td>\n",
       "      <td>-0.139659</td>\n",
       "      <td>-0.235959</td>\n",
       "      <td>-0.993169</td>\n",
       "      <td>0016bb22</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0  -1.277596  -0.176702   0.000000  -0.209436  -0.953788   1.771623   \n",
       "1   0.782720  -0.225858  -0.948658  -0.380787  -0.699663  -0.968830   \n",
       "2   0.782720   0.000000   0.000000   0.000000   0.740376   0.858138   \n",
       "3  -1.277596  -0.094130   0.000000  -0.165178   0.570959  -0.968830   \n",
       "4   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "\n",
       "   feature_6  feature_7  feature_8  feature_9  ...  feature_55  feature_56  \\\n",
       "0  -0.171600  -0.953742  -1.274301  -0.201970  ...    0.015691    0.015630   \n",
       "1  -0.202128  -0.953742   0.784744  -0.199625  ...    0.015270    0.015181   \n",
       "2   0.000000   1.048502   0.784744   0.000000  ...    0.014948    0.014837   \n",
       "3  -0.071440   1.048502  -1.274301  -0.049816  ...    0.016791    0.016926   \n",
       "4   0.000000   0.000000   0.000000   0.000000  ...    0.014948    0.014837   \n",
       "\n",
       "   feature_57  feature_58  feature_59  feature_60  feature_61  feature_62  \\\n",
       "0    0.531031    0.540327    0.113954    0.083339    0.251650    1.296492   \n",
       "1    0.629987    0.643793    0.021863    0.304658    0.209698    1.388511   \n",
       "2   -0.374560   -0.406553   -0.263102   -0.139659   -0.235959   -0.993169   \n",
       "3    0.309486    0.353385    0.156596    0.079541    0.191155    1.031686   \n",
       "4   -0.374560   -0.406553   -0.263102   -0.139659   -0.235959   -0.993169   \n",
       "\n",
       "         id  sii  \n",
       "0  00008ff9  2.0  \n",
       "1  000fd460  0.0  \n",
       "2  00105258  0.0  \n",
       "3  00115b9f  1.0  \n",
       "4  0016bb22 -1.0  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imputer = KNNImputer(n_neighbors=5)\n",
    "sii_imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "numeric_cols = test.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
    "numeric_feature_cols = numeric_cols.copy()\n",
    "# numeric_feature_cols = numeric_feature_cols.drop(\"sii\")\n",
    "\n",
    "numeric_sii_cols = train.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
    "\n",
    "sii_inputed = sii_imputer.fit_transform(train[numeric_sii_cols])\n",
    "feature_imputer.fit(test[numeric_feature_cols])\n",
    "feature_inputed = feature_imputer.fit_transform(train[numeric_feature_cols])\n",
    "\n",
    "train_imputed = pd.DataFrame(feature_inputed, columns=numeric_feature_cols)\n",
    "\n",
    "for col in train.columns:\n",
    "    if col not in numeric_cols:\n",
    "        train_imputed[col] = train[col]\n",
    "\n",
    "train_imputed[\"sii\"] = train[\"sii\"]\n",
    "train = train_imputed\n",
    "\n",
    "# train = train[train[\"sii\"] > -1].reset_index(drop=True)\n",
    "train = train[train[\"sii\"].notnull()].reset_index(drop=True)\n",
    "\n",
    "# sii_impute = pd.DataFrame(sii_inputed, columns=numeric_sii_cols)\n",
    "# sii_impute[\"sii\"] = sii_impute[\"sii\"].round().astype(int)\n",
    "# train[\"sii\"] = sii_impute[\"sii\"]\n",
    "\n",
    "with open(\"feature_imputer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(feature_imputer, f)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/996 [00:00<?, ?it/s]Could not load symbol cublasGetSmCountTarget from libcublas.so.11. Error: /usr/local/cuda-11.3/lib64/libcublas.so.11: undefined symbol: cublasGetSmCountTarget\n",
      "100%|██████████| 996/996 [01:50<00:00,  8.99it/s, loss=0.921]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 0.9213714597327821\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 996/996 [01:52<00:00,  8.82it/s, loss=0.918]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.9182404741424185\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 996/996 [01:53<00:00,  8.76it/s, loss=0.918]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 0.9182000718543298\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 996/996 [01:52<00:00,  8.86it/s, loss=0.918]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 0.918125432966479\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 847/996 [01:35<00:17,  8.42it/s, loss=0.957]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 163\u001b[0m\n\u001b[1;32m    159\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    161\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m--> 163\u001b[0m epoch_loss\u001b[38;5;241m.\u001b[39mappend(\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    165\u001b[0m tq\u001b[38;5;241m.\u001b[39mset_postfix(loss\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mmean(epoch_loss))\n\u001b[1;32m    166\u001b[0m tq\u001b[38;5;241m.\u001b[39mupdate()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class CMIDataset(Dataset):\n",
    "    def __init__(self, table_df, valid_ids, base_dir, save_filename):\n",
    "        self.base_dir = base_dir\n",
    "        self.table_df = table_df\n",
    "        self.valid_ids = valid_ids\n",
    "        self.save_filename = save_filename\n",
    "        self.scale_columns = [\n",
    "            \"X\",\n",
    "            \"Y\",\n",
    "            \"Z\",\n",
    "            \"enmo\",\n",
    "            \"anglez\",\n",
    "            \"light\",\n",
    "            \"battery_voltage\",\n",
    "        ]\n",
    "\n",
    "        self.masked_columns = [\n",
    "            \"masked_X\",\n",
    "            \"masked_Y\",\n",
    "            \"masked_Z\",\n",
    "            \"masked_enmo\",\n",
    "            \"masked_anglez\",\n",
    "            \"masked_light\",\n",
    "        ]\n",
    "\n",
    "        self.original_columns = [\"battery_voltage\", \"non-wear_flag\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # テーブルデータの抽出\n",
    "        id_ = self.valid_ids[idx]\n",
    "\n",
    "        save_dir = f\"/home/tatsuya/code/projects/kaggle/ChildMindInstitute2024/precreated_dataset/{self.save_filename}/\"\n",
    "        save_path = os.path.join(save_dir, id_)\n",
    "\n",
    "        table = self.table_df.loc[self.table_df[\"id\"] == self.valid_ids[idx], :]\n",
    "        table_feature = table.drop(columns=[\"id\", \"sii\"]).values\n",
    "        sii = table[\"sii\"].values\n",
    "\n",
    "        # 時系列データの抽出\n",
    "        use_cols = self.masked_columns + self.original_columns + self.scale_columns\n",
    "        p = read_parquet(self.base_dir, self.valid_ids[idx])\n",
    "\n",
    "        if p is not None:\n",
    "            p[\"non-wear_flag\"] = 1 - p[\"non-wear_flag\"]\n",
    "            scaler_features = p[scale_columns].values\n",
    "            scaler = StandardScaler()\n",
    "            p[scale_columns] = scaler.fit_transform(scaler_features)\n",
    "\n",
    "            for mask_col in masked_columns:\n",
    "                p[mask_col] = p[mask_col.replace(\"masked_\", \"\")] * p[\"non-wear_flag\"]\n",
    "\n",
    "            p = p.fillna(0.0)\n",
    "\n",
    "            groups = p.groupby(\"relative_date_PCIAT\")\n",
    "            # グループごとにデータフレームのリストに分割\n",
    "            chunks = [group.reset_index(drop=True) for _, group in groups]\n",
    "\n",
    "            use_cols = masked_columns + original_columns + scale_columns\n",
    "            watch_day = len(chunks)\n",
    "            active_logs = np.zeros((31, 17280, len(use_cols)), dtype=np.float32)\n",
    "            active_mask = np.zeros((31), dtype=np.int32)\n",
    "\n",
    "            for i, chunk in enumerate(chunks):\n",
    "                if i == 0:  #\n",
    "                    active_logs[i, -len(chunk) :, :] = chunk[use_cols].values\n",
    "                elif i == watch_day:\n",
    "                    active_logs[i, : len(chunk), :] = chunk[use_cols].values\n",
    "                else:\n",
    "                    array = chunk[use_cols].values\n",
    "                    active_logs[i, : len(array), :] = array\n",
    "\n",
    "                active_mask[i] = 1\n",
    "\n",
    "                if i == 30:\n",
    "                    break\n",
    "\n",
    "            active_logs = active_logs.reshape(31, 24, 60, 12, 15)  # 12は1時間の分割数\n",
    "            active_logs_mean = active_logs.mean(\n",
    "                axis=3\n",
    "            )  # 1時間の分割数で平均を取る # 31, 1440, 15\n",
    "            # active_logs_var = active_logs.var(axis=3)  # 1時間の分割数で分散を取る # 31, 1440, 15\n",
    "            active_logs = np.concatenate([active_logs_mean], axis=-1)  # (31, 24, 30)\n",
    "            # print(active_logs_mean.shape, active_logs_var.shape, active_logs.shape)\n",
    "\n",
    "            # print(active_logs_mean.shape, active_logs.shape)\n",
    "\n",
    "            active_logs_mean = active_logs.mean(\n",
    "                axis=2\n",
    "            )  # 1時間の分割数で平均を取る # 31, 1440, 15\n",
    "            active_logs_var = active_logs.var(\n",
    "                axis=2\n",
    "            )  # 1時間の分割数で分散を取る # 31, 1440, 15\n",
    "            active_logs = np.concatenate(\n",
    "                [active_logs_mean, active_logs_var], axis=-1\n",
    "            )  # (31, 24, 30)\n",
    "            # print(active_logs_mean.shape, active_logs_var.shape, active_logs.shape)\n",
    "            active_logs = active_logs.reshape(-1, 30)\n",
    "\n",
    "        else:\n",
    "            active_logs = np.zeros((744, 30), dtype=np.float32)\n",
    "            active_mask = np.zeros((744), dtype=np.int32)\n",
    "\n",
    "        dataset_ = {\n",
    "            \"id\": id_,\n",
    "            \"table_input\": torch.tensor(table_feature, dtype=torch.float32),\n",
    "            \"time_input\": torch.tensor(active_logs, dtype=torch.float32),\n",
    "            \"mask\": torch.tensor(active_mask, dtype=torch.int32),\n",
    "            \"output\": torch.tensor(sii, dtype=torch.float32),\n",
    "        }\n",
    "\n",
    "        return dataset_\n",
    "\n",
    "\n",
    "def read_parquet(base_dir, id_):\n",
    "    path = os.path.join(base_dir, f\"id={id_}\", \"part-0.parquet\")\n",
    "    if not os.path.exists(path):\n",
    "        return None\n",
    "    return pd.read_parquet(path)\n",
    "\n",
    "\n",
    "dataset = CMIDataset(\n",
    "    table_df=train,\n",
    "    valid_ids=get_valid_ids(train_series_dir),\n",
    "    base_dir=train_series_dir,\n",
    "    save_filename=\"train\",\n",
    ")\n",
    "\n",
    "# AutoEncoderのモデルのインスタンス化\n",
    "# transformer_model = TransformerAutoEncoder().to(\"cuda\")\n",
    "# transformer_model.load_state_dict(torch.load(\"./assets/transformer_autoencoder.pth\"))\n",
    "lstm_model = LSTMAutoEncoder().to(\"cuda\")\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(lstm_model.parameters(), lr=0.0001)\n",
    "# データセットからデータを取り出す\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "best_model = None\n",
    "minimum_loss = 1000000\n",
    "\n",
    "for epoch in range(10):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "    epoch_loss = []\n",
    "    tq = tqdm(dataloader)\n",
    "    for data in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        table_input = data[\"table_input\"]\n",
    "        time_input = data[\"time_input\"].to(\"cuda\")\n",
    "        mask = data[\"mask\"]\n",
    "\n",
    "        # モデルにデータを入力し、出力を取得\n",
    "        lstm_output, embedding = lstm_model(time_input)\n",
    "        # 損失の計算\n",
    "        loss = criterion(lstm_output, time_input)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss.append(loss.item())\n",
    "\n",
    "        tq.set_postfix(loss=np.mean(epoch_loss))\n",
    "        tq.update()\n",
    "\n",
    "    if np.mean(epoch_loss) < minimum_loss:\n",
    "        minimum_loss = np.mean(epoch_loss)\n",
    "        best_model = lstm_model\n",
    "        lstm_model.eval()\n",
    "        torch.save(lstm_model.state_dict(), \"./assets/lstm_autoencoder.pth\")\n",
    "        lstm_model.train()\n",
    "\n",
    "    print(f\"Epoch {epoch} Loss: {np.mean(epoch_loss)}\")\n",
    "    tq.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 107/996 [00:18<02:37,  5.65it/s]\n",
      "100%|██████████| 996/996 [01:45<00:00,  9.47it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = CMIDataset(\n",
    "    table_df=train,\n",
    "    valid_ids=get_valid_ids(train_series_dir),\n",
    "    base_dir=train_series_dir,\n",
    "    save_filename=\"train\",\n",
    ")\n",
    "\n",
    "# AutoEncoderのモデルのインスタンス化\n",
    "# transformer_model = TransformerAutoEncoder().to(\"cuda\")\n",
    "# transformer_model.load_state_dict(torch.load(\"./assets/transformer_autoencoder.pth\"))\n",
    "lstm_model = LSTMAutoEncoder().to(\"cuda\")\n",
    "lstm_model.load_state_dict(torch.load(\"./assets/lstm_autoencoder.pth\"))\n",
    "# データセットからデータを取り出す\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "best_model = None\n",
    "minimum_loss = 1000000\n",
    "\n",
    "print(f\"Create Embedding\")\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "epoch_loss = []\n",
    "tq = tqdm(dataloader)\n",
    "\n",
    "embedding_result = []\n",
    "\n",
    "for data in dataloader:\n",
    "    id_ = data[\"id\"][0]\n",
    "    table_input = data[\"table_input\"]\n",
    "    time_input = data[\"time_input\"].to(\"cuda\")\n",
    "    mask = data[\"mask\"]\n",
    "\n",
    "    # モデルにデータを入力し、出力を取得\n",
    "    lstm_output, embedding = lstm_model(time_input)\n",
    "    # 損失の計算\n",
    "\n",
    "    # mean_embedding = transformer_output.squeeze(0).mean(axis=0).cpu().detach().numpy()\n",
    "    mean_embedding = embedding.cpu().detach().numpy()\n",
    "\n",
    "    embedding_result.append({\"id\": id_, \"embedding\": mean_embedding})\n",
    "\n",
    "    tq.update()\n",
    "\n",
    "tq.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>embedding_0</th>\n",
       "      <th>embedding_1</th>\n",
       "      <th>embedding_2</th>\n",
       "      <th>embedding_3</th>\n",
       "      <th>embedding_4</th>\n",
       "      <th>embedding_5</th>\n",
       "      <th>embedding_6</th>\n",
       "      <th>embedding_7</th>\n",
       "      <th>embedding_8</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_54</th>\n",
       "      <th>embedding_55</th>\n",
       "      <th>embedding_56</th>\n",
       "      <th>embedding_57</th>\n",
       "      <th>embedding_58</th>\n",
       "      <th>embedding_59</th>\n",
       "      <th>embedding_60</th>\n",
       "      <th>embedding_61</th>\n",
       "      <th>embedding_62</th>\n",
       "      <th>embedding_63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23dafdab</td>\n",
       "      <td>-0.528813</td>\n",
       "      <td>-0.620962</td>\n",
       "      <td>-0.310135</td>\n",
       "      <td>0.170380</td>\n",
       "      <td>-0.074117</td>\n",
       "      <td>0.282184</td>\n",
       "      <td>-0.002533</td>\n",
       "      <td>0.716247</td>\n",
       "      <td>-0.323445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.242430</td>\n",
       "      <td>-0.411412</td>\n",
       "      <td>0.194835</td>\n",
       "      <td>0.513866</td>\n",
       "      <td>0.444615</td>\n",
       "      <td>-0.311440</td>\n",
       "      <td>-0.503001</td>\n",
       "      <td>0.379872</td>\n",
       "      <td>-0.301026</td>\n",
       "      <td>0.496942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e4614ec6</td>\n",
       "      <td>-0.528813</td>\n",
       "      <td>-0.620962</td>\n",
       "      <td>-0.310135</td>\n",
       "      <td>0.170380</td>\n",
       "      <td>-0.074117</td>\n",
       "      <td>0.282184</td>\n",
       "      <td>-0.002533</td>\n",
       "      <td>0.716247</td>\n",
       "      <td>-0.323445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.242430</td>\n",
       "      <td>-0.411412</td>\n",
       "      <td>0.194835</td>\n",
       "      <td>0.513866</td>\n",
       "      <td>0.444615</td>\n",
       "      <td>-0.311440</td>\n",
       "      <td>-0.503001</td>\n",
       "      <td>0.379872</td>\n",
       "      <td>-0.301026</td>\n",
       "      <td>0.496942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56ef356c</td>\n",
       "      <td>-0.762479</td>\n",
       "      <td>-0.732674</td>\n",
       "      <td>-0.558686</td>\n",
       "      <td>0.272567</td>\n",
       "      <td>-0.133033</td>\n",
       "      <td>0.456527</td>\n",
       "      <td>0.014443</td>\n",
       "      <td>0.803861</td>\n",
       "      <td>-0.518356</td>\n",
       "      <td>...</td>\n",
       "      <td>0.544268</td>\n",
       "      <td>-0.496551</td>\n",
       "      <td>0.510508</td>\n",
       "      <td>0.658227</td>\n",
       "      <td>0.603788</td>\n",
       "      <td>-0.453413</td>\n",
       "      <td>-0.780339</td>\n",
       "      <td>0.588516</td>\n",
       "      <td>-0.362753</td>\n",
       "      <td>0.768235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dcfcd574</td>\n",
       "      <td>-0.528813</td>\n",
       "      <td>-0.620962</td>\n",
       "      <td>-0.310135</td>\n",
       "      <td>0.170380</td>\n",
       "      <td>-0.074117</td>\n",
       "      <td>0.282184</td>\n",
       "      <td>-0.002533</td>\n",
       "      <td>0.716247</td>\n",
       "      <td>-0.323445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.242430</td>\n",
       "      <td>-0.411412</td>\n",
       "      <td>0.194835</td>\n",
       "      <td>0.513866</td>\n",
       "      <td>0.444615</td>\n",
       "      <td>-0.311440</td>\n",
       "      <td>-0.503001</td>\n",
       "      <td>0.379872</td>\n",
       "      <td>-0.301026</td>\n",
       "      <td>0.496942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>338146bd</td>\n",
       "      <td>-0.528813</td>\n",
       "      <td>-0.620962</td>\n",
       "      <td>-0.310135</td>\n",
       "      <td>0.170380</td>\n",
       "      <td>-0.074117</td>\n",
       "      <td>0.282184</td>\n",
       "      <td>-0.002533</td>\n",
       "      <td>0.716247</td>\n",
       "      <td>-0.323445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.242430</td>\n",
       "      <td>-0.411412</td>\n",
       "      <td>0.194835</td>\n",
       "      <td>0.513866</td>\n",
       "      <td>0.444615</td>\n",
       "      <td>-0.311440</td>\n",
       "      <td>-0.503001</td>\n",
       "      <td>0.379872</td>\n",
       "      <td>-0.301026</td>\n",
       "      <td>0.496942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2a9e0dee</td>\n",
       "      <td>-0.528813</td>\n",
       "      <td>-0.620962</td>\n",
       "      <td>-0.310135</td>\n",
       "      <td>0.170380</td>\n",
       "      <td>-0.074117</td>\n",
       "      <td>0.282184</td>\n",
       "      <td>-0.002533</td>\n",
       "      <td>0.716247</td>\n",
       "      <td>-0.323445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.242430</td>\n",
       "      <td>-0.411412</td>\n",
       "      <td>0.194835</td>\n",
       "      <td>0.513866</td>\n",
       "      <td>0.444615</td>\n",
       "      <td>-0.311440</td>\n",
       "      <td>-0.503001</td>\n",
       "      <td>0.379872</td>\n",
       "      <td>-0.301026</td>\n",
       "      <td>0.496942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0eddd8e5</td>\n",
       "      <td>-0.528813</td>\n",
       "      <td>-0.620962</td>\n",
       "      <td>-0.310135</td>\n",
       "      <td>0.170380</td>\n",
       "      <td>-0.074117</td>\n",
       "      <td>0.282184</td>\n",
       "      <td>-0.002533</td>\n",
       "      <td>0.716247</td>\n",
       "      <td>-0.323445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.242430</td>\n",
       "      <td>-0.411412</td>\n",
       "      <td>0.194835</td>\n",
       "      <td>0.513866</td>\n",
       "      <td>0.444615</td>\n",
       "      <td>-0.311440</td>\n",
       "      <td>-0.503001</td>\n",
       "      <td>0.379872</td>\n",
       "      <td>-0.301026</td>\n",
       "      <td>0.496942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a49eda7f</td>\n",
       "      <td>-0.528813</td>\n",
       "      <td>-0.620962</td>\n",
       "      <td>-0.310135</td>\n",
       "      <td>0.170380</td>\n",
       "      <td>-0.074117</td>\n",
       "      <td>0.282184</td>\n",
       "      <td>-0.002533</td>\n",
       "      <td>0.716247</td>\n",
       "      <td>-0.323445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.242430</td>\n",
       "      <td>-0.411412</td>\n",
       "      <td>0.194835</td>\n",
       "      <td>0.513866</td>\n",
       "      <td>0.444615</td>\n",
       "      <td>-0.311440</td>\n",
       "      <td>-0.503001</td>\n",
       "      <td>0.379872</td>\n",
       "      <td>-0.301026</td>\n",
       "      <td>0.496942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fa34f945</td>\n",
       "      <td>-0.528813</td>\n",
       "      <td>-0.620962</td>\n",
       "      <td>-0.310135</td>\n",
       "      <td>0.170380</td>\n",
       "      <td>-0.074117</td>\n",
       "      <td>0.282184</td>\n",
       "      <td>-0.002533</td>\n",
       "      <td>0.716247</td>\n",
       "      <td>-0.323445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.242430</td>\n",
       "      <td>-0.411412</td>\n",
       "      <td>0.194835</td>\n",
       "      <td>0.513866</td>\n",
       "      <td>0.444615</td>\n",
       "      <td>-0.311440</td>\n",
       "      <td>-0.503001</td>\n",
       "      <td>0.379872</td>\n",
       "      <td>-0.301026</td>\n",
       "      <td>0.496942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>526f719b</td>\n",
       "      <td>-0.795240</td>\n",
       "      <td>-0.763393</td>\n",
       "      <td>-0.612789</td>\n",
       "      <td>0.303828</td>\n",
       "      <td>-0.138992</td>\n",
       "      <td>0.497401</td>\n",
       "      <td>0.015070</td>\n",
       "      <td>0.813993</td>\n",
       "      <td>-0.559193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.634892</td>\n",
       "      <td>-0.506309</td>\n",
       "      <td>0.593090</td>\n",
       "      <td>0.685402</td>\n",
       "      <td>0.615198</td>\n",
       "      <td>-0.484400</td>\n",
       "      <td>-0.819888</td>\n",
       "      <td>0.619569</td>\n",
       "      <td>-0.361963</td>\n",
       "      <td>0.804542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>996 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  embedding_0  embedding_1  embedding_2  embedding_3  embedding_4  \\\n",
       "0   23dafdab    -0.528813    -0.620962    -0.310135     0.170380    -0.074117   \n",
       "0   e4614ec6    -0.528813    -0.620962    -0.310135     0.170380    -0.074117   \n",
       "0   56ef356c    -0.762479    -0.732674    -0.558686     0.272567    -0.133033   \n",
       "0   dcfcd574    -0.528813    -0.620962    -0.310135     0.170380    -0.074117   \n",
       "0   338146bd    -0.528813    -0.620962    -0.310135     0.170380    -0.074117   \n",
       "..       ...          ...          ...          ...          ...          ...   \n",
       "0   2a9e0dee    -0.528813    -0.620962    -0.310135     0.170380    -0.074117   \n",
       "0   0eddd8e5    -0.528813    -0.620962    -0.310135     0.170380    -0.074117   \n",
       "0   a49eda7f    -0.528813    -0.620962    -0.310135     0.170380    -0.074117   \n",
       "0   fa34f945    -0.528813    -0.620962    -0.310135     0.170380    -0.074117   \n",
       "0   526f719b    -0.795240    -0.763393    -0.612789     0.303828    -0.138992   \n",
       "\n",
       "    embedding_5  embedding_6  embedding_7  embedding_8  ...  embedding_54  \\\n",
       "0      0.282184    -0.002533     0.716247    -0.323445  ...      0.242430   \n",
       "0      0.282184    -0.002533     0.716247    -0.323445  ...      0.242430   \n",
       "0      0.456527     0.014443     0.803861    -0.518356  ...      0.544268   \n",
       "0      0.282184    -0.002533     0.716247    -0.323445  ...      0.242430   \n",
       "0      0.282184    -0.002533     0.716247    -0.323445  ...      0.242430   \n",
       "..          ...          ...          ...          ...  ...           ...   \n",
       "0      0.282184    -0.002533     0.716247    -0.323445  ...      0.242430   \n",
       "0      0.282184    -0.002533     0.716247    -0.323445  ...      0.242430   \n",
       "0      0.282184    -0.002533     0.716247    -0.323445  ...      0.242430   \n",
       "0      0.282184    -0.002533     0.716247    -0.323445  ...      0.242430   \n",
       "0      0.497401     0.015070     0.813993    -0.559193  ...      0.634892   \n",
       "\n",
       "    embedding_55  embedding_56  embedding_57  embedding_58  embedding_59  \\\n",
       "0      -0.411412      0.194835      0.513866      0.444615     -0.311440   \n",
       "0      -0.411412      0.194835      0.513866      0.444615     -0.311440   \n",
       "0      -0.496551      0.510508      0.658227      0.603788     -0.453413   \n",
       "0      -0.411412      0.194835      0.513866      0.444615     -0.311440   \n",
       "0      -0.411412      0.194835      0.513866      0.444615     -0.311440   \n",
       "..           ...           ...           ...           ...           ...   \n",
       "0      -0.411412      0.194835      0.513866      0.444615     -0.311440   \n",
       "0      -0.411412      0.194835      0.513866      0.444615     -0.311440   \n",
       "0      -0.411412      0.194835      0.513866      0.444615     -0.311440   \n",
       "0      -0.411412      0.194835      0.513866      0.444615     -0.311440   \n",
       "0      -0.506309      0.593090      0.685402      0.615198     -0.484400   \n",
       "\n",
       "    embedding_60  embedding_61  embedding_62  embedding_63  \n",
       "0      -0.503001      0.379872     -0.301026      0.496942  \n",
       "0      -0.503001      0.379872     -0.301026      0.496942  \n",
       "0      -0.780339      0.588516     -0.362753      0.768235  \n",
       "0      -0.503001      0.379872     -0.301026      0.496942  \n",
       "0      -0.503001      0.379872     -0.301026      0.496942  \n",
       "..           ...           ...           ...           ...  \n",
       "0      -0.503001      0.379872     -0.301026      0.496942  \n",
       "0      -0.503001      0.379872     -0.301026      0.496942  \n",
       "0      -0.503001      0.379872     -0.301026      0.496942  \n",
       "0      -0.503001      0.379872     -0.301026      0.496942  \n",
       "0      -0.819888      0.619569     -0.361963      0.804542  \n",
       "\n",
       "[996 rows x 65 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_df_all = None\n",
    "\n",
    "for row in embedding_result:\n",
    "    id_ = row[\"id\"]\n",
    "    embedding = row[\"embedding\"]\n",
    "    embedding_cols = [f\"embedding_{i}\" for i in range(embedding.shape[-1])]\n",
    "    embedding_df = pd.DataFrame(embedding.reshape(1, -1), columns=embedding_cols)\n",
    "    embedding_df[\"id\"] = id_\n",
    "\n",
    "    if embedding_df_all is None:\n",
    "        embedding_df_all = embedding_df\n",
    "    else:\n",
    "        embedding_df_all = pd.concat([embedding_df_all, embedding_df], axis=0)\n",
    "\n",
    "embedding_df_all = embedding_df_all[[\"id\"] + embedding_cols]\n",
    "embedding_df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "\n",
    "\n",
    "def quadratic_weighted_kappa(y_true, y_pred):\n",
    "    return cohen_kappa_score(y_true, y_pred, weights=\"quadratic\")\n",
    "\n",
    "\n",
    "def threshold_Rounder(oof_non_rounded, thresholds):\n",
    "    return np.where(\n",
    "        oof_non_rounded < thresholds[0],\n",
    "        0,\n",
    "        np.where(\n",
    "            oof_non_rounded < thresholds[1],\n",
    "            1,\n",
    "            np.where(oof_non_rounded < thresholds[2], 2, 3),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "def evaluate_predictions(thresholds, y_true, oof_non_rounded):\n",
    "    rounded_p = threshold_Rounder(oof_non_rounded, thresholds)\n",
    "    return -quadratic_weighted_kappa(y_true, rounded_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train[\"sii\"] != -1].reset_index(drop=True)\n",
    "train = train.merge(embedding_df_all, on=\"id\", how=\"left\")\n",
    "train.fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Folds: 100%|██████████| 4/4 [00:03<00:00,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train QWK --> 0.7412\n",
      "CV: 0.3770\n",
      "tuned Kappa: 0.440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy.optimize import minimize\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator, FormatStrFormatter, PercentFormatter\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from keras.models import Model\n",
    "# from keras.layers import Input, Dense\n",
    "# from keras.optimizers import Adam\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from colorama import Fore, Style\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import (\n",
    "    VotingRegressor,\n",
    "    RandomForestRegressor,\n",
    "    GradientBoostingRegressor,\n",
    ")\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "\n",
    "def quadratic_weighted_kappa(y_true, y_pred):\n",
    "    return cohen_kappa_score(y_true, y_pred, weights=\"quadratic\")\n",
    "\n",
    "\n",
    "def threshold_Rounder(oof_non_rounded, thresholds):\n",
    "    return np.where(\n",
    "        oof_non_rounded < thresholds[0],\n",
    "        0,\n",
    "        np.where(\n",
    "            oof_non_rounded < thresholds[1],\n",
    "            1,\n",
    "            np.where(oof_non_rounded < thresholds[2], 2, 3),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "def evaluate_predictions(thresholds, y_true, oof_non_rounded):\n",
    "    rounded_p = threshold_Rounder(oof_non_rounded, thresholds)\n",
    "    return -quadratic_weighted_kappa(y_true, rounded_p)\n",
    "\n",
    "\n",
    "def TrainML(model_class, test_data):\n",
    "    X = train.drop([\"sii\", \"id\"], axis=1)\n",
    "    y = train[\"sii\"]\n",
    "\n",
    "    n_splits = 4\n",
    "    SKF = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    train_S = []\n",
    "    test_S = []\n",
    "\n",
    "    oof_non_rounded = np.zeros(len(y), dtype=float)\n",
    "    oof_rounded = np.zeros(len(y), dtype=int)\n",
    "    test_preds = np.zeros((len(test_data), n_splits))\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(\n",
    "        tqdm(SKF.split(X, y), desc=\"Training Folds\", total=n_splits)\n",
    "    ):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        model = clone(model_class)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_val_pred = model.predict(X_val)\n",
    "\n",
    "        oof_non_rounded[test_idx] = y_val_pred\n",
    "        y_val_pred_rounded = y_val_pred.round(0).astype(int)\n",
    "        oof_rounded[test_idx] = y_val_pred_rounded\n",
    "\n",
    "        train_kappa = quadratic_weighted_kappa(\n",
    "            y_train, y_train_pred.round(0).astype(int)\n",
    "        )\n",
    "        val_kappa = quadratic_weighted_kappa(y_val, y_val_pred_rounded)\n",
    "\n",
    "        train_S.append(train_kappa)\n",
    "        test_S.append(val_kappa)\n",
    "\n",
    "        # test_preds[:, fold] = model.predict(test_data.drop(columns=[\"id\"]))\n",
    "\n",
    "        print(\n",
    "            f\"Fold {fold+1} - Train QWK: {train_kappa:.4f}, Validation QWK: {val_kappa:.4f}\"\n",
    "        )\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        voting_model = model\n",
    "        # modelの保存\n",
    "        with open(f\"./assets/voting_model_{fold}.pkl\", \"wb\") as f:\n",
    "            pickle.dump(voting_model, f)\n",
    "\n",
    "    print(f\"Mean Train QWK --> {np.mean(train_S):.4f}\")\n",
    "    print(f\"CV: {np.mean(test_S):.4f}\")\n",
    "\n",
    "    KappaOPtimizer = minimize(\n",
    "        evaluate_predictions,\n",
    "        x0=[0.5, 1.5, 2.5],\n",
    "        args=(y, oof_non_rounded),\n",
    "        method=\"Nelder-Mead\",\n",
    "    )\n",
    "    assert KappaOPtimizer.success, \"Optimization did not converge.\"\n",
    "\n",
    "    oof_tuned = threshold_Rounder(oof_non_rounded, KappaOPtimizer.x)\n",
    "    tKappa = quadratic_weighted_kappa(y, oof_tuned)\n",
    "\n",
    "    print(f\"tuned Kappa: {tKappa:.3f}\")\n",
    "\n",
    "    # tpm = test_preds.mean(axis=1)\n",
    "    # tpTuned = threshold_Rounder(tpm, KappaOPtimizer.x)\n",
    "\n",
    "\n",
    "# Model parameters for LightGBM\n",
    "Params = {\n",
    "    \"learning_rate\": 0.046,\n",
    "    \"max_depth\": 12,\n",
    "    \"num_leaves\": 478,\n",
    "    \"min_data_in_leaf\": 13,\n",
    "    \"feature_fraction\": 0.893,\n",
    "    \"bagging_fraction\": 0.784,\n",
    "    \"bagging_freq\": 4,\n",
    "    \"lambda_l1\": 10,  # Increased from 6.59\n",
    "    \"lambda_l2\": 0.01,  # Increased from 2.68e-06\n",
    "}\n",
    "\n",
    "\n",
    "# XGBoost parameters\n",
    "XGB_Params = {\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"max_depth\": 6,\n",
    "    \"n_estimators\": 200,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"reg_alpha\": 1,  # Increased from 0.1\n",
    "    \"reg_lambda\": 5,  # Increased from 1\n",
    "    \"random_state\": SEED,\n",
    "}\n",
    "\n",
    "\n",
    "CatBoost_Params = {\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"depth\": 6,\n",
    "    \"iterations\": 200,\n",
    "    \"random_seed\": SEED,\n",
    "    \"verbose\": 0,\n",
    "    \"l2_leaf_reg\": 10,  # Increase this value\n",
    "}\n",
    "\n",
    "# Create model instances\n",
    "Light = LGBMRegressor(**Params, random_state=SEED, verbose=-1, n_estimators=300)\n",
    "XGB_Model = XGBRegressor(**XGB_Params)\n",
    "CatBoost_Model = CatBoostRegressor(**CatBoost_Params)\n",
    "\n",
    "# Combine models using Voting Regressor\n",
    "voting_model = VotingRegressor(\n",
    "    estimators=[\n",
    "        (\"lightgbm\", Light),\n",
    "        (\"xgboost\", XGB_Model),\n",
    "        (\"catboost\", CatBoost_Model),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Train the ensemble model\n",
    "TrainML(voting_model, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
