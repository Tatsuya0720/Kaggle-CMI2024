{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from src.dataloader_ import *\n",
    "from src.network_ import *\n",
    "from src.utils import *\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "\n",
    "train_series_dir = \"../../inputs/series_train.parquet/\"\n",
    "test_series_dir = \"../../inputs/series_test.parquet/\"\n",
    "\n",
    "data_dic_path = \"../../inputs/data_dictionary.csv\"\n",
    "sample_submission_path = \"../../inputs/sample_submission.csv\"\n",
    "train_path = \"../../inputs/train.csv\"\n",
    "test_path = \"../../inputs/test.csv\"\n",
    "\n",
    "train = pd.read_csv(train_path)\n",
    "test = pd.read_csv(test_path)\n",
    "sample_submission = pd.read_csv(sample_submission_path)\n",
    "data_dic = pd.read_csv(data_dic_path)\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def seed_torch(seed=1029):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "nb_name = os.path.basename(os.getcwd())  # notebook name\n",
    "seed_torch(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 24, 60, 15) (31, 24, 60, 15)\n",
      "(31, 24, 15) (31, 24, 15) (31, 24, 30)\n",
      "(744, 30)\n",
      "torch.Size([1, 744, 30])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def read_parquet(base_dir, id_):\n",
    "    path = os.path.join(base_dir, f\"id={id_}\", \"part-0.parquet\")\n",
    "    return pd.read_parquet(path)\n",
    "\n",
    "\n",
    "def get_valid_ids(base_dir):\n",
    "    return [f.split(\"=\")[1].split(\".\")[0] for f in os.listdir(base_dir)]\n",
    "\n",
    "\n",
    "p = read_parquet(base_dir=\"../../inputs/series_train.parquet/\", id_=\"ffcd4dbd\")\n",
    "# p = read_parquet(base_dir=\"../../inputs/series_train.parquet/\", id_=\"10e46254\")\n",
    "\n",
    "scale_columns = [\n",
    "    \"X\",\n",
    "    \"Y\",\n",
    "    \"Z\",\n",
    "    \"enmo\",\n",
    "    \"anglez\",\n",
    "    \"light\",\n",
    "    \"battery_voltage\",\n",
    "]\n",
    "\n",
    "masked_columns = [\n",
    "    \"masked_X\",\n",
    "    \"masked_Y\",\n",
    "    \"masked_Z\",\n",
    "    \"masked_enmo\",\n",
    "    \"masked_anglez\",\n",
    "    \"masked_light\",\n",
    "]\n",
    "\n",
    "original_columns = [\"battery_voltage\", \"non-wear_flag\"]\n",
    "\n",
    "p[\"non-wear_flag\"] = 1 - p[\"non-wear_flag\"]\n",
    "scaler_features = p[scale_columns].values\n",
    "scaler = StandardScaler()\n",
    "p[scale_columns] = scaler.fit_transform(scaler_features)\n",
    "\n",
    "for mask_col in masked_columns:\n",
    "    p[mask_col] = p[mask_col.replace(\"masked_\", \"\")] * p[\"non-wear_flag\"]\n",
    "\n",
    "p = p.fillna(0.0)\n",
    "\n",
    "groups = p.groupby(\"relative_date_PCIAT\")\n",
    "# グループごとにデータフレームのリストに分割\n",
    "chunks = [group.reset_index(drop=True) for _, group in groups]\n",
    "\n",
    "use_cols = masked_columns + original_columns + scale_columns\n",
    "watch_day = len(chunks)\n",
    "active_logs = np.zeros((31, 17280, len(use_cols)), dtype=np.float32)\n",
    "active_mask = np.zeros((31), dtype=np.int32)\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    if i == 0:  #\n",
    "        active_logs[i, -len(chunk) :, :] = chunk[use_cols].values\n",
    "    elif i == watch_day:\n",
    "        active_logs[i, : len(chunk), :] = chunk[use_cols].values\n",
    "    else:\n",
    "        array = chunk[use_cols].values\n",
    "        active_logs[i, : len(array), :] = array\n",
    "\n",
    "    active_mask[i] = 1\n",
    "\n",
    "    if i == 30:\n",
    "        break\n",
    "\n",
    "active_logs = active_logs.reshape(31, 24, 60, 12, 15)  # 12は1時間の分割数\n",
    "active_logs_mean = active_logs.mean(axis=3)  # 1時間の分割数で平均を取る # 31, 1440, 15\n",
    "# active_logs_var = active_logs.var(axis=3)  # 1時間の分割数で分散を取る # 31, 1440, 15\n",
    "active_logs = np.concatenate([active_logs_mean], axis=-1)  # (31, 24, 30)\n",
    "# print(active_logs_mean.shape, active_logs_var.shape, active_logs.shape)\n",
    "\n",
    "print(active_logs_mean.shape, active_logs.shape)\n",
    "\n",
    "active_logs_mean = active_logs.mean(axis=2)  # 1時間の分割数で平均を取る # 31, 1440, 15\n",
    "active_logs_var = active_logs.var(axis=2)  # 1時間の分割数で分散を取る # 31, 1440, 15\n",
    "active_logs = np.concatenate(\n",
    "    [active_logs_mean, active_logs_var], axis=-1\n",
    ")  # (31, 24, 30)\n",
    "print(active_logs_mean.shape, active_logs_var.shape, active_logs.shape)\n",
    "active_logs = active_logs.reshape(-1, 30)\n",
    "print(active_logs.shape)\n",
    "\n",
    "# active_logs = active_logs.unsqueeze(0)\n",
    "active_logs = torch.tensor(active_logs, dtype=torch.float32).unsqueeze(0).to(\"cuda\")\n",
    "print(active_logs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 744, 30]) torch.Size([1, 64])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class TransformerAutoEncoder(nn.Module):\n",
    "    def __init__(self, d_model=64, nhead=4, num_layers=2):\n",
    "        super(TransformerAutoEncoder, self).__init__()\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead)\n",
    "        self.encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "        self.decoder_layer = nn.TransformerDecoderLayer(d_model=d_model, nhead=nhead)\n",
    "        self.decoder = nn.TransformerDecoder(self.decoder_layer, num_layers=num_layers)\n",
    "        self.embedding = nn.Linear(30, d_model)\n",
    "        self.output_layer = nn.Linear(d_model, 30)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  # (batch, day*time, d_model)\n",
    "        encoded = self.encoder(x.permute(1, 0, 2))  # (day*time, batch, d_model)\n",
    "        decoded = self.decoder(encoded, encoded)  # (day*time, batch, d_model)\n",
    "        return (\n",
    "            self.output_layer(decoded.permute(1, 0, 2)),\n",
    "            encoded.permute(1, 0, 2),\n",
    "        )  # (batch, day*time, hidden)\n",
    "\n",
    "\n",
    "# Example\n",
    "model = TransformerAutoEncoder().to(\"cuda\")\n",
    "input_data = torch.randn(1, 744, 30).to(\"cuda\")\n",
    "output = model(input_data)\n",
    "print(output[0].shape, torch.mean(output[1], dim=1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各モデルのインスタンス化\n",
    "# transformer_model = TransformerAutoEncoder()\n",
    "\n",
    "# # 正規分布からランダムに(1, 31, 17280, 15)の形状でデータを生成\n",
    "# input_data = torch.randn(1, 31, 17280, 15)\n",
    "\n",
    "# # 各モデルにデータを入力し、出力形状を確認\n",
    "# print(\"Input shape:\", input_data.shape)\n",
    "\n",
    "# # Transformerモデル\n",
    "# transformer_output = transformer_model(input_data)\n",
    "# print(\"Transformer Model output shape:\", transformer_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Basic_Demos-Enroll_Season</th>\n",
       "      <th>Basic_Demos-Age</th>\n",
       "      <th>Basic_Demos-Sex</th>\n",
       "      <th>CGAS-Season</th>\n",
       "      <th>CGAS-CGAS_Score</th>\n",
       "      <th>Physical-Season</th>\n",
       "      <th>Physical-BMI</th>\n",
       "      <th>Physical-Height</th>\n",
       "      <th>Physical-Weight</th>\n",
       "      <th>...</th>\n",
       "      <th>PCIAT-PCIAT_18</th>\n",
       "      <th>PCIAT-PCIAT_19</th>\n",
       "      <th>PCIAT-PCIAT_20</th>\n",
       "      <th>PCIAT-PCIAT_Total</th>\n",
       "      <th>SDS-Season</th>\n",
       "      <th>SDS-SDS_Total_Raw</th>\n",
       "      <th>SDS-SDS_Total_T</th>\n",
       "      <th>PreInt_EduHx-Season</th>\n",
       "      <th>PreInt_EduHx-computerinternet_hoursday</th>\n",
       "      <th>sii</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00008ff9</td>\n",
       "      <td>Fall</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>16.877316</td>\n",
       "      <td>46.0</td>\n",
       "      <td>50.8</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fall</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fd460</td>\n",
       "      <td>Summer</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fall</td>\n",
       "      <td>14.035590</td>\n",
       "      <td>48.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>46.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Summer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00105258</td>\n",
       "      <td>Summer</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Fall</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>16.648696</td>\n",
       "      <td>56.5</td>\n",
       "      <td>75.6</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>38.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00115b9f</td>\n",
       "      <td>Winter</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Summer</td>\n",
       "      <td>18.292347</td>\n",
       "      <td>56.0</td>\n",
       "      <td>81.6</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Summer</td>\n",
       "      <td>31.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0016bb22</td>\n",
       "      <td>Spring</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>Summer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3955</th>\n",
       "      <td>ff8a2de4</td>\n",
       "      <td>Fall</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>Spring</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>16.362460</td>\n",
       "      <td>59.5</td>\n",
       "      <td>82.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>35.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3956</th>\n",
       "      <td>ffa9794a</td>\n",
       "      <td>Winter</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spring</td>\n",
       "      <td>18.764678</td>\n",
       "      <td>53.5</td>\n",
       "      <td>76.4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Winter</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3957</th>\n",
       "      <td>ffcd4dbd</td>\n",
       "      <td>Fall</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>Spring</td>\n",
       "      <td>68.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>21.441500</td>\n",
       "      <td>60.0</td>\n",
       "      <td>109.8</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>56.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3958</th>\n",
       "      <td>ffed1dd5</td>\n",
       "      <td>Spring</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>Spring</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>12.235895</td>\n",
       "      <td>70.7</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Spring</td>\n",
       "      <td>33.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>Spring</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3959</th>\n",
       "      <td>ffef538e</td>\n",
       "      <td>Spring</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Winter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spring</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3960 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id Basic_Demos-Enroll_Season  Basic_Demos-Age  Basic_Demos-Sex  \\\n",
       "0     00008ff9                      Fall                5                0   \n",
       "1     000fd460                    Summer                9                0   \n",
       "2     00105258                    Summer               10                1   \n",
       "3     00115b9f                    Winter                9                0   \n",
       "4     0016bb22                    Spring               18                1   \n",
       "...        ...                       ...              ...              ...   \n",
       "3955  ff8a2de4                      Fall               13                0   \n",
       "3956  ffa9794a                    Winter               10                0   \n",
       "3957  ffcd4dbd                      Fall               11                0   \n",
       "3958  ffed1dd5                    Spring               13                0   \n",
       "3959  ffef538e                    Spring               11                0   \n",
       "\n",
       "     CGAS-Season  CGAS-CGAS_Score Physical-Season  Physical-BMI  \\\n",
       "0         Winter             51.0            Fall     16.877316   \n",
       "1            NaN              NaN            Fall     14.035590   \n",
       "2           Fall             71.0            Fall     16.648696   \n",
       "3           Fall             71.0          Summer     18.292347   \n",
       "4         Summer              NaN             NaN           NaN   \n",
       "...          ...              ...             ...           ...   \n",
       "3955      Spring             60.0            Fall     16.362460   \n",
       "3956         NaN              NaN          Spring     18.764678   \n",
       "3957      Spring             68.0          Winter     21.441500   \n",
       "3958      Spring             70.0          Winter     12.235895   \n",
       "3959         NaN              NaN          Winter           NaN   \n",
       "\n",
       "      Physical-Height  Physical-Weight  ...  PCIAT-PCIAT_18  PCIAT-PCIAT_19  \\\n",
       "0                46.0             50.8  ...             4.0             2.0   \n",
       "1                48.0             46.0  ...             0.0             0.0   \n",
       "2                56.5             75.6  ...             2.0             1.0   \n",
       "3                56.0             81.6  ...             3.0             4.0   \n",
       "4                 NaN              NaN  ...             NaN             NaN   \n",
       "...               ...              ...  ...             ...             ...   \n",
       "3955             59.5             82.4  ...             1.0             1.0   \n",
       "3956             53.5             76.4  ...             NaN             NaN   \n",
       "3957             60.0            109.8  ...             1.0             0.0   \n",
       "3958             70.7             87.0  ...             1.0             1.0   \n",
       "3959              NaN              NaN  ...             NaN             NaN   \n",
       "\n",
       "      PCIAT-PCIAT_20  PCIAT-PCIAT_Total SDS-Season  SDS-SDS_Total_Raw  \\\n",
       "0                4.0               55.0        NaN                NaN   \n",
       "1                0.0                0.0       Fall               46.0   \n",
       "2                1.0               28.0       Fall               38.0   \n",
       "3                1.0               44.0     Summer               31.0   \n",
       "4                NaN                NaN        NaN                NaN   \n",
       "...              ...                ...        ...                ...   \n",
       "3955             0.0               32.0     Winter               35.0   \n",
       "3956             NaN                NaN        NaN                NaN   \n",
       "3957             1.0               31.0     Winter               56.0   \n",
       "3958             1.0               19.0     Spring               33.0   \n",
       "3959             NaN                NaN        NaN                NaN   \n",
       "\n",
       "      SDS-SDS_Total_T  PreInt_EduHx-Season  \\\n",
       "0                 NaN                 Fall   \n",
       "1                64.0               Summer   \n",
       "2                54.0               Summer   \n",
       "3                45.0               Winter   \n",
       "4                 NaN                  NaN   \n",
       "...               ...                  ...   \n",
       "3955             50.0                 Fall   \n",
       "3956              NaN               Winter   \n",
       "3957             77.0                 Fall   \n",
       "3958             47.0               Spring   \n",
       "3959              NaN               Spring   \n",
       "\n",
       "     PreInt_EduHx-computerinternet_hoursday  sii  \n",
       "0                                       3.0  2.0  \n",
       "1                                       0.0  0.0  \n",
       "2                                       2.0  0.0  \n",
       "3                                       0.0  1.0  \n",
       "4                                       NaN  NaN  \n",
       "...                                     ...  ...  \n",
       "3955                                    1.0  1.0  \n",
       "3956                                    0.0  NaN  \n",
       "3957                                    0.0  1.0  \n",
       "3958                                    1.0  0.0  \n",
       "3959                                    1.0  NaN  \n",
       "\n",
       "[3960 rows x 82 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テーブルデータセット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_features = [\n",
    "    \"BMI_Age\",\n",
    "    \"Internet_Hours_Age\",\n",
    "    \"BMI_Internet_Hours\",\n",
    "    \"BFP_BMI\",\n",
    "    \"FFMI_BFP\",\n",
    "    \"FMI_BFP\",\n",
    "    \"LST_TBW\",\n",
    "    \"BFP_BMR\",\n",
    "    \"BFP_DEE\",\n",
    "    \"BMR_Weight\",\n",
    "    \"DEE_Weight\",\n",
    "    \"SMM_Height\",\n",
    "    \"Muscle_to_Fat\",\n",
    "    \"Hydration_Status\",\n",
    "    \"ICW_TBW\",\n",
    "]\n",
    "\n",
    "\n",
    "def feature_engineering(df):\n",
    "    # season_cols = [col for col in df.columns if \"Season\" in col]\n",
    "    # df = df.drop(season_cols, axis=1)\n",
    "    df[\"BMI_Age\"] = df[\"Physical-BMI\"] * df[\"Basic_Demos-Age\"]\n",
    "    df[\"Internet_Hours_Age\"] = (\n",
    "        df[\"PreInt_EduHx-computerinternet_hoursday\"] * df[\"Basic_Demos-Age\"]\n",
    "    )\n",
    "    df[\"BMI_Internet_Hours\"] = (\n",
    "        df[\"Physical-BMI\"] * df[\"PreInt_EduHx-computerinternet_hoursday\"]\n",
    "    )\n",
    "    df[\"BFP_BMI\"] = df[\"BIA-BIA_Fat\"] / df[\"BIA-BIA_BMI\"]\n",
    "    df[\"FFMI_BFP\"] = df[\"BIA-BIA_FFMI\"] / df[\"BIA-BIA_Fat\"]\n",
    "    df[\"FMI_BFP\"] = df[\"BIA-BIA_FMI\"] / df[\"BIA-BIA_Fat\"]\n",
    "    df[\"LST_TBW\"] = df[\"BIA-BIA_LST\"] / df[\"BIA-BIA_TBW\"]\n",
    "    df[\"BFP_BMR\"] = df[\"BIA-BIA_Fat\"] * df[\"BIA-BIA_BMR\"]\n",
    "    df[\"BFP_DEE\"] = df[\"BIA-BIA_Fat\"] * df[\"BIA-BIA_DEE\"]\n",
    "    df[\"BMR_Weight\"] = df[\"BIA-BIA_BMR\"] / df[\"Physical-Weight\"]\n",
    "    df[\"DEE_Weight\"] = df[\"BIA-BIA_DEE\"] / df[\"Physical-Weight\"]\n",
    "    df[\"SMM_Height\"] = df[\"BIA-BIA_SMM\"] / df[\"Physical-Height\"]\n",
    "    df[\"Muscle_to_Fat\"] = df[\"BIA-BIA_SMM\"] / df[\"BIA-BIA_FMI\"]\n",
    "    df[\"Hydration_Status\"] = df[\"BIA-BIA_TBW\"] / df[\"Physical-Weight\"]\n",
    "    df[\"ICW_TBW\"] = df[\"BIA-BIA_ICW\"] / df[\"BIA-BIA_TBW\"]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "train = feature_engineering(train)\n",
    "train = train.replace([np.inf, -np.inf], np.nan)\n",
    "for add_ in add_features:\n",
    "    train[add_] = train[add_].fillna(0.0)\n",
    "train = train.dropna(thresh=10, axis=0)\n",
    "\n",
    "test = feature_engineering(test)\n",
    "test = test.replace([np.inf, -np.inf], np.nan)\n",
    "for add_ in add_features:\n",
    "    test[add_] = test[add_].fillna(0.0)\n",
    "test = test.dropna(thresh=10, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create new scaler\n"
     ]
    }
   ],
   "source": [
    "# onehotEncoderの作成\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "double_columns = [\n",
    "    \"FGC-FGC_SRR_Zone\",\n",
    "    \"BIA-BIA_SMM\",\n",
    "    \"Physical-Waist_Circumference\",\n",
    "    \"BIA-BIA_FFMI\",\n",
    "    \"FGC-FGC_CU\",\n",
    "    \"PreInt_EduHx-computerinternet_hoursday\",\n",
    "    \"BIA-BIA_ECW\",\n",
    "    \"FGC-FGC_CU_Zone\",\n",
    "    \"FGC-FGC_SRL_Zone\",\n",
    "    \"BIA-BIA_DEE\",\n",
    "    \"Physical-Weight\",\n",
    "    \"Fitness_Endurance-Time_Mins\",\n",
    "    \"FGC-FGC_SRR\",\n",
    "    \"SDS-SDS_Total_T\",\n",
    "    \"FGC-FGC_PU\",\n",
    "    \"BIA-BIA_FFM\",\n",
    "    \"FGC-FGC_TL_Zone\",\n",
    "    \"Physical-BMI\",\n",
    "    \"Physical-Systolic_BP\",\n",
    "    \"Physical-HeartRate\",\n",
    "    \"BIA-BIA_ICW\",\n",
    "    \"Physical-Height\",\n",
    "    \"FGC-FGC_SRL\",\n",
    "    \"BIA-BIA_BMC\",\n",
    "    \"Fitness_Endurance-Time_Sec\",\n",
    "    \"BIA-BIA_Frame_num\",\n",
    "    \"Basic_Demos-Age\",\n",
    "    \"FGC-FGC_GSND_Zone\",\n",
    "    \"Basic_Demos-Sex\",\n",
    "    \"FGC-FGC_GSND\",\n",
    "    \"BIA-BIA_LST\",\n",
    "    \"FGC-FGC_TL\",\n",
    "    \"BIA-BIA_BMI\",\n",
    "    \"BIA-BIA_FMI\",\n",
    "    \"PAQ_C-PAQ_C_Total\",\n",
    "    \"BIA-BIA_Activity_Level_num\",\n",
    "    \"FGC-FGC_GSD\",\n",
    "    \"BIA-BIA_BMR\",\n",
    "    \"BIA-BIA_Fat\",\n",
    "    \"SDS-SDS_Total_Raw\",\n",
    "    \"CGAS-CGAS_Score\",\n",
    "    \"FGC-FGC_PU_Zone\",\n",
    "    \"BIA-BIA_LDM\",\n",
    "    \"Fitness_Endurance-Max_Stage\",\n",
    "    \"PAQ_A-PAQ_A_Total\",\n",
    "    \"BIA-BIA_TBW\",\n",
    "    \"FGC-FGC_GSD_Zone\",\n",
    "    \"Physical-Diastolic_BP\",\n",
    "]\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def create_dataset_(df, scaler=None, train=True):\n",
    "\n",
    "    if scaler is None:\n",
    "        print(\"create new scaler\")\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(df[double_columns + add_features])\n",
    "        with open(\"./assets/scaler.pkl\", \"wb\") as f:\n",
    "            pickle.dump(scaler, f)\n",
    "\n",
    "    double_feature = scaler.transform(df[double_columns + add_features])\n",
    "    # 欠損値の補完\n",
    "    double_feature = np.nan_to_num(double_feature)\n",
    "\n",
    "    ids = df[\"id\"].values.reshape(-1, 1)\n",
    "    X = double_feature\n",
    "\n",
    "    # DataFrameの作成\n",
    "    ids_df = pd.DataFrame(ids, columns=[\"id\"])\n",
    "    X_df = pd.DataFrame(X, columns=[f\"feature_{i}\" for i in range(X.shape[1])])\n",
    "\n",
    "    if train:\n",
    "        y = df[\"sii\"].fillna(-1).values.reshape(-1, 1)\n",
    "        y_df = pd.DataFrame(y, columns=[\"sii\"])\n",
    "        df = pd.concat([ids_df, X_df, y_df], axis=1)\n",
    "    else:\n",
    "        df = pd.concat([ids_df, X_df], axis=1)\n",
    "    return df, scaler\n",
    "\n",
    "\n",
    "train, scaler = create_dataset_(train)\n",
    "test = create_dataset_(test, scaler=scaler, train=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_55</th>\n",
       "      <th>feature_56</th>\n",
       "      <th>feature_57</th>\n",
       "      <th>feature_58</th>\n",
       "      <th>feature_59</th>\n",
       "      <th>feature_60</th>\n",
       "      <th>feature_61</th>\n",
       "      <th>feature_62</th>\n",
       "      <th>id</th>\n",
       "      <th>sii</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.277596</td>\n",
       "      <td>-0.176702</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.209436</td>\n",
       "      <td>-0.953788</td>\n",
       "      <td>1.771623</td>\n",
       "      <td>-0.171600</td>\n",
       "      <td>-0.953742</td>\n",
       "      <td>-1.274301</td>\n",
       "      <td>-0.201970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015691</td>\n",
       "      <td>0.015630</td>\n",
       "      <td>0.531031</td>\n",
       "      <td>0.540327</td>\n",
       "      <td>0.113954</td>\n",
       "      <td>0.083339</td>\n",
       "      <td>0.251650</td>\n",
       "      <td>1.296492</td>\n",
       "      <td>00008ff9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.782720</td>\n",
       "      <td>-0.225858</td>\n",
       "      <td>-0.948658</td>\n",
       "      <td>-0.380787</td>\n",
       "      <td>-0.699663</td>\n",
       "      <td>-0.968830</td>\n",
       "      <td>-0.202128</td>\n",
       "      <td>-0.953742</td>\n",
       "      <td>0.784744</td>\n",
       "      <td>-0.199625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015270</td>\n",
       "      <td>0.015181</td>\n",
       "      <td>0.629987</td>\n",
       "      <td>0.643793</td>\n",
       "      <td>0.021863</td>\n",
       "      <td>0.304658</td>\n",
       "      <td>0.209698</td>\n",
       "      <td>1.388511</td>\n",
       "      <td>000fd460</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.782720</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.740376</td>\n",
       "      <td>0.858138</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.048502</td>\n",
       "      <td>0.784744</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014948</td>\n",
       "      <td>0.014837</td>\n",
       "      <td>-0.374560</td>\n",
       "      <td>-0.406553</td>\n",
       "      <td>-0.263102</td>\n",
       "      <td>-0.139659</td>\n",
       "      <td>-0.235959</td>\n",
       "      <td>-0.993169</td>\n",
       "      <td>00105258</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.277596</td>\n",
       "      <td>-0.094130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.165178</td>\n",
       "      <td>0.570959</td>\n",
       "      <td>-0.968830</td>\n",
       "      <td>-0.071440</td>\n",
       "      <td>1.048502</td>\n",
       "      <td>-1.274301</td>\n",
       "      <td>-0.049816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016791</td>\n",
       "      <td>0.016926</td>\n",
       "      <td>0.309486</td>\n",
       "      <td>0.353385</td>\n",
       "      <td>0.156596</td>\n",
       "      <td>0.079541</td>\n",
       "      <td>0.191155</td>\n",
       "      <td>1.031686</td>\n",
       "      <td>00115b9f</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014948</td>\n",
       "      <td>0.014837</td>\n",
       "      <td>-0.374560</td>\n",
       "      <td>-0.406553</td>\n",
       "      <td>-0.263102</td>\n",
       "      <td>-0.139659</td>\n",
       "      <td>-0.235959</td>\n",
       "      <td>-0.993169</td>\n",
       "      <td>0016bb22</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0  -1.277596  -0.176702   0.000000  -0.209436  -0.953788   1.771623   \n",
       "1   0.782720  -0.225858  -0.948658  -0.380787  -0.699663  -0.968830   \n",
       "2   0.782720   0.000000   0.000000   0.000000   0.740376   0.858138   \n",
       "3  -1.277596  -0.094130   0.000000  -0.165178   0.570959  -0.968830   \n",
       "4   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "\n",
       "   feature_6  feature_7  feature_8  feature_9  ...  feature_55  feature_56  \\\n",
       "0  -0.171600  -0.953742  -1.274301  -0.201970  ...    0.015691    0.015630   \n",
       "1  -0.202128  -0.953742   0.784744  -0.199625  ...    0.015270    0.015181   \n",
       "2   0.000000   1.048502   0.784744   0.000000  ...    0.014948    0.014837   \n",
       "3  -0.071440   1.048502  -1.274301  -0.049816  ...    0.016791    0.016926   \n",
       "4   0.000000   0.000000   0.000000   0.000000  ...    0.014948    0.014837   \n",
       "\n",
       "   feature_57  feature_58  feature_59  feature_60  feature_61  feature_62  \\\n",
       "0    0.531031    0.540327    0.113954    0.083339    0.251650    1.296492   \n",
       "1    0.629987    0.643793    0.021863    0.304658    0.209698    1.388511   \n",
       "2   -0.374560   -0.406553   -0.263102   -0.139659   -0.235959   -0.993169   \n",
       "3    0.309486    0.353385    0.156596    0.079541    0.191155    1.031686   \n",
       "4   -0.374560   -0.406553   -0.263102   -0.139659   -0.235959   -0.993169   \n",
       "\n",
       "         id  sii  \n",
       "0  00008ff9  2.0  \n",
       "1  000fd460  0.0  \n",
       "2  00105258  0.0  \n",
       "3  00115b9f  1.0  \n",
       "4  0016bb22 -1.0  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imputer = KNNImputer(n_neighbors=5)\n",
    "sii_imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "numeric_cols = test.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
    "numeric_feature_cols = numeric_cols.copy()\n",
    "# numeric_feature_cols = numeric_feature_cols.drop(\"sii\")\n",
    "\n",
    "numeric_sii_cols = train.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
    "\n",
    "sii_inputed = sii_imputer.fit_transform(train[numeric_sii_cols])\n",
    "feature_imputer.fit(test[numeric_feature_cols])\n",
    "feature_inputed = feature_imputer.fit_transform(train[numeric_feature_cols])\n",
    "\n",
    "train_imputed = pd.DataFrame(feature_inputed, columns=numeric_feature_cols)\n",
    "\n",
    "for col in train.columns:\n",
    "    if col not in numeric_cols:\n",
    "        train_imputed[col] = train[col]\n",
    "\n",
    "train_imputed[\"sii\"] = train[\"sii\"]\n",
    "train = train_imputed\n",
    "\n",
    "# train = train[train[\"sii\"] > -1].reset_index(drop=True)\n",
    "train = train[train[\"sii\"].notnull()].reset_index(drop=True)\n",
    "\n",
    "# sii_impute = pd.DataFrame(sii_inputed, columns=numeric_sii_cols)\n",
    "# sii_impute[\"sii\"] = sii_impute[\"sii\"].round().astype(int)\n",
    "# train[\"sii\"] = sii_impute[\"sii\"]\n",
    "\n",
    "with open(\"feature_imputer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(feature_imputer, f)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 996/996 [02:24<00:00,  6.90it/s, loss=0.665]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 0.6650273665574465\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 996/996 [02:27<00:00,  6.77it/s, loss=0.544]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.5440596200835325\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 996/996 [02:23<00:00,  6.93it/s, loss=0.477]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 0.47686209048055367\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 996/996 [02:18<00:00,  7.19it/s, loss=0.425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 0.42491140063017324\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 996/996 [02:05<00:00,  7.92it/s, loss=0.383]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 0.3834669724003187\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 996/996 [02:05<00:00,  7.91it/s, loss=0.35] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 0.3501966703706456\n",
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 996/996 [02:14<00:00,  7.43it/s, loss=0.321]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 0.32088588900516485\n",
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 996/996 [02:06<00:00,  7.86it/s, loss=0.297] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Loss: 0.29652277850630393\n",
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 996/996 [02:04<00:00,  7.97it/s, loss=0.274]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Loss: 0.27434497606634933\n",
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 996/996 [02:24<00:00,  6.89it/s, loss=0.256]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Loss: 0.2559293524754172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class CMIDataset(Dataset):\n",
    "    def __init__(self, table_df, valid_ids, base_dir, save_filename):\n",
    "        self.base_dir = base_dir\n",
    "        self.table_df = table_df\n",
    "        self.valid_ids = valid_ids\n",
    "        self.save_filename = save_filename\n",
    "        self.scale_columns = [\n",
    "            \"X\",\n",
    "            \"Y\",\n",
    "            \"Z\",\n",
    "            \"enmo\",\n",
    "            \"anglez\",\n",
    "            \"light\",\n",
    "            \"battery_voltage\",\n",
    "        ]\n",
    "\n",
    "        self.masked_columns = [\n",
    "            \"masked_X\",\n",
    "            \"masked_Y\",\n",
    "            \"masked_Z\",\n",
    "            \"masked_enmo\",\n",
    "            \"masked_anglez\",\n",
    "            \"masked_light\",\n",
    "        ]\n",
    "\n",
    "        self.original_columns = [\"battery_voltage\", \"non-wear_flag\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # テーブルデータの抽出\n",
    "        id_ = self.valid_ids[idx]\n",
    "\n",
    "        save_dir = f\"/home/tatsuya/code/projects/kaggle/ChildMindInstitute2024/precreated_dataset/{self.save_filename}/\"\n",
    "        save_path = os.path.join(save_dir, id_)\n",
    "\n",
    "        table = self.table_df.loc[self.table_df[\"id\"] == self.valid_ids[idx], :]\n",
    "        table_feature = table.drop(columns=[\"id\", \"sii\"]).values\n",
    "        sii = table[\"sii\"].values\n",
    "\n",
    "        # 時系列データの抽出\n",
    "        use_cols = self.masked_columns + self.original_columns + self.scale_columns\n",
    "        p = read_parquet(self.base_dir, self.valid_ids[idx])\n",
    "\n",
    "        if p is not None:\n",
    "            p[\"non-wear_flag\"] = 1 - p[\"non-wear_flag\"]\n",
    "            scaler_features = p[scale_columns].values\n",
    "            scaler = StandardScaler()\n",
    "            p[scale_columns] = scaler.fit_transform(scaler_features)\n",
    "\n",
    "            for mask_col in masked_columns:\n",
    "                p[mask_col] = p[mask_col.replace(\"masked_\", \"\")] * p[\"non-wear_flag\"]\n",
    "\n",
    "            p = p.fillna(0.0)\n",
    "\n",
    "            groups = p.groupby(\"relative_date_PCIAT\")\n",
    "            # グループごとにデータフレームのリストに分割\n",
    "            chunks = [group.reset_index(drop=True) for _, group in groups]\n",
    "\n",
    "            use_cols = masked_columns + original_columns + scale_columns\n",
    "            watch_day = len(chunks)\n",
    "            active_logs = np.zeros((31, 17280, len(use_cols)), dtype=np.float32)\n",
    "            active_mask = np.zeros((31), dtype=np.int32)\n",
    "\n",
    "            for i, chunk in enumerate(chunks):\n",
    "                if i == 0:  #\n",
    "                    active_logs[i, -len(chunk) :, :] = chunk[use_cols].values\n",
    "                elif i == watch_day:\n",
    "                    active_logs[i, : len(chunk), :] = chunk[use_cols].values\n",
    "                else:\n",
    "                    array = chunk[use_cols].values\n",
    "                    active_logs[i, : len(array), :] = array\n",
    "\n",
    "                active_mask[i] = 1\n",
    "\n",
    "                if i == 30:\n",
    "                    break\n",
    "\n",
    "            active_logs = active_logs.reshape(31, 24, 60, 12, 15)  # 12は1時間の分割数\n",
    "            active_logs_mean = active_logs.mean(\n",
    "                axis=3\n",
    "            )  # 1時間の分割数で平均を取る # 31, 1440, 15\n",
    "            # active_logs_var = active_logs.var(axis=3)  # 1時間の分割数で分散を取る # 31, 1440, 15\n",
    "            active_logs = np.concatenate([active_logs_mean], axis=-1)  # (31, 24, 30)\n",
    "            # print(active_logs_mean.shape, active_logs_var.shape, active_logs.shape)\n",
    "\n",
    "            # print(active_logs_mean.shape, active_logs.shape)\n",
    "\n",
    "            active_logs_mean = active_logs.mean(\n",
    "                axis=2\n",
    "            )  # 1時間の分割数で平均を取る # 31, 1440, 15\n",
    "            active_logs_var = active_logs.var(\n",
    "                axis=2\n",
    "            )  # 1時間の分割数で分散を取る # 31, 1440, 15\n",
    "            active_logs = np.concatenate(\n",
    "                [active_logs_mean, active_logs_var], axis=-1\n",
    "            )  # (31, 24, 30)\n",
    "            # print(active_logs_mean.shape, active_logs_var.shape, active_logs.shape)\n",
    "            active_logs = active_logs.reshape(-1, 30)\n",
    "\n",
    "        else:\n",
    "            active_logs = np.zeros((744, 30), dtype=np.float32)\n",
    "            active_mask = np.zeros((744), dtype=np.int32)\n",
    "\n",
    "        dataset_ = {\n",
    "            \"id\": id_,\n",
    "            \"table_input\": torch.tensor(table_feature, dtype=torch.float32),\n",
    "            \"time_input\": torch.tensor(active_logs, dtype=torch.float32),\n",
    "            \"mask\": torch.tensor(active_mask, dtype=torch.int32),\n",
    "            \"output\": torch.tensor(sii, dtype=torch.float32),\n",
    "        }\n",
    "\n",
    "        return dataset_\n",
    "\n",
    "\n",
    "def read_parquet(base_dir, id_):\n",
    "    path = os.path.join(base_dir, f\"id={id_}\", \"part-0.parquet\")\n",
    "    if not os.path.exists(path):\n",
    "        return None\n",
    "    return pd.read_parquet(path)\n",
    "\n",
    "\n",
    "dataset = CMIDataset(\n",
    "    table_df=train,\n",
    "    valid_ids=get_valid_ids(train_series_dir),\n",
    "    base_dir=train_series_dir,\n",
    "    save_filename=\"train\",\n",
    ")\n",
    "\n",
    "# AutoEncoderのモデルのインスタンス化\n",
    "transformer_model = TransformerAutoEncoder().to(\"cuda\")\n",
    "# transformer_model.load_state_dict(torch.load(\"./assets/transformer_autoencoder.pth\"))\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(transformer_model.parameters(), lr=0.0001)\n",
    "# データセットからデータを取り出す\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "best_model = None\n",
    "minimum_loss = 1000000\n",
    "\n",
    "for epoch in range(10):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "    epoch_loss = []\n",
    "    tq = tqdm(dataloader)\n",
    "    for data in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        table_input = data[\"table_input\"]\n",
    "        time_input = data[\"time_input\"].to(\"cuda\")\n",
    "        mask = data[\"mask\"]\n",
    "\n",
    "        # モデルにデータを入力し、出力を取得\n",
    "        transformer_output, embedding = transformer_model(time_input)\n",
    "        # 損失の計算\n",
    "        loss = criterion(transformer_output, time_input)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss.append(loss.item())\n",
    "\n",
    "        tq.set_postfix(loss=np.mean(epoch_loss))\n",
    "        tq.update()\n",
    "\n",
    "    if np.mean(epoch_loss) < minimum_loss:\n",
    "        minimum_loss = np.mean(epoch_loss)\n",
    "        best_model = transformer_model\n",
    "        transformer_model.eval()\n",
    "        torch.save(\n",
    "            transformer_model.state_dict(), \"./assets/transformer_autoencoder.pth\"\n",
    "        )\n",
    "        model.train()\n",
    "\n",
    "    print(f\"Epoch {epoch} Loss: {np.mean(epoch_loss)}\")\n",
    "    tq.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 996/996 [01:47<00:00,  9.27it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = CMIDataset(\n",
    "    table_df=train,\n",
    "    valid_ids=get_valid_ids(train_series_dir),\n",
    "    base_dir=train_series_dir,\n",
    "    save_filename=\"train\",\n",
    ")\n",
    "\n",
    "# AutoEncoderのモデルのインスタンス化\n",
    "transformer_model = TransformerAutoEncoder().to(\"cuda\")\n",
    "transformer_model.load_state_dict(torch.load(\"./assets/transformer_autoencoder.pth\"))\n",
    "# データセットからデータを取り出す\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "best_model = None\n",
    "minimum_loss = 1000000\n",
    "\n",
    "print(f\"Create Embedding\")\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "epoch_loss = []\n",
    "tq = tqdm(dataloader)\n",
    "\n",
    "embedding_result = []\n",
    "\n",
    "for data in dataloader:\n",
    "    id_ = data[\"id\"][0]\n",
    "    table_input = data[\"table_input\"]\n",
    "    time_input = data[\"time_input\"].to(\"cuda\")\n",
    "    mask = data[\"mask\"]\n",
    "\n",
    "    # モデルにデータを入力し、出力を取得\n",
    "    transformer_output, embedding = transformer_model(time_input)\n",
    "    # 損失の計算\n",
    "\n",
    "    mean_embedding = torch.mean(embedding, dim=1).squeeze(0).cpu().detach().numpy()\n",
    "    # mean_embedding = transformer_output.squeeze(0).mean(axis=0).cpu().detach().numpy()\n",
    "\n",
    "    embedding_result.append({\"id\": id_, \"embedding\": mean_embedding})\n",
    "\n",
    "    tq.update()\n",
    "\n",
    "tq.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>embedding_0</th>\n",
       "      <th>embedding_1</th>\n",
       "      <th>embedding_2</th>\n",
       "      <th>embedding_3</th>\n",
       "      <th>embedding_4</th>\n",
       "      <th>embedding_5</th>\n",
       "      <th>embedding_6</th>\n",
       "      <th>embedding_7</th>\n",
       "      <th>embedding_8</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_54</th>\n",
       "      <th>embedding_55</th>\n",
       "      <th>embedding_56</th>\n",
       "      <th>embedding_57</th>\n",
       "      <th>embedding_58</th>\n",
       "      <th>embedding_59</th>\n",
       "      <th>embedding_60</th>\n",
       "      <th>embedding_61</th>\n",
       "      <th>embedding_62</th>\n",
       "      <th>embedding_63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23dafdab</td>\n",
       "      <td>0.722981</td>\n",
       "      <td>0.972480</td>\n",
       "      <td>0.320560</td>\n",
       "      <td>-0.045523</td>\n",
       "      <td>0.486333</td>\n",
       "      <td>0.010224</td>\n",
       "      <td>-0.184912</td>\n",
       "      <td>-0.398195</td>\n",
       "      <td>-0.468804</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.041285</td>\n",
       "      <td>-0.431181</td>\n",
       "      <td>-0.926744</td>\n",
       "      <td>-1.152586</td>\n",
       "      <td>0.288071</td>\n",
       "      <td>-0.647866</td>\n",
       "      <td>1.471712</td>\n",
       "      <td>1.852199</td>\n",
       "      <td>-0.210128</td>\n",
       "      <td>-0.144354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e4614ec6</td>\n",
       "      <td>0.843533</td>\n",
       "      <td>0.920402</td>\n",
       "      <td>0.246039</td>\n",
       "      <td>-0.018809</td>\n",
       "      <td>0.386122</td>\n",
       "      <td>0.049963</td>\n",
       "      <td>-0.130582</td>\n",
       "      <td>-0.395948</td>\n",
       "      <td>-0.451044</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.009870</td>\n",
       "      <td>-0.457578</td>\n",
       "      <td>-0.956706</td>\n",
       "      <td>-1.042328</td>\n",
       "      <td>0.211449</td>\n",
       "      <td>-0.710467</td>\n",
       "      <td>1.533372</td>\n",
       "      <td>1.972301</td>\n",
       "      <td>-0.148478</td>\n",
       "      <td>-0.180185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56ef356c</td>\n",
       "      <td>0.815776</td>\n",
       "      <td>0.940347</td>\n",
       "      <td>0.276199</td>\n",
       "      <td>0.067319</td>\n",
       "      <td>0.443625</td>\n",
       "      <td>0.079862</td>\n",
       "      <td>-0.112527</td>\n",
       "      <td>-0.474563</td>\n",
       "      <td>-0.514544</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.997894</td>\n",
       "      <td>-0.413691</td>\n",
       "      <td>-1.039906</td>\n",
       "      <td>-1.109035</td>\n",
       "      <td>0.123151</td>\n",
       "      <td>-0.712050</td>\n",
       "      <td>1.545436</td>\n",
       "      <td>2.043810</td>\n",
       "      <td>-0.100478</td>\n",
       "      <td>-0.210419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dcfcd574</td>\n",
       "      <td>0.794182</td>\n",
       "      <td>0.922748</td>\n",
       "      <td>0.300054</td>\n",
       "      <td>0.030987</td>\n",
       "      <td>0.385285</td>\n",
       "      <td>0.063245</td>\n",
       "      <td>-0.127654</td>\n",
       "      <td>-0.471181</td>\n",
       "      <td>-0.465883</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.938861</td>\n",
       "      <td>-0.438761</td>\n",
       "      <td>-1.035307</td>\n",
       "      <td>-1.044639</td>\n",
       "      <td>0.095013</td>\n",
       "      <td>-0.699590</td>\n",
       "      <td>1.554100</td>\n",
       "      <td>1.982189</td>\n",
       "      <td>-0.070971</td>\n",
       "      <td>-0.232328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>338146bd</td>\n",
       "      <td>0.775644</td>\n",
       "      <td>0.957284</td>\n",
       "      <td>0.341444</td>\n",
       "      <td>0.031167</td>\n",
       "      <td>0.466055</td>\n",
       "      <td>0.067557</td>\n",
       "      <td>-0.141597</td>\n",
       "      <td>-0.481295</td>\n",
       "      <td>-0.555753</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.050994</td>\n",
       "      <td>-0.429000</td>\n",
       "      <td>-0.961325</td>\n",
       "      <td>-1.164431</td>\n",
       "      <td>0.169325</td>\n",
       "      <td>-0.651885</td>\n",
       "      <td>1.549012</td>\n",
       "      <td>1.949509</td>\n",
       "      <td>-0.112341</td>\n",
       "      <td>-0.187825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2a9e0dee</td>\n",
       "      <td>0.812333</td>\n",
       "      <td>0.928318</td>\n",
       "      <td>0.295445</td>\n",
       "      <td>0.040721</td>\n",
       "      <td>0.393984</td>\n",
       "      <td>0.071607</td>\n",
       "      <td>-0.135753</td>\n",
       "      <td>-0.460919</td>\n",
       "      <td>-0.487546</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.023763</td>\n",
       "      <td>-0.457032</td>\n",
       "      <td>-0.960132</td>\n",
       "      <td>-1.088129</td>\n",
       "      <td>0.151415</td>\n",
       "      <td>-0.684462</td>\n",
       "      <td>1.563088</td>\n",
       "      <td>1.979765</td>\n",
       "      <td>-0.106722</td>\n",
       "      <td>-0.199308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0eddd8e5</td>\n",
       "      <td>0.802002</td>\n",
       "      <td>0.939377</td>\n",
       "      <td>0.313522</td>\n",
       "      <td>0.060402</td>\n",
       "      <td>0.395060</td>\n",
       "      <td>0.033857</td>\n",
       "      <td>-0.154611</td>\n",
       "      <td>-0.434979</td>\n",
       "      <td>-0.462967</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.019517</td>\n",
       "      <td>-0.460439</td>\n",
       "      <td>-0.991772</td>\n",
       "      <td>-1.068464</td>\n",
       "      <td>0.154841</td>\n",
       "      <td>-0.694276</td>\n",
       "      <td>1.561919</td>\n",
       "      <td>1.973148</td>\n",
       "      <td>-0.135226</td>\n",
       "      <td>-0.226951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a49eda7f</td>\n",
       "      <td>0.823501</td>\n",
       "      <td>0.923516</td>\n",
       "      <td>0.300094</td>\n",
       "      <td>0.024553</td>\n",
       "      <td>0.402166</td>\n",
       "      <td>0.029877</td>\n",
       "      <td>-0.147272</td>\n",
       "      <td>-0.449120</td>\n",
       "      <td>-0.457177</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.976383</td>\n",
       "      <td>-0.425602</td>\n",
       "      <td>-1.017790</td>\n",
       "      <td>-1.051384</td>\n",
       "      <td>0.124061</td>\n",
       "      <td>-0.704755</td>\n",
       "      <td>1.564402</td>\n",
       "      <td>1.991453</td>\n",
       "      <td>-0.098391</td>\n",
       "      <td>-0.249995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fa34f945</td>\n",
       "      <td>0.724339</td>\n",
       "      <td>0.978255</td>\n",
       "      <td>0.325422</td>\n",
       "      <td>-0.032838</td>\n",
       "      <td>0.508774</td>\n",
       "      <td>0.061492</td>\n",
       "      <td>-0.229939</td>\n",
       "      <td>-0.385244</td>\n",
       "      <td>-0.508964</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.084202</td>\n",
       "      <td>-0.472991</td>\n",
       "      <td>-0.858802</td>\n",
       "      <td>-1.195414</td>\n",
       "      <td>0.303603</td>\n",
       "      <td>-0.606173</td>\n",
       "      <td>1.480294</td>\n",
       "      <td>1.771525</td>\n",
       "      <td>-0.197009</td>\n",
       "      <td>-0.102264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>526f719b</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.949477</td>\n",
       "      <td>0.320309</td>\n",
       "      <td>0.054745</td>\n",
       "      <td>0.395894</td>\n",
       "      <td>0.084839</td>\n",
       "      <td>-0.131656</td>\n",
       "      <td>-0.445712</td>\n",
       "      <td>-0.518001</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.063697</td>\n",
       "      <td>-0.452151</td>\n",
       "      <td>-0.982387</td>\n",
       "      <td>-1.116243</td>\n",
       "      <td>0.188366</td>\n",
       "      <td>-0.665709</td>\n",
       "      <td>1.562503</td>\n",
       "      <td>1.983754</td>\n",
       "      <td>-0.133684</td>\n",
       "      <td>-0.192508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>996 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  embedding_0  embedding_1  embedding_2  embedding_3  embedding_4  \\\n",
       "0   23dafdab     0.722981     0.972480     0.320560    -0.045523     0.486333   \n",
       "0   e4614ec6     0.843533     0.920402     0.246039    -0.018809     0.386122   \n",
       "0   56ef356c     0.815776     0.940347     0.276199     0.067319     0.443625   \n",
       "0   dcfcd574     0.794182     0.922748     0.300054     0.030987     0.385285   \n",
       "0   338146bd     0.775644     0.957284     0.341444     0.031167     0.466055   \n",
       "..       ...          ...          ...          ...          ...          ...   \n",
       "0   2a9e0dee     0.812333     0.928318     0.295445     0.040721     0.393984   \n",
       "0   0eddd8e5     0.802002     0.939377     0.313522     0.060402     0.395060   \n",
       "0   a49eda7f     0.823501     0.923516     0.300094     0.024553     0.402166   \n",
       "0   fa34f945     0.724339     0.978255     0.325422    -0.032838     0.508774   \n",
       "0   526f719b     0.808511     0.949477     0.320309     0.054745     0.395894   \n",
       "\n",
       "    embedding_5  embedding_6  embedding_7  embedding_8  ...  embedding_54  \\\n",
       "0      0.010224    -0.184912    -0.398195    -0.468804  ...     -2.041285   \n",
       "0      0.049963    -0.130582    -0.395948    -0.451044  ...     -2.009870   \n",
       "0      0.079862    -0.112527    -0.474563    -0.514544  ...     -1.997894   \n",
       "0      0.063245    -0.127654    -0.471181    -0.465883  ...     -1.938861   \n",
       "0      0.067557    -0.141597    -0.481295    -0.555753  ...     -2.050994   \n",
       "..          ...          ...          ...          ...  ...           ...   \n",
       "0      0.071607    -0.135753    -0.460919    -0.487546  ...     -2.023763   \n",
       "0      0.033857    -0.154611    -0.434979    -0.462967  ...     -2.019517   \n",
       "0      0.029877    -0.147272    -0.449120    -0.457177  ...     -1.976383   \n",
       "0      0.061492    -0.229939    -0.385244    -0.508964  ...     -2.084202   \n",
       "0      0.084839    -0.131656    -0.445712    -0.518001  ...     -2.063697   \n",
       "\n",
       "    embedding_55  embedding_56  embedding_57  embedding_58  embedding_59  \\\n",
       "0      -0.431181     -0.926744     -1.152586      0.288071     -0.647866   \n",
       "0      -0.457578     -0.956706     -1.042328      0.211449     -0.710467   \n",
       "0      -0.413691     -1.039906     -1.109035      0.123151     -0.712050   \n",
       "0      -0.438761     -1.035307     -1.044639      0.095013     -0.699590   \n",
       "0      -0.429000     -0.961325     -1.164431      0.169325     -0.651885   \n",
       "..           ...           ...           ...           ...           ...   \n",
       "0      -0.457032     -0.960132     -1.088129      0.151415     -0.684462   \n",
       "0      -0.460439     -0.991772     -1.068464      0.154841     -0.694276   \n",
       "0      -0.425602     -1.017790     -1.051384      0.124061     -0.704755   \n",
       "0      -0.472991     -0.858802     -1.195414      0.303603     -0.606173   \n",
       "0      -0.452151     -0.982387     -1.116243      0.188366     -0.665709   \n",
       "\n",
       "    embedding_60  embedding_61  embedding_62  embedding_63  \n",
       "0       1.471712      1.852199     -0.210128     -0.144354  \n",
       "0       1.533372      1.972301     -0.148478     -0.180185  \n",
       "0       1.545436      2.043810     -0.100478     -0.210419  \n",
       "0       1.554100      1.982189     -0.070971     -0.232328  \n",
       "0       1.549012      1.949509     -0.112341     -0.187825  \n",
       "..           ...           ...           ...           ...  \n",
       "0       1.563088      1.979765     -0.106722     -0.199308  \n",
       "0       1.561919      1.973148     -0.135226     -0.226951  \n",
       "0       1.564402      1.991453     -0.098391     -0.249995  \n",
       "0       1.480294      1.771525     -0.197009     -0.102264  \n",
       "0       1.562503      1.983754     -0.133684     -0.192508  \n",
       "\n",
       "[996 rows x 65 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_df_all = None\n",
    "\n",
    "for row in embedding_result:\n",
    "    id_ = row[\"id\"]\n",
    "    embedding = row[\"embedding\"]\n",
    "    embedding_cols = [f\"embedding_{i}\" for i in range(embedding.shape[0])]\n",
    "    embedding_df = pd.DataFrame(embedding.reshape(1, -1), columns=embedding_cols)\n",
    "    embedding_df[\"id\"] = id_\n",
    "\n",
    "    if embedding_df_all is None:\n",
    "        embedding_df_all = embedding_df\n",
    "    else:\n",
    "        embedding_df_all = pd.concat([embedding_df_all, embedding_df], axis=0)\n",
    "\n",
    "embedding_df_all = embedding_df_all[[\"id\"] + embedding_cols]\n",
    "embedding_df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "\n",
    "\n",
    "def quadratic_weighted_kappa(y_true, y_pred):\n",
    "    return cohen_kappa_score(y_true, y_pred, weights=\"quadratic\")\n",
    "\n",
    "\n",
    "def threshold_Rounder(oof_non_rounded, thresholds):\n",
    "    return np.where(\n",
    "        oof_non_rounded < thresholds[0],\n",
    "        0,\n",
    "        np.where(\n",
    "            oof_non_rounded < thresholds[1],\n",
    "            1,\n",
    "            np.where(oof_non_rounded < thresholds[2], 2, 3),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "def evaluate_predictions(thresholds, y_true, oof_non_rounded):\n",
    "    rounded_p = threshold_Rounder(oof_non_rounded, thresholds)\n",
    "    return -quadratic_weighted_kappa(y_true, rounded_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train[\"sii\"] != -1].reset_index(drop=True)\n",
    "train = train.merge(embedding_df_all, on=\"id\", how=\"left\")\n",
    "train.fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Folds: 100%|██████████| 5/5 [00:06<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train QWK --> 0.7483\n",
      "CV: 0.3847\n",
      "tuned Kappa: 0.447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy.optimize import minimize\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator, FormatStrFormatter, PercentFormatter\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from keras.models import Model\n",
    "# from keras.layers import Input, Dense\n",
    "# from keras.optimizers import Adam\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from colorama import Fore, Style\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import (\n",
    "    VotingRegressor,\n",
    "    RandomForestRegressor,\n",
    "    GradientBoostingRegressor,\n",
    ")\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "\n",
    "def quadratic_weighted_kappa(y_true, y_pred):\n",
    "    return cohen_kappa_score(y_true, y_pred, weights=\"quadratic\")\n",
    "\n",
    "\n",
    "def threshold_Rounder(oof_non_rounded, thresholds):\n",
    "    return np.where(\n",
    "        oof_non_rounded < thresholds[0],\n",
    "        0,\n",
    "        np.where(\n",
    "            oof_non_rounded < thresholds[1],\n",
    "            1,\n",
    "            np.where(oof_non_rounded < thresholds[2], 2, 3),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "def evaluate_predictions(thresholds, y_true, oof_non_rounded):\n",
    "    rounded_p = threshold_Rounder(oof_non_rounded, thresholds)\n",
    "    return -quadratic_weighted_kappa(y_true, rounded_p)\n",
    "\n",
    "\n",
    "def TrainML(model_class, test_data):\n",
    "    X = train.drop([\"sii\", \"id\"], axis=1)\n",
    "    y = train[\"sii\"]\n",
    "\n",
    "    n_splits = 5\n",
    "    SKF = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    train_S = []\n",
    "    test_S = []\n",
    "\n",
    "    oof_non_rounded = np.zeros(len(y), dtype=float)\n",
    "    oof_rounded = np.zeros(len(y), dtype=int)\n",
    "    test_preds = np.zeros((len(test_data), n_splits))\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(\n",
    "        tqdm(SKF.split(X, y), desc=\"Training Folds\", total=n_splits)\n",
    "    ):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        model = clone(model_class)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_val_pred = model.predict(X_val)\n",
    "\n",
    "        oof_non_rounded[test_idx] = y_val_pred\n",
    "        y_val_pred_rounded = y_val_pred.round(0).astype(int)\n",
    "        oof_rounded[test_idx] = y_val_pred_rounded\n",
    "\n",
    "        train_kappa = quadratic_weighted_kappa(\n",
    "            y_train, y_train_pred.round(0).astype(int)\n",
    "        )\n",
    "        val_kappa = quadratic_weighted_kappa(y_val, y_val_pred_rounded)\n",
    "\n",
    "        train_S.append(train_kappa)\n",
    "        test_S.append(val_kappa)\n",
    "\n",
    "        # test_preds[:, fold] = model.predict(test_data.drop(columns=[\"id\"]))\n",
    "\n",
    "        print(\n",
    "            f\"Fold {fold+1} - Train QWK: {train_kappa:.4f}, Validation QWK: {val_kappa:.4f}\"\n",
    "        )\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        voting_model = model\n",
    "        # modelの保存\n",
    "        with open(f\"./assets/voting_model_{fold}.pkl\", \"wb\") as f:\n",
    "            pickle.dump(voting_model, f)\n",
    "\n",
    "    print(f\"Mean Train QWK --> {np.mean(train_S):.4f}\")\n",
    "    print(f\"CV: {np.mean(test_S):.4f}\")\n",
    "\n",
    "    KappaOPtimizer = minimize(\n",
    "        evaluate_predictions,\n",
    "        x0=[0.5, 1.5, 2.5],\n",
    "        args=(y, oof_non_rounded),\n",
    "        method=\"Nelder-Mead\",\n",
    "    )\n",
    "    assert KappaOPtimizer.success, \"Optimization did not converge.\"\n",
    "\n",
    "    oof_tuned = threshold_Rounder(oof_non_rounded, KappaOPtimizer.x)\n",
    "    tKappa = quadratic_weighted_kappa(y, oof_tuned)\n",
    "\n",
    "    print(f\"tuned Kappa: {tKappa:.3f}\")\n",
    "\n",
    "    # tpm = test_preds.mean(axis=1)\n",
    "    # tpTuned = threshold_Rounder(tpm, KappaOPtimizer.x)\n",
    "\n",
    "\n",
    "# Model parameters for LightGBM\n",
    "Params = {\n",
    "    \"learning_rate\": 0.046,\n",
    "    \"max_depth\": 12,\n",
    "    \"num_leaves\": 478,\n",
    "    \"min_data_in_leaf\": 13,\n",
    "    \"feature_fraction\": 0.893,\n",
    "    \"bagging_fraction\": 0.784,\n",
    "    \"bagging_freq\": 4,\n",
    "    \"lambda_l1\": 10,  # Increased from 6.59\n",
    "    \"lambda_l2\": 0.01,  # Increased from 2.68e-06\n",
    "}\n",
    "\n",
    "\n",
    "# XGBoost parameters\n",
    "XGB_Params = {\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"max_depth\": 6,\n",
    "    \"n_estimators\": 200,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"reg_alpha\": 1,  # Increased from 0.1\n",
    "    \"reg_lambda\": 5,  # Increased from 1\n",
    "    \"random_state\": SEED,\n",
    "}\n",
    "\n",
    "\n",
    "CatBoost_Params = {\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"depth\": 6,\n",
    "    \"iterations\": 200,\n",
    "    \"random_seed\": SEED,\n",
    "    \"verbose\": 0,\n",
    "    \"l2_leaf_reg\": 10,  # Increase this value\n",
    "}\n",
    "\n",
    "# Create model instances\n",
    "Light = LGBMRegressor(**Params, random_state=SEED, verbose=-1, n_estimators=300)\n",
    "XGB_Model = XGBRegressor(**XGB_Params)\n",
    "CatBoost_Model = CatBoostRegressor(**CatBoost_Params)\n",
    "\n",
    "# Combine models using Voting Regressor\n",
    "voting_model = VotingRegressor(\n",
    "    estimators=[\n",
    "        (\"lightgbm\", Light),\n",
    "        (\"xgboost\", XGB_Model),\n",
    "        (\"catboost\", CatBoost_Model),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Train the ensemble model\n",
    "TrainML(voting_model, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
