{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# from src.dataloader_ import *\n",
    "# from src.network_ import *\n",
    "from src.utils import *\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "\n",
    "train_series_dir = \"../../../inputs/series_train.parquet/\"\n",
    "test_series_dir = \"../../../inputs/series_test.parquet/\"\n",
    "\n",
    "data_dic_path = \"../../../inputs/data_dictionary.csv\"\n",
    "sample_submission_path = \"../../../inputs/sample_submission.csv\"\n",
    "train_path = \"../../../inputs/train.csv\"\n",
    "test_path = \"../../../inputs/test.csv\"\n",
    "\n",
    "train = pd.read_csv(train_path)\n",
    "test = pd.read_csv(test_path)\n",
    "sample_submission = pd.read_csv(sample_submission_path)\n",
    "data_dic = pd.read_csv(data_dic_path)\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def seed_torch(seed=1029):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "nb_name = os.path.basename(os.getcwd())  # notebook name\n",
    "seed_torch(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの前処理\n",
    "\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "\n",
    "add_features = [\n",
    "    \"BMI_Age\",\n",
    "    \"Internet_Hours_Age\",\n",
    "    \"BMI_Internet_Hours\",\n",
    "    \"BFP_BMI\",\n",
    "    \"FFMI_BFP\",\n",
    "    \"FMI_BFP\",\n",
    "    \"LST_TBW\",\n",
    "    \"BFP_BMR\",\n",
    "    \"BFP_DEE\",\n",
    "    \"BMR_Weight\",\n",
    "    \"DEE_Weight\",\n",
    "    \"SMM_Height\",\n",
    "    \"Muscle_to_Fat\",\n",
    "    \"Hydration_Status\",\n",
    "    \"ICW_TBW\",\n",
    "]\n",
    "\n",
    "double_columns = [\n",
    "    \"FGC-FGC_SRR_Zone\",\n",
    "    \"BIA-BIA_SMM\",\n",
    "    \"Physical-Waist_Circumference\",\n",
    "    \"BIA-BIA_FFMI\",\n",
    "    \"FGC-FGC_CU\",\n",
    "    \"PreInt_EduHx-computerinternet_hoursday\",\n",
    "    \"BIA-BIA_ECW\",\n",
    "    \"FGC-FGC_CU_Zone\",\n",
    "    \"FGC-FGC_SRL_Zone\",\n",
    "    \"BIA-BIA_DEE\",\n",
    "    \"Physical-Weight\",\n",
    "    \"Fitness_Endurance-Time_Mins\",\n",
    "    \"FGC-FGC_SRR\",\n",
    "    \"SDS-SDS_Total_T\",\n",
    "    \"FGC-FGC_PU\",\n",
    "    \"BIA-BIA_FFM\",\n",
    "    \"FGC-FGC_TL_Zone\",\n",
    "    \"Physical-BMI\",\n",
    "    \"Physical-Systolic_BP\",\n",
    "    \"Physical-HeartRate\",\n",
    "    \"BIA-BIA_ICW\",\n",
    "    \"Physical-Height\",\n",
    "    \"FGC-FGC_SRL\",\n",
    "    \"BIA-BIA_BMC\",\n",
    "    \"Fitness_Endurance-Time_Sec\",\n",
    "    \"BIA-BIA_Frame_num\",\n",
    "    \"Basic_Demos-Age\",\n",
    "    \"FGC-FGC_GSND_Zone\",\n",
    "    \"Basic_Demos-Sex\",\n",
    "    \"FGC-FGC_GSND\",\n",
    "    \"BIA-BIA_LST\",\n",
    "    \"FGC-FGC_TL\",\n",
    "    \"BIA-BIA_BMI\",\n",
    "    \"BIA-BIA_FMI\",\n",
    "    \"PAQ_C-PAQ_C_Total\",\n",
    "    \"BIA-BIA_Activity_Level_num\",\n",
    "    \"FGC-FGC_GSD\",\n",
    "    \"BIA-BIA_BMR\",\n",
    "    \"BIA-BIA_Fat\",\n",
    "    \"SDS-SDS_Total_Raw\",\n",
    "    \"CGAS-CGAS_Score\",\n",
    "    \"FGC-FGC_PU_Zone\",\n",
    "    \"BIA-BIA_LDM\",\n",
    "    \"Fitness_Endurance-Max_Stage\",\n",
    "    \"PAQ_A-PAQ_A_Total\",\n",
    "    \"BIA-BIA_TBW\",\n",
    "    \"FGC-FGC_GSD_Zone\",\n",
    "    \"Physical-Diastolic_BP\",\n",
    "]\n",
    "\n",
    "\n",
    "def feature_engineering(df):\n",
    "    # season_cols = [col for col in df.columns if \"Season\" in col]\n",
    "    # df = df.drop(season_cols, axis=1)\n",
    "    df[\"BMI_Age\"] = df[\"Physical-BMI\"] * df[\"Basic_Demos-Age\"]\n",
    "    df[\"Internet_Hours_Age\"] = (\n",
    "        df[\"PreInt_EduHx-computerinternet_hoursday\"] * df[\"Basic_Demos-Age\"]\n",
    "    )\n",
    "    df[\"BMI_Internet_Hours\"] = (\n",
    "        df[\"Physical-BMI\"] * df[\"PreInt_EduHx-computerinternet_hoursday\"]\n",
    "    )\n",
    "    df[\"BFP_BMI\"] = df[\"BIA-BIA_Fat\"] / df[\"BIA-BIA_BMI\"]\n",
    "    df[\"FFMI_BFP\"] = df[\"BIA-BIA_FFMI\"] / df[\"BIA-BIA_Fat\"]\n",
    "    df[\"FMI_BFP\"] = df[\"BIA-BIA_FMI\"] / df[\"BIA-BIA_Fat\"]\n",
    "    df[\"LST_TBW\"] = df[\"BIA-BIA_LST\"] / df[\"BIA-BIA_TBW\"]\n",
    "    df[\"BFP_BMR\"] = df[\"BIA-BIA_Fat\"] * df[\"BIA-BIA_BMR\"]\n",
    "    df[\"BFP_DEE\"] = df[\"BIA-BIA_Fat\"] * df[\"BIA-BIA_DEE\"]\n",
    "    df[\"BMR_Weight\"] = df[\"BIA-BIA_BMR\"] / df[\"Physical-Weight\"]\n",
    "    df[\"DEE_Weight\"] = df[\"BIA-BIA_DEE\"] / df[\"Physical-Weight\"]\n",
    "    df[\"SMM_Height\"] = df[\"BIA-BIA_SMM\"] / df[\"Physical-Height\"]\n",
    "    df[\"Muscle_to_Fat\"] = df[\"BIA-BIA_SMM\"] / df[\"BIA-BIA_FMI\"]\n",
    "    df[\"Hydration_Status\"] = df[\"BIA-BIA_TBW\"] / df[\"Physical-Weight\"]\n",
    "    df[\"ICW_TBW\"] = df[\"BIA-BIA_ICW\"] / df[\"BIA-BIA_TBW\"]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "train = feature_engineering(train)\n",
    "train = train.replace([np.inf, -np.inf], np.nan)\n",
    "for add_ in add_features:\n",
    "    train[add_] = train[add_].fillna(0.0)\n",
    "train = train.dropna(thresh=10, axis=0)\n",
    "\n",
    "test = feature_engineering(test)\n",
    "test = test.replace([np.inf, -np.inf], np.nan)\n",
    "for add_ in add_features:\n",
    "    test[add_] = test[add_].fillna(0.0)\n",
    "test = test.dropna(thresh=10, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Tabnet***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_tabnet.callbacks import Callback\n",
    "import os\n",
    "import torch\n",
    "from pytorch_tabnet.callbacks import Callback\n",
    "\n",
    "\n",
    "class TabNetWrapper(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.model = TabNetRegressor(**kwargs)\n",
    "        self.kwargs = kwargs\n",
    "        self.imputer = SimpleImputer(strategy=\"median\")\n",
    "        self.best_model_path = \"best_tabnet_model.pt\"\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Handle missing values\n",
    "        X_imputed = self.imputer.fit_transform(X)\n",
    "\n",
    "        if hasattr(y, \"values\"):\n",
    "            y = y.values\n",
    "\n",
    "        # Create internal validation set\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "            X_imputed, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "\n",
    "        # Train TabNet model\n",
    "        history = self.model.fit(\n",
    "            X_train=X_train,\n",
    "            y_train=y_train.reshape(-1, 1),\n",
    "            eval_set=[(X_valid, y_valid.reshape(-1, 1))],\n",
    "            eval_name=[\"valid\"],\n",
    "            eval_metric=[\"mse\"],\n",
    "            max_epochs=200,\n",
    "            patience=20,\n",
    "            batch_size=1024,\n",
    "            virtual_batch_size=128,\n",
    "            num_workers=0,\n",
    "            drop_last=False,\n",
    "            callbacks=[\n",
    "                TabNetPretrainedModelCheckpoint(\n",
    "                    filepath=self.best_model_path,\n",
    "                    monitor=\"valid_mse\",\n",
    "                    mode=\"min\",\n",
    "                    save_best_only=True,\n",
    "                    verbose=True,\n",
    "                )\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        # Load the best model\n",
    "        if os.path.exists(self.best_model_path):\n",
    "            self.model.load_model(self.best_model_path)\n",
    "            os.remove(self.best_model_path)  # Remove temporary file\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_imputed = self.imputer.transform(X)\n",
    "        return self.model.predict(X_imputed).flatten()\n",
    "\n",
    "    def __deepcopy__(self, memo):\n",
    "        # Add deepcopy support for scikit-learn\n",
    "        cls = self.__class__\n",
    "        result = cls.__new__(cls)\n",
    "        memo[id(self)] = result\n",
    "        for k, v in self.__dict__.items():\n",
    "            setattr(result, k, deepcopy(v, memo))\n",
    "        return result\n",
    "\n",
    "\n",
    "# TabNet hyperparameters\n",
    "TabNet_Params = {\n",
    "    \"n_d\": 64,  # Width of the decision prediction layer\n",
    "    \"n_a\": 64,  # Width of the attention embedding for each step\n",
    "    \"n_steps\": 5,  # Number of steps in the architecture\n",
    "    \"gamma\": 1.5,  # Coefficient for feature selection regularization\n",
    "    \"n_independent\": 2,  # Number of independent GLU layer in each GLU block\n",
    "    \"n_shared\": 2,  # Number of shared GLU layer in each GLU block\n",
    "    \"lambda_sparse\": 1e-4,  # Sparsity regularization\n",
    "    \"optimizer_fn\": torch.optim.Adam,\n",
    "    \"optimizer_params\": dict(lr=2e-2, weight_decay=1e-5),\n",
    "    \"mask_type\": \"entmax\",\n",
    "    \"scheduler_params\": dict(mode=\"min\", patience=10, min_lr=1e-5, factor=0.5),\n",
    "    \"scheduler_fn\": torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    \"verbose\": 1,\n",
    "    \"device_name\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "}\n",
    "\n",
    "\n",
    "class TabNetPretrainedModelCheckpoint(Callback):\n",
    "    def __init__(\n",
    "        self, filepath, monitor=\"val_loss\", mode=\"min\", save_best_only=True, verbose=1\n",
    "    ):\n",
    "        super().__init__()  # Initialize parent class\n",
    "        self.filepath = filepath\n",
    "        self.monitor = monitor\n",
    "        self.mode = mode\n",
    "        self.save_best_only = save_best_only\n",
    "        self.verbose = verbose\n",
    "        self.best = float(\"inf\") if mode == \"min\" else -float(\"inf\")\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.model = self.trainer  # Use trainer itself as model\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            return\n",
    "\n",
    "        # Check if current metric is better than best\n",
    "        if (self.mode == \"min\" and current < self.best) or (\n",
    "            self.mode == \"max\" and current > self.best\n",
    "        ):\n",
    "            if self.verbose:\n",
    "                print(\n",
    "                    f\"\\nEpoch {epoch}: {self.monitor} improved from {self.best:.4f} to {current:.4f}\"\n",
    "                )\n",
    "            self.best = current\n",
    "            if self.save_best_only:\n",
    "                self.model.save_model(self.filepath)  # Save the entire model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2188, 63) (548, 63)\n",
      "epoch 0  | loss: 4.38521 | valid_mse: 48.56769|  0:00:00s\n",
      "\n",
      "Epoch 0: valid_mse improved from inf to 48.5677\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 1  | loss: 2.70531 | valid_mse: 9.06162 |  0:00:00s\n",
      "\n",
      "Epoch 1: valid_mse improved from 48.5677 to 9.0616\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 2  | loss: 1.76055 | valid_mse: 13.02918|  0:00:00s\n",
      "epoch 3  | loss: 1.20246 | valid_mse: 13.05631|  0:00:00s\n",
      "epoch 4  | loss: 0.89956 | valid_mse: 12.35513|  0:00:00s\n",
      "epoch 5  | loss: 0.80253 | valid_mse: 7.19226 |  0:00:00s\n",
      "\n",
      "Epoch 5: valid_mse improved from 9.0616 to 7.1923\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 6  | loss: 0.74541 | valid_mse: 13.99798|  0:00:01s\n",
      "epoch 7  | loss: 0.70791 | valid_mse: 9.4266  |  0:00:01s\n",
      "epoch 8  | loss: 0.68448 | valid_mse: 4.48733 |  0:00:01s\n",
      "\n",
      "Epoch 8: valid_mse improved from 7.1923 to 4.4873\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 9  | loss: 0.63347 | valid_mse: 2.47785 |  0:00:01s\n",
      "\n",
      "Epoch 9: valid_mse improved from 4.4873 to 2.4779\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 10 | loss: 0.60975 | valid_mse: 1.91766 |  0:00:01s\n",
      "\n",
      "Epoch 10: valid_mse improved from 2.4779 to 1.9177\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 11 | loss: 0.59424 | valid_mse: 1.95089 |  0:00:01s\n",
      "epoch 12 | loss: 0.59517 | valid_mse: 1.71668 |  0:00:01s\n",
      "\n",
      "Epoch 12: valid_mse improved from 1.9177 to 1.7167\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 13 | loss: 0.57532 | valid_mse: 1.36965 |  0:00:01s\n",
      "\n",
      "Epoch 13: valid_mse improved from 1.7167 to 1.3697\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 14 | loss: 0.57382 | valid_mse: 1.22059 |  0:00:01s\n",
      "\n",
      "Epoch 14: valid_mse improved from 1.3697 to 1.2206\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 15 | loss: 0.56632 | valid_mse: 1.1523  |  0:00:01s\n",
      "\n",
      "Epoch 15: valid_mse improved from 1.2206 to 1.1523\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 16 | loss: 0.57376 | valid_mse: 1.0289  |  0:00:01s\n",
      "\n",
      "Epoch 16: valid_mse improved from 1.1523 to 1.0289\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 17 | loss: 0.54629 | valid_mse: 1.05728 |  0:00:01s\n",
      "epoch 18 | loss: 0.54671 | valid_mse: 1.0287  |  0:00:01s\n",
      "\n",
      "Epoch 18: valid_mse improved from 1.0289 to 1.0287\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 19 | loss: 0.54959 | valid_mse: 0.91201 |  0:00:02s\n",
      "\n",
      "Epoch 19: valid_mse improved from 1.0287 to 0.9120\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 20 | loss: 0.54388 | valid_mse: 0.84866 |  0:00:02s\n",
      "\n",
      "Epoch 20: valid_mse improved from 0.9120 to 0.8487\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 21 | loss: 0.54016 | valid_mse: 0.81511 |  0:00:02s\n",
      "\n",
      "Epoch 21: valid_mse improved from 0.8487 to 0.8151\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 22 | loss: 0.52905 | valid_mse: 0.85256 |  0:00:02s\n",
      "epoch 23 | loss: 0.53963 | valid_mse: 0.86529 |  0:00:02s\n",
      "epoch 24 | loss: 0.51762 | valid_mse: 0.85591 |  0:00:02s\n",
      "epoch 25 | loss: 0.51844 | valid_mse: 0.83449 |  0:00:02s\n",
      "epoch 26 | loss: 0.518   | valid_mse: 0.78104 |  0:00:02s\n",
      "\n",
      "Epoch 26: valid_mse improved from 0.8151 to 0.7810\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 27 | loss: 0.51405 | valid_mse: 0.80694 |  0:00:02s\n",
      "epoch 28 | loss: 0.52194 | valid_mse: 0.85472 |  0:00:02s\n",
      "epoch 29 | loss: 0.50872 | valid_mse: 0.99837 |  0:00:02s\n",
      "epoch 30 | loss: 0.50772 | valid_mse: 1.01847 |  0:00:02s\n",
      "epoch 31 | loss: 0.5043  | valid_mse: 1.06174 |  0:00:02s\n",
      "epoch 32 | loss: 0.50884 | valid_mse: 1.03464 |  0:00:02s\n",
      "epoch 33 | loss: 0.50506 | valid_mse: 1.01373 |  0:00:02s\n",
      "epoch 34 | loss: 0.49774 | valid_mse: 0.9087  |  0:00:03s\n",
      "epoch 35 | loss: 0.51798 | valid_mse: 0.79967 |  0:00:03s\n",
      "epoch 36 | loss: 0.49818 | valid_mse: 0.71042 |  0:00:03s\n",
      "\n",
      "Epoch 36: valid_mse improved from 0.7810 to 0.7104\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 37 | loss: 0.50601 | valid_mse: 0.6784  |  0:00:03s\n",
      "\n",
      "Epoch 37: valid_mse improved from 0.7104 to 0.6784\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 38 | loss: 0.50095 | valid_mse: 0.72156 |  0:00:03s\n",
      "epoch 39 | loss: 0.50112 | valid_mse: 0.72589 |  0:00:03s\n",
      "epoch 40 | loss: 0.49082 | valid_mse: 0.7039  |  0:00:03s\n",
      "epoch 41 | loss: 0.49188 | valid_mse: 0.75102 |  0:00:03s\n",
      "epoch 42 | loss: 0.49579 | valid_mse: 0.84801 |  0:00:03s\n",
      "epoch 43 | loss: 0.48182 | valid_mse: 0.90015 |  0:00:03s\n",
      "epoch 44 | loss: 0.48591 | valid_mse: 0.88847 |  0:00:03s\n",
      "epoch 45 | loss: 0.48845 | valid_mse: 0.78998 |  0:00:03s\n",
      "epoch 46 | loss: 0.48814 | valid_mse: 0.75221 |  0:00:03s\n",
      "epoch 47 | loss: 0.48371 | valid_mse: 0.75953 |  0:00:03s\n",
      "epoch 48 | loss: 0.47839 | valid_mse: 0.78745 |  0:00:03s\n",
      "epoch 49 | loss: 0.46975 | valid_mse: 0.77811 |  0:00:04s\n",
      "epoch 50 | loss: 0.47132 | valid_mse: 0.75393 |  0:00:04s\n",
      "epoch 51 | loss: 0.46867 | valid_mse: 0.77419 |  0:00:04s\n",
      "epoch 52 | loss: 0.47468 | valid_mse: 0.77499 |  0:00:04s\n",
      "epoch 53 | loss: 0.47852 | valid_mse: 0.81791 |  0:00:04s\n",
      "epoch 54 | loss: 0.46694 | valid_mse: 0.78993 |  0:00:04s\n",
      "epoch 55 | loss: 0.46312 | valid_mse: 0.80183 |  0:00:04s\n",
      "epoch 56 | loss: 0.46719 | valid_mse: 0.80505 |  0:00:04s\n",
      "epoch 57 | loss: 0.46496 | valid_mse: 0.79872 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 57 with best_epoch = 37 and best_valid_mse = 0.6784\n",
      "Fold 1 - Train QWK: 0.6478, Validation QWK: 0.3525\n",
      "(2189, 63) (547, 63)\n",
      "epoch 0  | loss: 4.4124  | valid_mse: 77.28459|  0:00:00s\n",
      "\n",
      "Epoch 0: valid_mse improved from inf to 77.2846\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 1  | loss: 2.28553 | valid_mse: 16.20773|  0:00:00s\n",
      "\n",
      "Epoch 1: valid_mse improved from 77.2846 to 16.2077\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 2  | loss: 1.386   | valid_mse: 20.0427 |  0:00:00s\n",
      "epoch 3  | loss: 0.99877 | valid_mse: 16.06408|  0:00:00s\n",
      "\n",
      "Epoch 3: valid_mse improved from 16.2077 to 16.0641\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 4  | loss: 0.83376 | valid_mse: 21.94813|  0:00:00s\n",
      "epoch 5  | loss: 0.80431 | valid_mse: 18.96688|  0:00:00s\n",
      "epoch 6  | loss: 0.77162 | valid_mse: 10767037.86687|  0:00:00s\n",
      "epoch 7  | loss: 0.71178 | valid_mse: 2743943.41718|  0:00:00s\n",
      "epoch 8  | loss: 0.66825 | valid_mse: 3743.40427|  0:00:00s\n",
      "epoch 9  | loss: 0.65831 | valid_mse: 3286.08677|  0:00:00s\n",
      "epoch 10 | loss: 0.65164 | valid_mse: 3243.38615|  0:00:00s\n",
      "epoch 11 | loss: 0.59276 | valid_mse: 2869.77389|  0:00:00s\n",
      "epoch 12 | loss: 0.58443 | valid_mse: 3279.18582|  0:00:00s\n",
      "epoch 13 | loss: 0.57378 | valid_mse: 1.31344 |  0:00:00s\n",
      "\n",
      "Epoch 13: valid_mse improved from 16.0641 to 1.3134\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 14 | loss: 0.55973 | valid_mse: 1.74533 |  0:00:00s\n",
      "epoch 15 | loss: 0.55111 | valid_mse: 1.69697 |  0:00:01s\n",
      "epoch 16 | loss: 0.5451  | valid_mse: 1.6659  |  0:00:01s\n",
      "epoch 17 | loss: 0.55654 | valid_mse: 1.10736 |  0:00:01s\n",
      "\n",
      "Epoch 17: valid_mse improved from 1.3134 to 1.1074\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 18 | loss: 0.54158 | valid_mse: 1.0671  |  0:00:01s\n",
      "\n",
      "Epoch 18: valid_mse improved from 1.1074 to 1.0671\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 19 | loss: 0.53629 | valid_mse: 1.01776 |  0:00:01s\n",
      "\n",
      "Epoch 19: valid_mse improved from 1.0671 to 1.0178\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 20 | loss: 0.53407 | valid_mse: 4830.12519|  0:00:01s\n",
      "epoch 21 | loss: 0.53946 | valid_mse: 4441.41221|  0:00:01s\n",
      "epoch 22 | loss: 0.52735 | valid_mse: 2070.59787|  0:00:01s\n",
      "epoch 23 | loss: 0.53884 | valid_mse: 1571.9854|  0:00:01s\n",
      "epoch 24 | loss: 0.51348 | valid_mse: 1406.37845|  0:00:01s\n",
      "epoch 25 | loss: 0.52989 | valid_mse: 803.73101|  0:00:01s\n",
      "epoch 26 | loss: 0.52687 | valid_mse: 1.22434 |  0:00:01s\n",
      "epoch 27 | loss: 0.525   | valid_mse: 0.90555 |  0:00:01s\n",
      "\n",
      "Epoch 27: valid_mse improved from 1.0178 to 0.9055\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 28 | loss: 0.51431 | valid_mse: 0.74845 |  0:00:01s\n",
      "\n",
      "Epoch 28: valid_mse improved from 0.9055 to 0.7485\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 29 | loss: 0.50911 | valid_mse: 0.77518 |  0:00:01s\n",
      "epoch 30 | loss: 0.50728 | valid_mse: 0.80837 |  0:00:02s\n",
      "epoch 31 | loss: 0.50859 | valid_mse: 0.81323 |  0:00:02s\n",
      "epoch 32 | loss: 0.51423 | valid_mse: 0.77792 |  0:00:02s\n",
      "epoch 33 | loss: 0.51049 | valid_mse: 0.79135 |  0:00:02s\n",
      "epoch 34 | loss: 0.51157 | valid_mse: 0.77043 |  0:00:02s\n",
      "epoch 35 | loss: 0.50248 | valid_mse: 0.67494 |  0:00:02s\n",
      "\n",
      "Epoch 35: valid_mse improved from 0.7485 to 0.6749\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 36 | loss: 0.4988  | valid_mse: 0.67462 |  0:00:02s\n",
      "\n",
      "Epoch 36: valid_mse improved from 0.6749 to 0.6746\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 37 | loss: 0.50119 | valid_mse: 0.67907 |  0:00:02s\n",
      "epoch 38 | loss: 0.49933 | valid_mse: 0.69437 |  0:00:02s\n",
      "epoch 39 | loss: 0.49944 | valid_mse: 0.72827 |  0:00:02s\n",
      "epoch 40 | loss: 0.49181 | valid_mse: 0.67764 |  0:00:02s\n",
      "epoch 41 | loss: 0.49487 | valid_mse: 0.70569 |  0:00:02s\n",
      "epoch 42 | loss: 0.49434 | valid_mse: 0.72534 |  0:00:02s\n",
      "epoch 43 | loss: 0.48757 | valid_mse: 5.09927 |  0:00:02s\n",
      "epoch 44 | loss: 0.49232 | valid_mse: 3.90293 |  0:00:02s\n",
      "epoch 45 | loss: 0.49338 | valid_mse: 3.53064 |  0:00:03s\n",
      "epoch 46 | loss: 0.48502 | valid_mse: 3.65636 |  0:00:03s\n",
      "epoch 47 | loss: 0.48549 | valid_mse: 1.0695  |  0:00:03s\n",
      "epoch 48 | loss: 0.48715 | valid_mse: 0.69218 |  0:00:03s\n",
      "epoch 49 | loss: 0.48651 | valid_mse: 0.70951 |  0:00:03s\n",
      "epoch 50 | loss: 0.48512 | valid_mse: 0.69762 |  0:00:03s\n",
      "epoch 51 | loss: 0.48329 | valid_mse: 0.6752  |  0:00:03s\n",
      "epoch 52 | loss: 0.48196 | valid_mse: 0.63608 |  0:00:03s\n",
      "\n",
      "Epoch 52: valid_mse improved from 0.6746 to 0.6361\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 53 | loss: 0.47975 | valid_mse: 0.60564 |  0:00:03s\n",
      "\n",
      "Epoch 53: valid_mse improved from 0.6361 to 0.6056\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 54 | loss: 0.48508 | valid_mse: 0.60938 |  0:00:03s\n",
      "epoch 55 | loss: 0.47203 | valid_mse: 0.64857 |  0:00:03s\n",
      "epoch 56 | loss: 0.47532 | valid_mse: 0.66532 |  0:00:03s\n",
      "epoch 57 | loss: 0.4795  | valid_mse: 0.64762 |  0:00:03s\n",
      "epoch 58 | loss: 0.4766  | valid_mse: 0.64591 |  0:00:03s\n",
      "epoch 59 | loss: 0.47444 | valid_mse: 0.64848 |  0:00:03s\n",
      "epoch 60 | loss: 0.47478 | valid_mse: 0.64192 |  0:00:03s\n",
      "epoch 61 | loss: 0.47124 | valid_mse: 0.638   |  0:00:04s\n",
      "epoch 62 | loss: 0.46864 | valid_mse: 0.63884 |  0:00:04s\n",
      "epoch 63 | loss: 0.4694  | valid_mse: 0.64541 |  0:00:04s\n",
      "epoch 64 | loss: 0.47358 | valid_mse: 0.62373 |  0:00:04s\n",
      "epoch 65 | loss: 0.45628 | valid_mse: 0.62909 |  0:00:04s\n",
      "epoch 66 | loss: 0.46429 | valid_mse: 0.64223 |  0:00:04s\n",
      "epoch 67 | loss: 0.46179 | valid_mse: 0.63996 |  0:00:04s\n",
      "epoch 68 | loss: 0.45448 | valid_mse: 0.63702 |  0:00:04s\n",
      "epoch 69 | loss: 0.45387 | valid_mse: 0.62016 |  0:00:04s\n",
      "epoch 70 | loss: 0.45557 | valid_mse: 0.61758 |  0:00:04s\n",
      "epoch 71 | loss: 0.4581  | valid_mse: 1.13    |  0:00:04s\n",
      "epoch 72 | loss: 0.46112 | valid_mse: 1.19195 |  0:00:04s\n",
      "epoch 73 | loss: 0.46052 | valid_mse: 1.15829 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 73 with best_epoch = 53 and best_valid_mse = 0.60564\n",
      "Fold 2 - Train QWK: 0.6452, Validation QWK: 0.3566\n",
      "(2189, 63) (547, 63)\n",
      "epoch 0  | loss: 4.17547 | valid_mse: 154.72759|  0:00:00s\n",
      "\n",
      "Epoch 0: valid_mse improved from inf to 154.7276\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 1  | loss: 2.17367 | valid_mse: 961.81088|  0:00:00s\n",
      "epoch 2  | loss: 1.3153  | valid_mse: 407.31014|  0:00:00s\n",
      "epoch 3  | loss: 0.93537 | valid_mse: 116.03052|  0:00:00s\n",
      "\n",
      "Epoch 3: valid_mse improved from 154.7276 to 116.0305\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 4  | loss: 0.76238 | valid_mse: 63.79934|  0:00:00s\n",
      "\n",
      "Epoch 4: valid_mse improved from 116.0305 to 63.7993\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 5  | loss: 0.6995  | valid_mse: 5.52733 |  0:00:00s\n",
      "\n",
      "Epoch 5: valid_mse improved from 63.7993 to 5.5273\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 6  | loss: 0.62515 | valid_mse: 5.40317 |  0:00:00s\n",
      "\n",
      "Epoch 6: valid_mse improved from 5.5273 to 5.4032\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 7  | loss: 0.58113 | valid_mse: 733.75573|  0:00:00s\n",
      "epoch 8  | loss: 0.59427 | valid_mse: 1421.42019|  0:00:00s\n",
      "epoch 9  | loss: 0.56998 | valid_mse: 451.40315|  0:00:00s\n",
      "epoch 10 | loss: 0.56326 | valid_mse: 601.73598|  0:00:00s\n",
      "epoch 11 | loss: 0.55897 | valid_mse: 529.05213|  0:00:00s\n",
      "epoch 12 | loss: 0.54289 | valid_mse: 1.59975 |  0:00:00s\n",
      "\n",
      "Epoch 12: valid_mse improved from 5.4032 to 1.5997\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 13 | loss: 0.53807 | valid_mse: 1.27987 |  0:00:00s\n",
      "\n",
      "Epoch 13: valid_mse improved from 1.5997 to 1.2799\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 14 | loss: 0.54473 | valid_mse: 1.02122 |  0:00:01s\n",
      "\n",
      "Epoch 14: valid_mse improved from 1.2799 to 1.0212\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 15 | loss: 0.52787 | valid_mse: 21.60105|  0:00:01s\n",
      "epoch 16 | loss: 0.52783 | valid_mse: 24.47475|  0:00:01s\n",
      "epoch 17 | loss: 0.52065 | valid_mse: 28.43779|  0:00:01s\n",
      "epoch 18 | loss: 0.52209 | valid_mse: 32.94267|  0:00:01s\n",
      "epoch 19 | loss: 0.51159 | valid_mse: 81.65124|  0:00:01s\n",
      "epoch 20 | loss: 0.52543 | valid_mse: 103.99064|  0:00:01s\n",
      "epoch 21 | loss: 0.51003 | valid_mse: 59.99294|  0:00:01s\n",
      "epoch 22 | loss: 0.51561 | valid_mse: 51.57893|  0:00:01s\n",
      "epoch 23 | loss: 0.5068  | valid_mse: 0.78746 |  0:00:01s\n",
      "\n",
      "Epoch 23: valid_mse improved from 1.0212 to 0.7875\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 24 | loss: 0.50495 | valid_mse: 0.67104 |  0:00:01s\n",
      "\n",
      "Epoch 24: valid_mse improved from 0.7875 to 0.6710\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 25 | loss: 0.50305 | valid_mse: 0.60536 |  0:00:01s\n",
      "\n",
      "Epoch 25: valid_mse improved from 0.6710 to 0.6054\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 26 | loss: 0.49909 | valid_mse: 0.59879 |  0:00:01s\n",
      "\n",
      "Epoch 26: valid_mse improved from 0.6054 to 0.5988\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 27 | loss: 0.49584 | valid_mse: 0.60747 |  0:00:01s\n",
      "epoch 28 | loss: 0.49184 | valid_mse: 0.60089 |  0:00:02s\n",
      "epoch 29 | loss: 0.48392 | valid_mse: 0.60198 |  0:00:02s\n",
      "epoch 30 | loss: 0.49476 | valid_mse: 0.6076  |  0:00:02s\n",
      "epoch 31 | loss: 0.48936 | valid_mse: 0.62076 |  0:00:02s\n",
      "epoch 32 | loss: 0.48379 | valid_mse: 0.62974 |  0:00:02s\n",
      "epoch 33 | loss: 0.48302 | valid_mse: 5.01056 |  0:00:02s\n",
      "epoch 34 | loss: 0.48568 | valid_mse: 0.61463 |  0:00:02s\n",
      "epoch 35 | loss: 0.48733 | valid_mse: 0.55474 |  0:00:02s\n",
      "\n",
      "Epoch 35: valid_mse improved from 0.5988 to 0.5547\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 36 | loss: 0.49433 | valid_mse: 0.57378 |  0:00:02s\n",
      "epoch 37 | loss: 0.4851  | valid_mse: 0.63877 |  0:00:02s\n",
      "epoch 38 | loss: 0.48776 | valid_mse: 0.53391 |  0:00:02s\n",
      "\n",
      "Epoch 38: valid_mse improved from 0.5547 to 0.5339\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 39 | loss: 0.49776 | valid_mse: 0.4999  |  0:00:02s\n",
      "\n",
      "Epoch 39: valid_mse improved from 0.5339 to 0.4999\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 40 | loss: 0.47421 | valid_mse: 0.48695 |  0:00:02s\n",
      "\n",
      "Epoch 40: valid_mse improved from 0.4999 to 0.4869\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 41 | loss: 0.4893  | valid_mse: 0.48499 |  0:00:02s\n",
      "\n",
      "Epoch 41: valid_mse improved from 0.4869 to 0.4850\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 42 | loss: 0.48213 | valid_mse: 0.49969 |  0:00:02s\n",
      "epoch 43 | loss: 0.4831  | valid_mse: 0.51738 |  0:00:03s\n",
      "epoch 44 | loss: 0.47531 | valid_mse: 2.15006 |  0:00:03s\n",
      "epoch 45 | loss: 0.48182 | valid_mse: 1.91391 |  0:00:03s\n",
      "epoch 46 | loss: 0.46828 | valid_mse: 2.13596 |  0:00:03s\n",
      "epoch 47 | loss: 0.4761  | valid_mse: 2.4365  |  0:00:03s\n",
      "epoch 48 | loss: 0.46306 | valid_mse: 0.57265 |  0:00:03s\n",
      "epoch 49 | loss: 0.47187 | valid_mse: 0.56797 |  0:00:03s\n",
      "epoch 50 | loss: 0.47581 | valid_mse: 0.55649 |  0:00:03s\n",
      "epoch 51 | loss: 0.46395 | valid_mse: 0.56024 |  0:00:03s\n",
      "epoch 52 | loss: 0.46138 | valid_mse: 0.5581  |  0:00:03s\n",
      "epoch 53 | loss: 0.45666 | valid_mse: 0.5575  |  0:00:03s\n",
      "epoch 54 | loss: 0.46525 | valid_mse: 0.54913 |  0:00:03s\n",
      "epoch 55 | loss: 0.4603  | valid_mse: 0.54519 |  0:00:03s\n",
      "epoch 56 | loss: 0.46044 | valid_mse: 0.55213 |  0:00:03s\n",
      "epoch 57 | loss: 0.45558 | valid_mse: 0.59369 |  0:00:03s\n",
      "epoch 58 | loss: 0.47079 | valid_mse: 0.60129 |  0:00:04s\n",
      "epoch 59 | loss: 0.4572  | valid_mse: 0.56923 |  0:00:04s\n",
      "epoch 60 | loss: 0.44399 | valid_mse: 0.55661 |  0:00:04s\n",
      "epoch 61 | loss: 0.45027 | valid_mse: 0.57003 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 41 and best_valid_mse = 0.48499\n",
      "Fold 3 - Train QWK: 0.6500, Validation QWK: 0.3621\n",
      "(2189, 63) (547, 63)\n",
      "epoch 0  | loss: 4.40067 | valid_mse: 68.26127|  0:00:00s\n",
      "\n",
      "Epoch 0: valid_mse improved from inf to 68.2613\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 1  | loss: 2.71376 | valid_mse: 17.4866 |  0:00:00s\n",
      "\n",
      "Epoch 1: valid_mse improved from 68.2613 to 17.4866\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 2  | loss: 1.72512 | valid_mse: 12.63056|  0:00:00s\n",
      "\n",
      "Epoch 2: valid_mse improved from 17.4866 to 12.6306\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 3  | loss: 1.18275 | valid_mse: 5.72932 |  0:00:00s\n",
      "\n",
      "Epoch 3: valid_mse improved from 12.6306 to 5.7293\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 4  | loss: 0.89975 | valid_mse: 19.00598|  0:00:00s\n",
      "epoch 5  | loss: 0.78093 | valid_mse: 18.08803|  0:00:00s\n",
      "epoch 6  | loss: 0.71486 | valid_mse: 10.80348|  0:00:00s\n",
      "epoch 7  | loss: 0.67173 | valid_mse: 8.66761 |  0:00:00s\n",
      "epoch 8  | loss: 0.64111 | valid_mse: 8.31147 |  0:00:00s\n",
      "epoch 9  | loss: 0.59252 | valid_mse: 4.93673 |  0:00:00s\n",
      "\n",
      "Epoch 9: valid_mse improved from 5.7293 to 4.9367\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 10 | loss: 0.59645 | valid_mse: 3.73745 |  0:00:00s\n",
      "\n",
      "Epoch 10: valid_mse improved from 4.9367 to 3.7375\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 11 | loss: 0.59945 | valid_mse: 2.85583 |  0:00:00s\n",
      "\n",
      "Epoch 11: valid_mse improved from 3.7375 to 2.8558\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 12 | loss: 0.57912 | valid_mse: 3.31983 |  0:00:01s\n",
      "epoch 13 | loss: 0.56955 | valid_mse: 4.0423  |  0:00:01s\n",
      "epoch 14 | loss: 0.56653 | valid_mse: 4.27448 |  0:00:01s\n",
      "epoch 15 | loss: 0.55742 | valid_mse: 4.3587  |  0:00:01s\n",
      "epoch 16 | loss: 0.55324 | valid_mse: 3.67148 |  0:00:01s\n",
      "epoch 17 | loss: 0.53671 | valid_mse: 2.88588 |  0:00:01s\n",
      "epoch 18 | loss: 0.53687 | valid_mse: 2.21734 |  0:00:01s\n",
      "\n",
      "Epoch 18: valid_mse improved from 2.8558 to 2.2173\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 19 | loss: 0.52056 | valid_mse: 1.48888 |  0:00:01s\n",
      "\n",
      "Epoch 19: valid_mse improved from 2.2173 to 1.4889\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 20 | loss: 0.53395 | valid_mse: 1.48609 |  0:00:01s\n",
      "\n",
      "Epoch 20: valid_mse improved from 1.4889 to 1.4861\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 21 | loss: 0.51612 | valid_mse: 1.42275 |  0:00:01s\n",
      "\n",
      "Epoch 21: valid_mse improved from 1.4861 to 1.4228\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 22 | loss: 0.5272  | valid_mse: 1.21068 |  0:00:01s\n",
      "\n",
      "Epoch 22: valid_mse improved from 1.4228 to 1.2107\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 23 | loss: 0.51597 | valid_mse: 0.96341 |  0:00:01s\n",
      "\n",
      "Epoch 23: valid_mse improved from 1.2107 to 0.9634\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 24 | loss: 0.50767 | valid_mse: 0.86451 |  0:00:01s\n",
      "\n",
      "Epoch 24: valid_mse improved from 0.9634 to 0.8645\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 25 | loss: 0.49882 | valid_mse: 0.88067 |  0:00:01s\n",
      "epoch 26 | loss: 0.51129 | valid_mse: 0.90995 |  0:00:02s\n",
      "epoch 27 | loss: 0.49803 | valid_mse: 0.89913 |  0:00:02s\n",
      "epoch 28 | loss: 0.50701 | valid_mse: 1.07758 |  0:00:02s\n",
      "epoch 29 | loss: 0.4899  | valid_mse: 1.26462 |  0:00:02s\n",
      "epoch 30 | loss: 0.496   | valid_mse: 1.38346 |  0:00:02s\n",
      "epoch 31 | loss: 0.49216 | valid_mse: 1.40531 |  0:00:02s\n",
      "epoch 32 | loss: 0.48771 | valid_mse: 1.31863 |  0:00:02s\n",
      "epoch 33 | loss: 0.48199 | valid_mse: 1.20686 |  0:00:02s\n",
      "epoch 34 | loss: 0.49283 | valid_mse: 1.11175 |  0:00:02s\n",
      "epoch 35 | loss: 0.48327 | valid_mse: 1.08911 |  0:00:02s\n",
      "epoch 36 | loss: 0.47999 | valid_mse: 1.03322 |  0:00:02s\n",
      "epoch 37 | loss: 0.47098 | valid_mse: 0.94021 |  0:00:02s\n",
      "epoch 38 | loss: 0.4795  | valid_mse: 0.96013 |  0:00:02s\n",
      "epoch 39 | loss: 0.49226 | valid_mse: 0.95586 |  0:00:02s\n",
      "epoch 40 | loss: 0.47489 | valid_mse: 1.01102 |  0:00:02s\n",
      "epoch 41 | loss: 0.4726  | valid_mse: 1.04978 |  0:00:02s\n",
      "epoch 42 | loss: 0.4704  | valid_mse: 1.12758 |  0:00:03s\n",
      "epoch 43 | loss: 0.47901 | valid_mse: 1.09247 |  0:00:03s\n",
      "epoch 44 | loss: 0.47887 | valid_mse: 0.96507 |  0:00:03s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_valid_mse = 0.86451\n",
      "Fold 4 - Train QWK: 0.6249, Validation QWK: 0.3790\n",
      "(2189, 63) (547, 63)\n",
      "epoch 0  | loss: 4.4565  | valid_mse: 105.45915|  0:00:00s\n",
      "\n",
      "Epoch 0: valid_mse improved from inf to 105.4591\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 1  | loss: 2.11192 | valid_mse: 39.28654|  0:00:00s\n",
      "\n",
      "Epoch 1: valid_mse improved from 105.4591 to 39.2865\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 2  | loss: 1.20624 | valid_mse: 25.84205|  0:00:00s\n",
      "\n",
      "Epoch 2: valid_mse improved from 39.2865 to 25.8421\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 3  | loss: 0.8891  | valid_mse: 7.34464 |  0:00:00s\n",
      "\n",
      "Epoch 3: valid_mse improved from 25.8421 to 7.3446\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 4  | loss: 0.74684 | valid_mse: 10.67714|  0:00:00s\n",
      "epoch 5  | loss: 0.71342 | valid_mse: 26.00716|  0:00:00s\n",
      "epoch 6  | loss: 0.6391  | valid_mse: 9.73531 |  0:00:00s\n",
      "epoch 7  | loss: 0.61505 | valid_mse: 5.76191 |  0:00:00s\n",
      "\n",
      "Epoch 7: valid_mse improved from 7.3446 to 5.7619\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 8  | loss: 0.58266 | valid_mse: 4.42681 |  0:00:00s\n",
      "\n",
      "Epoch 8: valid_mse improved from 5.7619 to 4.4268\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 9  | loss: 0.57677 | valid_mse: 3.32998 |  0:00:00s\n",
      "\n",
      "Epoch 9: valid_mse improved from 4.4268 to 3.3300\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 10 | loss: 0.55835 | valid_mse: 3.24587 |  0:00:00s\n",
      "\n",
      "Epoch 10: valid_mse improved from 3.3300 to 3.2459\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 11 | loss: 0.55334 | valid_mse: 2.75935 |  0:00:00s\n",
      "\n",
      "Epoch 11: valid_mse improved from 3.2459 to 2.7594\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 12 | loss: 0.54408 | valid_mse: 2.17675 |  0:00:00s\n",
      "\n",
      "Epoch 12: valid_mse improved from 2.7594 to 2.1767\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 13 | loss: 0.52643 | valid_mse: 1.85399 |  0:00:01s\n",
      "\n",
      "Epoch 13: valid_mse improved from 2.1767 to 1.8540\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 14 | loss: 0.5236  | valid_mse: 3.26446 |  0:00:01s\n",
      "epoch 15 | loss: 0.52679 | valid_mse: 3.75354 |  0:00:01s\n",
      "epoch 16 | loss: 0.52326 | valid_mse: 6.13372 |  0:00:01s\n",
      "epoch 17 | loss: 0.52746 | valid_mse: 3.34228 |  0:00:01s\n",
      "epoch 18 | loss: 0.51099 | valid_mse: 13.6597 |  0:00:01s\n",
      "epoch 19 | loss: 0.5173  | valid_mse: 9.8919  |  0:00:01s\n",
      "epoch 20 | loss: 0.50742 | valid_mse: 7.24477 |  0:00:01s\n",
      "epoch 21 | loss: 0.50367 | valid_mse: 1.44699 |  0:00:01s\n",
      "\n",
      "Epoch 21: valid_mse improved from 1.8540 to 1.4470\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 22 | loss: 0.49733 | valid_mse: 2.93931 |  0:00:01s\n",
      "epoch 23 | loss: 0.49565 | valid_mse: 1.42477 |  0:00:01s\n",
      "\n",
      "Epoch 23: valid_mse improved from 1.4470 to 1.4248\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 24 | loss: 0.49436 | valid_mse: 3.59224 |  0:00:01s\n",
      "epoch 25 | loss: 0.48211 | valid_mse: 3.43347 |  0:00:01s\n",
      "epoch 26 | loss: 0.49102 | valid_mse: 2.93654 |  0:00:01s\n",
      "epoch 27 | loss: 0.47875 | valid_mse: 1.85615 |  0:00:01s\n",
      "epoch 28 | loss: 0.48182 | valid_mse: 1.51226 |  0:00:02s\n",
      "epoch 29 | loss: 0.47727 | valid_mse: 1.36432 |  0:00:02s\n",
      "\n",
      "Epoch 29: valid_mse improved from 1.4248 to 1.3643\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 30 | loss: 0.47134 | valid_mse: 1.3223  |  0:00:02s\n",
      "\n",
      "Epoch 30: valid_mse improved from 1.3643 to 1.3223\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 31 | loss: 0.45995 | valid_mse: 1.71555 |  0:00:02s\n",
      "epoch 32 | loss: 0.47274 | valid_mse: 1.9277  |  0:00:02s\n",
      "epoch 33 | loss: 0.46335 | valid_mse: 1.91753 |  0:00:02s\n",
      "epoch 34 | loss: 0.45937 | valid_mse: 1.84203 |  0:00:02s\n",
      "epoch 35 | loss: 0.46876 | valid_mse: 1.66236 |  0:00:02s\n",
      "epoch 36 | loss: 0.45014 | valid_mse: 1.47396 |  0:00:02s\n",
      "epoch 37 | loss: 0.46029 | valid_mse: 1.28684 |  0:00:02s\n",
      "\n",
      "Epoch 37: valid_mse improved from 1.3223 to 1.2868\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 38 | loss: 0.44481 | valid_mse: 1.21133 |  0:00:02s\n",
      "\n",
      "Epoch 38: valid_mse improved from 1.2868 to 1.2113\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 39 | loss: 0.45959 | valid_mse: 1.12695 |  0:00:02s\n",
      "\n",
      "Epoch 39: valid_mse improved from 1.2113 to 1.1270\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 40 | loss: 0.44219 | valid_mse: 1.09815 |  0:00:03s\n",
      "\n",
      "Epoch 40: valid_mse improved from 1.1270 to 1.0981\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 41 | loss: 0.45566 | valid_mse: 0.99571 |  0:00:03s\n",
      "\n",
      "Epoch 41: valid_mse improved from 1.0981 to 0.9957\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 42 | loss: 0.44422 | valid_mse: 0.9398  |  0:00:03s\n",
      "\n",
      "Epoch 42: valid_mse improved from 0.9957 to 0.9398\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 43 | loss: 0.44221 | valid_mse: 0.92847 |  0:00:03s\n",
      "\n",
      "Epoch 43: valid_mse improved from 0.9398 to 0.9285\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 44 | loss: 0.44198 | valid_mse: 0.95399 |  0:00:03s\n",
      "epoch 45 | loss: 0.44371 | valid_mse: 0.95919 |  0:00:03s\n",
      "epoch 46 | loss: 0.43369 | valid_mse: 1.04902 |  0:00:03s\n",
      "epoch 47 | loss: 0.44298 | valid_mse: 0.94203 |  0:00:03s\n",
      "epoch 48 | loss: 0.43511 | valid_mse: 0.79609 |  0:00:03s\n",
      "\n",
      "Epoch 48: valid_mse improved from 0.9285 to 0.7961\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 49 | loss: 0.44155 | valid_mse: 0.82986 |  0:00:03s\n",
      "epoch 50 | loss: 0.44153 | valid_mse: 0.76074 |  0:00:03s\n",
      "\n",
      "Epoch 50: valid_mse improved from 0.7961 to 0.7607\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 51 | loss: 0.44642 | valid_mse: 0.71387 |  0:00:03s\n",
      "\n",
      "Epoch 51: valid_mse improved from 0.7607 to 0.7139\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 52 | loss: 0.44304 | valid_mse: 0.71137 |  0:00:03s\n",
      "\n",
      "Epoch 52: valid_mse improved from 0.7139 to 0.7114\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 53 | loss: 0.44661 | valid_mse: 0.72623 |  0:00:04s\n",
      "epoch 54 | loss: 0.44646 | valid_mse: 0.73637 |  0:00:04s\n",
      "epoch 55 | loss: 0.44224 | valid_mse: 0.75692 |  0:00:04s\n",
      "epoch 56 | loss: 0.443   | valid_mse: 0.72297 |  0:00:04s\n",
      "epoch 57 | loss: 0.43133 | valid_mse: 0.67649 |  0:00:04s\n",
      "\n",
      "Epoch 57: valid_mse improved from 0.7114 to 0.6765\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 58 | loss: 0.42353 | valid_mse: 0.65451 |  0:00:04s\n",
      "\n",
      "Epoch 58: valid_mse improved from 0.6765 to 0.6545\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 59 | loss: 0.43433 | valid_mse: 0.62488 |  0:00:04s\n",
      "\n",
      "Epoch 59: valid_mse improved from 0.6545 to 0.6249\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 60 | loss: 0.43797 | valid_mse: 0.64413 |  0:00:04s\n",
      "epoch 61 | loss: 0.4325  | valid_mse: 0.67714 |  0:00:04s\n",
      "epoch 62 | loss: 0.42074 | valid_mse: 0.71534 |  0:00:04s\n",
      "epoch 63 | loss: 0.4268  | valid_mse: 0.667   |  0:00:04s\n",
      "epoch 64 | loss: 0.42815 | valid_mse: 0.62821 |  0:00:04s\n",
      "epoch 65 | loss: 0.42424 | valid_mse: 0.62488 |  0:00:04s\n",
      "\n",
      "Epoch 65: valid_mse improved from 0.6249 to 0.6249\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 66 | loss: 0.4238  | valid_mse: 0.61591 |  0:00:05s\n",
      "\n",
      "Epoch 66: valid_mse improved from 0.6249 to 0.6159\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 67 | loss: 0.42438 | valid_mse: 0.59575 |  0:00:05s\n",
      "\n",
      "Epoch 67: valid_mse improved from 0.6159 to 0.5957\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 68 | loss: 0.42145 | valid_mse: 0.58733 |  0:00:05s\n",
      "\n",
      "Epoch 68: valid_mse improved from 0.5957 to 0.5873\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 69 | loss: 0.43051 | valid_mse: 0.59146 |  0:00:05s\n",
      "epoch 70 | loss: 0.41377 | valid_mse: 0.57679 |  0:00:05s\n",
      "\n",
      "Epoch 70: valid_mse improved from 0.5873 to 0.5768\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 71 | loss: 0.41306 | valid_mse: 0.55267 |  0:00:05s\n",
      "\n",
      "Epoch 71: valid_mse improved from 0.5768 to 0.5527\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 72 | loss: 0.42416 | valid_mse: 0.54961 |  0:00:05s\n",
      "\n",
      "Epoch 72: valid_mse improved from 0.5527 to 0.5496\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 73 | loss: 0.41417 | valid_mse: 0.55976 |  0:00:05s\n",
      "epoch 74 | loss: 0.40998 | valid_mse: 0.57094 |  0:00:05s\n",
      "epoch 75 | loss: 0.41204 | valid_mse: 0.55477 |  0:00:05s\n",
      "epoch 76 | loss: 0.41218 | valid_mse: 0.55696 |  0:00:05s\n",
      "epoch 77 | loss: 0.41671 | valid_mse: 0.56277 |  0:00:05s\n",
      "epoch 78 | loss: 0.4083  | valid_mse: 0.58768 |  0:00:05s\n",
      "epoch 79 | loss: 0.39988 | valid_mse: 0.59351 |  0:00:06s\n",
      "epoch 80 | loss: 0.40251 | valid_mse: 0.59326 |  0:00:06s\n",
      "epoch 81 | loss: 0.40521 | valid_mse: 0.56965 |  0:00:06s\n",
      "epoch 82 | loss: 0.39733 | valid_mse: 0.55078 |  0:00:06s\n",
      "epoch 83 | loss: 0.40113 | valid_mse: 0.57603 |  0:00:06s\n",
      "epoch 84 | loss: 0.39844 | valid_mse: 0.60031 |  0:00:06s\n",
      "epoch 85 | loss: 0.39705 | valid_mse: 0.59028 |  0:00:06s\n",
      "epoch 86 | loss: 0.40489 | valid_mse: 0.55765 |  0:00:06s\n",
      "epoch 87 | loss: 0.3925  | valid_mse: 0.54715 |  0:00:06s\n",
      "\n",
      "Epoch 87: valid_mse improved from 0.5496 to 0.5472\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 88 | loss: 0.40072 | valid_mse: 0.5511  |  0:00:06s\n",
      "epoch 89 | loss: 0.39974 | valid_mse: 0.55686 |  0:00:06s\n",
      "epoch 90 | loss: 0.40107 | valid_mse: 0.54913 |  0:00:06s\n",
      "epoch 91 | loss: 0.40598 | valid_mse: 0.53785 |  0:00:06s\n",
      "\n",
      "Epoch 91: valid_mse improved from 0.5472 to 0.5378\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 92 | loss: 0.39439 | valid_mse: 0.53118 |  0:00:07s\n",
      "\n",
      "Epoch 92: valid_mse improved from 0.5378 to 0.5312\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 93 | loss: 0.39057 | valid_mse: 0.53651 |  0:00:07s\n",
      "epoch 94 | loss: 0.39693 | valid_mse: 0.52349 |  0:00:07s\n",
      "\n",
      "Epoch 94: valid_mse improved from 0.5312 to 0.5235\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 95 | loss: 0.39552 | valid_mse: 0.51666 |  0:00:07s\n",
      "\n",
      "Epoch 95: valid_mse improved from 0.5235 to 0.5167\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 96 | loss: 0.39086 | valid_mse: 0.51291 |  0:00:07s\n",
      "\n",
      "Epoch 96: valid_mse improved from 0.5167 to 0.5129\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 97 | loss: 0.39063 | valid_mse: 0.51928 |  0:00:07s\n",
      "epoch 98 | loss: 0.38652 | valid_mse: 0.51493 |  0:00:07s\n",
      "epoch 99 | loss: 0.38282 | valid_mse: 0.51458 |  0:00:07s\n",
      "epoch 100| loss: 0.38645 | valid_mse: 0.50281 |  0:00:07s\n",
      "\n",
      "Epoch 100: valid_mse improved from 0.5129 to 0.5028\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 101| loss: 0.38827 | valid_mse: 0.50518 |  0:00:07s\n",
      "epoch 102| loss: 0.38612 | valid_mse: 0.50097 |  0:00:07s\n",
      "\n",
      "Epoch 102: valid_mse improved from 0.5028 to 0.5010\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 103| loss: 0.38161 | valid_mse: 0.5119  |  0:00:07s\n",
      "epoch 104| loss: 0.38186 | valid_mse: 0.51973 |  0:00:07s\n",
      "epoch 105| loss: 0.37756 | valid_mse: 0.49687 |  0:00:08s\n",
      "\n",
      "Epoch 105: valid_mse improved from 0.5010 to 0.4969\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 106| loss: 0.39032 | valid_mse: 0.49336 |  0:00:08s\n",
      "\n",
      "Epoch 106: valid_mse improved from 0.4969 to 0.4934\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 107| loss: 0.38756 | valid_mse: 0.48822 |  0:00:08s\n",
      "\n",
      "Epoch 107: valid_mse improved from 0.4934 to 0.4882\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 108| loss: 0.37758 | valid_mse: 0.49432 |  0:00:08s\n",
      "epoch 109| loss: 0.38769 | valid_mse: 0.49632 |  0:00:08s\n",
      "epoch 110| loss: 0.38861 | valid_mse: 0.49557 |  0:00:08s\n",
      "epoch 111| loss: 0.37842 | valid_mse: 0.49823 |  0:00:08s\n",
      "epoch 112| loss: 0.37092 | valid_mse: 0.50339 |  0:00:08s\n",
      "epoch 113| loss: 0.37269 | valid_mse: 0.51858 |  0:00:08s\n",
      "epoch 114| loss: 0.36385 | valid_mse: 0.52218 |  0:00:08s\n",
      "epoch 115| loss: 0.35929 | valid_mse: 0.50583 |  0:00:08s\n",
      "epoch 116| loss: 0.36717 | valid_mse: 0.50416 |  0:00:08s\n",
      "epoch 117| loss: 0.36879 | valid_mse: 0.51052 |  0:00:08s\n",
      "epoch 118| loss: 0.36128 | valid_mse: 0.54214 |  0:00:08s\n",
      "epoch 119| loss: 0.34763 | valid_mse: 0.52875 |  0:00:08s\n",
      "epoch 120| loss: 0.36719 | valid_mse: 0.52373 |  0:00:09s\n",
      "epoch 121| loss: 0.35687 | valid_mse: 0.52359 |  0:00:09s\n",
      "epoch 122| loss: 0.35954 | valid_mse: 0.53071 |  0:00:09s\n",
      "epoch 123| loss: 0.35616 | valid_mse: 0.55874 |  0:00:09s\n",
      "epoch 124| loss: 0.3505  | valid_mse: 0.57202 |  0:00:09s\n",
      "epoch 125| loss: 0.35887 | valid_mse: 0.56458 |  0:00:09s\n",
      "epoch 126| loss: 0.36371 | valid_mse: 0.5456  |  0:00:09s\n",
      "epoch 127| loss: 0.3531  | valid_mse: 0.72655 |  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 127 with best_epoch = 107 and best_valid_mse = 0.48822\n",
      "Fold 5 - Train QWK: 0.6743, Validation QWK: 0.3999\n",
      "CV: 0.3700\n",
      "tuned Kappa: 0.442\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import (\n",
    "    VotingRegressor,\n",
    "    RandomForestRegressor,\n",
    "    GradientBoostingRegressor,\n",
    ")\n",
    "\n",
    "\n",
    "def extract_features(df):\n",
    "    return df[double_columns + add_features]\n",
    "\n",
    "\n",
    "seed = 42\n",
    "oof = []\n",
    "cv_scores = []\n",
    "y = None\n",
    "\n",
    "# Model parameters for LightGBM\n",
    "Params = {\n",
    "    \"learning_rate\": 0.046,\n",
    "    \"max_depth\": 12,\n",
    "    \"num_leaves\": 478,\n",
    "    \"min_data_in_leaf\": 13,\n",
    "    \"feature_fraction\": 0.893,\n",
    "    \"bagging_fraction\": 0.784,\n",
    "    \"bagging_freq\": 4,\n",
    "    \"lambda_l1\": 10,  # Increased from 6.59\n",
    "    \"lambda_l2\": 0.01,  # Increased from 2.68e-06\n",
    "}\n",
    "XGB_Params = {\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"max_depth\": 6,\n",
    "    \"n_estimators\": 200,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"reg_alpha\": 1,  # Increased from 0.1\n",
    "    \"reg_lambda\": 5,  # Increased from 1\n",
    "    \"random_state\": seed,\n",
    "}\n",
    "\n",
    "\n",
    "CatBoost_Params = {\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"depth\": 6,\n",
    "    \"iterations\": 200,\n",
    "    \"random_seed\": seed,\n",
    "    \"verbose\": 0,\n",
    "    \"l2_leaf_reg\": 10,  # Increase this value\n",
    "}\n",
    "\n",
    "for fold in range(5):\n",
    "    Light = LGBMRegressor(**Params, random_state=seed, verbose=-1, n_estimators=300)\n",
    "    XGB_Model = XGBRegressor(**XGB_Params)\n",
    "    CatBoost_Model = CatBoostRegressor(**CatBoost_Params)\n",
    "    TabNet_Model = TabNetWrapper(**TabNet_Params)  # New\n",
    "\n",
    "    model = VotingRegressor(\n",
    "        estimators=[\n",
    "            (\"lightgbm\", Light),\n",
    "            (\"xgboost\", XGB_Model),\n",
    "            (\"catboost\", CatBoost_Model),\n",
    "            (\"tabnet\", TabNet_Model),\n",
    "        ]\n",
    "    )\n",
    "    # model = LGBMRegressor(**Params, random_state=seed, verbose=-1, n_estimators=300)\n",
    "\n",
    "    with open(f\"../divided-datasets/fold_train_ids_{fold}.pkl\", \"rb\") as f:\n",
    "        fold_train_ids = pickle.load(f)\n",
    "\n",
    "    with open(f\"../divided-datasets/fold_valid_ids_{fold}.pkl\", \"rb\") as f:\n",
    "        fold_valid_ids = pickle.load(f)\n",
    "\n",
    "    train_fold = train[train[\"id\"].isin(fold_train_ids)].reset_index(drop=True)\n",
    "    valid_fold = train[train[\"id\"].isin(fold_valid_ids)].reset_index(drop=True)\n",
    "\n",
    "    mode = \"drop\"\n",
    "\n",
    "    if mode == \"impute\":\n",
    "        numeric_cols = train.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
    "        imputer = KNNImputer(n_neighbors=5)\n",
    "        train_fold[numeric_cols] = imputer.fit_transform(train_fold[numeric_cols])\n",
    "        test[numeric_cols] = imputer.transform(test[numeric_cols])\n",
    "    elif mode == \"drop\":\n",
    "        train_fold = train_fold[train_fold[\"sii\"].notnull()].reset_index(drop=True)\n",
    "\n",
    "    train_fold_x = extract_features(train_fold)\n",
    "    valid_fold_x = extract_features(valid_fold)\n",
    "\n",
    "    train_fold_y = train_fold[\"sii\"].astype(int)\n",
    "    valid_fold_y = valid_fold[\"sii\"].astype(int)\n",
    "\n",
    "    print(train_fold_x.shape, valid_fold_x.shape)\n",
    "\n",
    "    model.fit(train_fold_x, train_fold_y)\n",
    "\n",
    "    # save model\n",
    "    with open(f\"./assets/model01_{fold}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "    train_pred = model.predict(train_fold_x)\n",
    "    valid_pred = model.predict(valid_fold_x)\n",
    "\n",
    "    train_kappa = quadratic_weighted_kappa(\n",
    "        train_fold_y, train_pred.round(0).astype(int)\n",
    "    )\n",
    "    val_kappa = quadratic_weighted_kappa(valid_fold_y, valid_pred.round(0).astype(int))\n",
    "    cv_scores.append(val_kappa)\n",
    "\n",
    "    print(\n",
    "        f\"Fold {fold+1} - Train QWK: {train_kappa:.4f}, Validation QWK: {val_kappa:.4f}\"\n",
    "    )\n",
    "\n",
    "    for i, id_ in enumerate(fold_valid_ids):\n",
    "        oof.append({\"id\": id_, \"sii\": valid_pred[i]})\n",
    "\n",
    "    if y is None:\n",
    "        y = valid_fold[[\"id\", \"sii\"]]\n",
    "    else:\n",
    "        y = pd.concat([y, valid_fold[[\"id\", \"sii\"]]], axis=0).reset_index(drop=True)\n",
    "\n",
    "oof = pd.DataFrame(oof)\n",
    "\n",
    "KappaOPtimizer = minimize(\n",
    "    evaluate_predictions,\n",
    "    x0=[0.5, 1.5, 2.5],\n",
    "    args=(y[\"sii\"].astype(int), oof[\"sii\"]),\n",
    "    method=\"Nelder-Mead\",\n",
    ")\n",
    "\n",
    "oof_tuned = threshold_Rounder(oof[\"sii\"], KappaOPtimizer.x)\n",
    "tKappa = quadratic_weighted_kappa(y[\"sii\"], oof_tuned)\n",
    "print(f\"CV: {np.mean(cv_scores):.4f}\")\n",
    "print(f\"tuned Kappa: {tKappa:.3f}\")  # tuned Kappa: 0.451"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof.to_csv(\"./oof/oof.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
