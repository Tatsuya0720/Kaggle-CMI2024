{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# from src.dataloader_ import *\n",
    "# from src.network_ import *\n",
    "from src.utils import *\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "\n",
    "train_series_dir = \"../../../inputs/series_train.parquet/\"\n",
    "test_series_dir = \"../../../inputs/series_test.parquet/\"\n",
    "\n",
    "data_dic_path = \"../../../inputs/data_dictionary.csv\"\n",
    "sample_submission_path = \"../../../inputs/sample_submission.csv\"\n",
    "train_path = \"../../../inputs/train.csv\"\n",
    "test_path = \"../../../inputs/test.csv\"\n",
    "\n",
    "train = pd.read_csv(train_path)\n",
    "test = pd.read_csv(test_path)\n",
    "sample_submission = pd.read_csv(sample_submission_path)\n",
    "data_dic = pd.read_csv(data_dic_path)\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def seed_torch(seed=1029):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "nb_name = os.path.basename(os.getcwd())  # notebook name\n",
    "seed_torch(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの前処理\n",
    "\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "\n",
    "add_features = [\n",
    "    \"BMI_Age\",\n",
    "    \"Internet_Hours_Age\",\n",
    "    \"BMI_Internet_Hours\",\n",
    "    \"BFP_BMI\",\n",
    "    \"FFMI_BFP\",\n",
    "    \"FMI_BFP\",\n",
    "    \"LST_TBW\",\n",
    "    \"BFP_BMR\",\n",
    "    \"BFP_DEE\",\n",
    "    \"BMR_Weight\",\n",
    "    \"DEE_Weight\",\n",
    "    \"SMM_Height\",\n",
    "    \"Muscle_to_Fat\",\n",
    "    \"Hydration_Status\",\n",
    "    \"ICW_TBW\",\n",
    "]\n",
    "\n",
    "double_columns = [\n",
    "    \"FGC-FGC_SRR_Zone\",\n",
    "    \"BIA-BIA_SMM\",\n",
    "    \"Physical-Waist_Circumference\",\n",
    "    \"BIA-BIA_FFMI\",\n",
    "    \"FGC-FGC_CU\",\n",
    "    \"PreInt_EduHx-computerinternet_hoursday\",\n",
    "    \"BIA-BIA_ECW\",\n",
    "    \"FGC-FGC_CU_Zone\",\n",
    "    \"FGC-FGC_SRL_Zone\",\n",
    "    \"BIA-BIA_DEE\",\n",
    "    \"Physical-Weight\",\n",
    "    \"Fitness_Endurance-Time_Mins\",\n",
    "    \"FGC-FGC_SRR\",\n",
    "    \"SDS-SDS_Total_T\",\n",
    "    \"FGC-FGC_PU\",\n",
    "    \"BIA-BIA_FFM\",\n",
    "    \"FGC-FGC_TL_Zone\",\n",
    "    \"Physical-BMI\",\n",
    "    \"Physical-Systolic_BP\",\n",
    "    \"Physical-HeartRate\",\n",
    "    \"BIA-BIA_ICW\",\n",
    "    \"Physical-Height\",\n",
    "    \"FGC-FGC_SRL\",\n",
    "    \"BIA-BIA_BMC\",\n",
    "    \"Fitness_Endurance-Time_Sec\",\n",
    "    \"BIA-BIA_Frame_num\",\n",
    "    \"Basic_Demos-Age\",\n",
    "    \"FGC-FGC_GSND_Zone\",\n",
    "    \"Basic_Demos-Sex\",\n",
    "    \"FGC-FGC_GSND\",\n",
    "    \"BIA-BIA_LST\",\n",
    "    \"FGC-FGC_TL\",\n",
    "    \"BIA-BIA_BMI\",\n",
    "    \"BIA-BIA_FMI\",\n",
    "    \"PAQ_C-PAQ_C_Total\",\n",
    "    \"BIA-BIA_Activity_Level_num\",\n",
    "    \"FGC-FGC_GSD\",\n",
    "    \"BIA-BIA_BMR\",\n",
    "    \"BIA-BIA_Fat\",\n",
    "    \"SDS-SDS_Total_Raw\",\n",
    "    \"CGAS-CGAS_Score\",\n",
    "    \"FGC-FGC_PU_Zone\",\n",
    "    \"BIA-BIA_LDM\",\n",
    "    \"Fitness_Endurance-Max_Stage\",\n",
    "    \"PAQ_A-PAQ_A_Total\",\n",
    "    \"BIA-BIA_TBW\",\n",
    "    \"FGC-FGC_GSD_Zone\",\n",
    "    \"Physical-Diastolic_BP\",\n",
    "]\n",
    "\n",
    "\n",
    "def feature_engineering(df):\n",
    "    # season_cols = [col for col in df.columns if \"Season\" in col]\n",
    "    # df = df.drop(season_cols, axis=1)\n",
    "    df[\"BMI_Age\"] = df[\"Physical-BMI\"] * df[\"Basic_Demos-Age\"]\n",
    "    df[\"Internet_Hours_Age\"] = (\n",
    "        df[\"PreInt_EduHx-computerinternet_hoursday\"] * df[\"Basic_Demos-Age\"]\n",
    "    )\n",
    "    df[\"BMI_Internet_Hours\"] = (\n",
    "        df[\"Physical-BMI\"] * df[\"PreInt_EduHx-computerinternet_hoursday\"]\n",
    "    )\n",
    "    df[\"BFP_BMI\"] = df[\"BIA-BIA_Fat\"] / df[\"BIA-BIA_BMI\"]\n",
    "    df[\"FFMI_BFP\"] = df[\"BIA-BIA_FFMI\"] / df[\"BIA-BIA_Fat\"]\n",
    "    df[\"FMI_BFP\"] = df[\"BIA-BIA_FMI\"] / df[\"BIA-BIA_Fat\"]\n",
    "    df[\"LST_TBW\"] = df[\"BIA-BIA_LST\"] / df[\"BIA-BIA_TBW\"]\n",
    "    df[\"BFP_BMR\"] = df[\"BIA-BIA_Fat\"] * df[\"BIA-BIA_BMR\"]\n",
    "    df[\"BFP_DEE\"] = df[\"BIA-BIA_Fat\"] * df[\"BIA-BIA_DEE\"]\n",
    "    df[\"BMR_Weight\"] = df[\"BIA-BIA_BMR\"] / df[\"Physical-Weight\"]\n",
    "    df[\"DEE_Weight\"] = df[\"BIA-BIA_DEE\"] / df[\"Physical-Weight\"]\n",
    "    df[\"SMM_Height\"] = df[\"BIA-BIA_SMM\"] / df[\"Physical-Height\"]\n",
    "    df[\"Muscle_to_Fat\"] = df[\"BIA-BIA_SMM\"] / df[\"BIA-BIA_FMI\"]\n",
    "    df[\"Hydration_Status\"] = df[\"BIA-BIA_TBW\"] / df[\"Physical-Weight\"]\n",
    "    df[\"ICW_TBW\"] = df[\"BIA-BIA_ICW\"] / df[\"BIA-BIA_TBW\"]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "train = feature_engineering(train)\n",
    "train = train.replace([np.inf, -np.inf], np.nan)\n",
    "for add_ in add_features:\n",
    "    train[add_] = train[add_].fillna(0.0)\n",
    "train = train.dropna(thresh=10, axis=0)\n",
    "\n",
    "test = feature_engineering(test)\n",
    "test = test.replace([np.inf, -np.inf], np.nan)\n",
    "for add_ in add_features:\n",
    "    test[add_] = test[add_].fillna(0.0)\n",
    "test = test.dropna(thresh=10, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 24, 60, 15) (31, 24, 60, 15)\n",
      "(31, 24, 15) (31, 24, 15) (31, 24, 30)\n",
      "(744, 30)\n",
      "torch.Size([1, 744, 30])\n",
      "CNN AutoEncoder output shape: torch.Size([1, 744, 30]) torch.Size([1, 128, 186])\n"
     ]
    }
   ],
   "source": [
    "# AutoEncoderの学習\n",
    "\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def read_parquet(base_dir, id_):\n",
    "    path = os.path.join(base_dir, f\"id={id_}\", \"part-0.parquet\")\n",
    "    return pd.read_parquet(path)\n",
    "\n",
    "\n",
    "def get_valid_ids(base_dir):\n",
    "    return [f.split(\"=\")[1].split(\".\")[0] for f in os.listdir(base_dir)]\n",
    "\n",
    "\n",
    "p = read_parquet(base_dir=\"../../../inputs/series_train.parquet/\", id_=\"ffcd4dbd\")\n",
    "# p = read_parquet(base_dir=\"../../inputs/series_train.parquet/\", id_=\"10e46254\")\n",
    "\n",
    "scale_columns = [\n",
    "    \"X\",\n",
    "    \"Y\",\n",
    "    \"Z\",\n",
    "    \"enmo\",\n",
    "    \"anglez\",\n",
    "    \"light\",\n",
    "    \"battery_voltage\",\n",
    "]\n",
    "\n",
    "masked_columns = [\n",
    "    \"masked_X\",\n",
    "    \"masked_Y\",\n",
    "    \"masked_Z\",\n",
    "    \"masked_enmo\",\n",
    "    \"masked_anglez\",\n",
    "    \"masked_light\",\n",
    "]\n",
    "\n",
    "original_columns = [\"battery_voltage\", \"non-wear_flag\"]\n",
    "\n",
    "p[\"non-wear_flag\"] = 1 - p[\"non-wear_flag\"]\n",
    "scaler_features = p[scale_columns].values\n",
    "scaler = StandardScaler()\n",
    "p[scale_columns] = scaler.fit_transform(scaler_features)\n",
    "\n",
    "for mask_col in masked_columns:\n",
    "    p[mask_col] = p[mask_col.replace(\"masked_\", \"\")] * p[\"non-wear_flag\"]\n",
    "\n",
    "p = p.fillna(0.0)\n",
    "\n",
    "groups = p.groupby(\"relative_date_PCIAT\")\n",
    "# グループごとにデータフレームのリストに分割\n",
    "chunks = [group.reset_index(drop=True) for _, group in groups]\n",
    "\n",
    "use_cols = masked_columns + original_columns + scale_columns\n",
    "watch_day = len(chunks)\n",
    "active_logs = np.zeros((31, 17280, len(use_cols)), dtype=np.float32)\n",
    "active_mask = np.zeros((31), dtype=np.int32)\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    if i == 0:  #\n",
    "        active_logs[i, -len(chunk) :, :] = chunk[use_cols].values\n",
    "    elif i == watch_day:\n",
    "        active_logs[i, : len(chunk), :] = chunk[use_cols].values\n",
    "    else:\n",
    "        array = chunk[use_cols].values\n",
    "        active_logs[i, : len(array), :] = array\n",
    "\n",
    "    active_mask[i] = 1\n",
    "\n",
    "    if i == 30:\n",
    "        break\n",
    "\n",
    "active_logs = active_logs.reshape(31, 24, 60, 12, 15)  # 12は1時間の分割数\n",
    "active_logs_mean = active_logs.mean(axis=3)  # 1時間の分割数で平均を取る # 31, 1440, 15\n",
    "# active_logs_var = active_logs.var(axis=3)  # 1時間の分割数で分散を取る # 31, 1440, 15\n",
    "active_logs = np.concatenate([active_logs_mean], axis=-1)  # (31, 24, 30)\n",
    "# print(active_logs_mean.shape, active_logs_var.shape, active_logs.shape)\n",
    "\n",
    "print(active_logs_mean.shape, active_logs.shape)\n",
    "\n",
    "active_logs_mean = active_logs.mean(axis=2)  # 1時間の分割数で平均を取る # 31, 1440, 15\n",
    "active_logs_var = active_logs.var(axis=2)  # 1時間の分割数で分散を取る # 31, 1440, 15\n",
    "active_logs = np.concatenate(\n",
    "    [active_logs_mean, active_logs_var], axis=-1\n",
    ")  # (31, 24, 30)\n",
    "print(active_logs_mean.shape, active_logs_var.shape, active_logs.shape)\n",
    "active_logs = active_logs.reshape(-1, 30)\n",
    "print(active_logs.shape)\n",
    "\n",
    "# active_logs = active_logs.unsqueeze(0)\n",
    "active_logs = torch.tensor(active_logs, dtype=torch.float32).unsqueeze(0).to(\"cuda\")\n",
    "print(active_logs.shape)\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class CNNAutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNAutoEncoder, self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(\n",
    "                in_channels=30, out_channels=64, kernel_size=3, stride=2, padding=1\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose1d(\n",
    "                128, 64, kernel_size=3, stride=2, padding=1, output_padding=1\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(\n",
    "                64, 30, kernel_size=3, stride=2, padding=1, output_padding=1\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  # (batch, channel, time)\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded.permute(0, 2, 1), encoded  # (batch, time, channel)\n",
    "\n",
    "\n",
    "# 実行例\n",
    "model = CNNAutoEncoder()\n",
    "input_data = torch.randn(1, 744, 30)\n",
    "output, embedding = model(input_data)\n",
    "print(\"CNN AutoEncoder output shape:\", output.shape, embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class CMIDataset(Dataset):\n",
    "    def __init__(self, table_df, valid_ids, base_dir, save_filename):\n",
    "        self.base_dir = base_dir\n",
    "        self.table_df = table_df\n",
    "        self.valid_ids = valid_ids\n",
    "        self.save_filename = save_filename\n",
    "        self.scale_columns = [\n",
    "            \"X\",\n",
    "            \"Y\",\n",
    "            \"Z\",\n",
    "            \"enmo\",\n",
    "            \"anglez\",\n",
    "            \"light\",\n",
    "            \"battery_voltage\",\n",
    "        ]\n",
    "\n",
    "        self.masked_columns = [\n",
    "            \"masked_X\",\n",
    "            \"masked_Y\",\n",
    "            \"masked_Z\",\n",
    "            \"masked_enmo\",\n",
    "            \"masked_anglez\",\n",
    "            \"masked_light\",\n",
    "        ]\n",
    "\n",
    "        self.original_columns = [\"battery_voltage\", \"non-wear_flag\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # テーブルデータの抽出\n",
    "        id_ = self.valid_ids[idx]\n",
    "\n",
    "        save_dir = f\"/home/tatsuya/code/projects/kaggle/ChildMindInstitute2024/precreated_dataset/{self.save_filename}/\"\n",
    "        save_path = os.path.join(save_dir, id_)\n",
    "\n",
    "        table = self.table_df.loc[self.table_df[\"id\"] == self.valid_ids[idx], :]\n",
    "        table_feature = table.drop(columns=[\"id\", \"sii\"]).values\n",
    "        sii = table[\"sii\"].values\n",
    "\n",
    "        # 時系列データの抽出\n",
    "        use_cols = self.masked_columns + self.original_columns + self.scale_columns\n",
    "        p = read_parquet(self.base_dir, self.valid_ids[idx])\n",
    "\n",
    "        if p is not None:\n",
    "            p[\"non-wear_flag\"] = 1 - p[\"non-wear_flag\"]\n",
    "            scaler_features = p[scale_columns].values\n",
    "            scaler = StandardScaler()\n",
    "            p[scale_columns] = scaler.fit_transform(scaler_features)\n",
    "\n",
    "            for mask_col in masked_columns:\n",
    "                p[mask_col] = p[mask_col.replace(\"masked_\", \"\")] * p[\"non-wear_flag\"]\n",
    "\n",
    "            p = p.fillna(0.0)\n",
    "\n",
    "            groups = p.groupby(\"relative_date_PCIAT\")\n",
    "            # グループごとにデータフレームのリストに分割\n",
    "            chunks = [group.reset_index(drop=True) for _, group in groups]\n",
    "\n",
    "            use_cols = masked_columns + original_columns + scale_columns\n",
    "            watch_day = len(chunks)\n",
    "            active_logs = np.zeros((31, 17280, len(use_cols)), dtype=np.float32)\n",
    "            active_mask = np.zeros((31), dtype=np.int32)\n",
    "\n",
    "            for i, chunk in enumerate(chunks):\n",
    "                if i == 0:  #\n",
    "                    active_logs[i, -len(chunk) :, :] = chunk[use_cols].values\n",
    "                elif i == watch_day:\n",
    "                    active_logs[i, : len(chunk), :] = chunk[use_cols].values\n",
    "                else:\n",
    "                    array = chunk[use_cols].values\n",
    "                    active_logs[i, : len(array), :] = array\n",
    "\n",
    "                active_mask[i] = 1\n",
    "\n",
    "                if i == 30:\n",
    "                    break\n",
    "\n",
    "            active_logs = active_logs.reshape(31, 24, 60, 12, 15)  # 12は1時間の分割数\n",
    "            active_logs_mean = active_logs.mean(\n",
    "                axis=3\n",
    "            )  # 1時間の分割数で平均を取る # 31, 1440, 15\n",
    "            # active_logs_var = active_logs.var(axis=3)  # 1時間の分割数で分散を取る # 31, 1440, 15\n",
    "            active_logs = np.concatenate([active_logs_mean], axis=-1)  # (31, 24, 30)\n",
    "            # print(active_logs_mean.shape, active_logs_var.shape, active_logs.shape)\n",
    "\n",
    "            # print(active_logs_mean.shape, active_logs.shape)\n",
    "\n",
    "            active_logs_mean = active_logs.mean(\n",
    "                axis=2\n",
    "            )  # 1時間の分割数で平均を取る # 31, 1440, 15\n",
    "            active_logs_var = active_logs.var(\n",
    "                axis=2\n",
    "            )  # 1時間の分割数で分散を取る # 31, 1440, 15\n",
    "            active_logs = np.concatenate(\n",
    "                [active_logs_mean, active_logs_var], axis=-1\n",
    "            )  # (31, 24, 30)\n",
    "            # print(active_logs_mean.shape, active_logs_var.shape, active_logs.shape)\n",
    "            active_logs = active_logs.reshape(-1, 30)\n",
    "\n",
    "        else:\n",
    "            active_logs = np.zeros((744, 30), dtype=np.float32)\n",
    "            active_mask = np.zeros((744), dtype=np.int32)\n",
    "\n",
    "        dataset_ = {\n",
    "            \"id\": id_,\n",
    "            # \"table_input\": torch.tensor(table_feature, dtype=torch.float32),\n",
    "            \"time_input\": torch.tensor(active_logs, dtype=torch.float32),\n",
    "            \"mask\": torch.tensor(active_mask, dtype=torch.int32),\n",
    "            \"output\": torch.tensor(sii, dtype=torch.float32),\n",
    "        }\n",
    "\n",
    "        return dataset_\n",
    "\n",
    "\n",
    "def read_parquet(base_dir, id_):\n",
    "    path = os.path.join(base_dir, f\"id={id_}\", \"part-0.parquet\")\n",
    "    if not os.path.exists(path):\n",
    "        return None\n",
    "    return pd.read_parquet(path)\n",
    "\n",
    "\n",
    "dataset = CMIDataset(\n",
    "    table_df=train,\n",
    "    valid_ids=get_valid_ids(train_series_dir),\n",
    "    base_dir=train_series_dir,\n",
    "    save_filename=\"train\",\n",
    ")\n",
    "\n",
    "# AutoEncoderのモデルのインスタンス化\n",
    "cnn_model = CNNAutoEncoder().to(\"cuda\")\n",
    "cnn_model.load_state_dict(torch.load(\"./assets/cnn_autoencoder.pth\"))\n",
    "\n",
    "# criterion = nn.MSELoss()\n",
    "# optimizer = torch.optim.Adam(cnn_model.parameters(), lr=0.0001)\n",
    "# # データセットからデータを取り出す\n",
    "\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# best_model = None\n",
    "# minimum_loss = 1000000\n",
    "\n",
    "# for epoch in range(10):\n",
    "#     print(f\"Epoch {epoch}\")\n",
    "#     dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "#     epoch_loss = []\n",
    "#     tq = tqdm(dataloader)\n",
    "#     for data in dataloader:\n",
    "#         optimizer.zero_grad()\n",
    "#         # table_input = data[\"table_input\"]\n",
    "#         time_input = data[\"time_input\"].to(\"cuda\")\n",
    "#         mask = data[\"mask\"]\n",
    "\n",
    "#         # モデルにデータを入力し、出力を取得\n",
    "#         cnn_output, embedding = cnn_model(time_input)\n",
    "#         # 損失の計算\n",
    "#         loss = criterion(cnn_output, time_input)\n",
    "#         loss.backward()\n",
    "\n",
    "#         optimizer.step()\n",
    "\n",
    "#         epoch_loss.append(loss.item())\n",
    "\n",
    "#         tq.set_postfix(loss=np.mean(epoch_loss))\n",
    "#         tq.update()\n",
    "\n",
    "#     if np.mean(epoch_loss) < minimum_loss:\n",
    "#         minimum_loss = np.mean(epoch_loss)\n",
    "#         best_model = cnn_model\n",
    "#         cnn_model.eval()\n",
    "#         torch.save(cnn_model.state_dict(), \"./assets/cnn_autoencoder.pth\")\n",
    "#         cnn_model.train()\n",
    "\n",
    "#     print(f\"Epoch {epoch} Loss: {np.mean(epoch_loss)}\")\n",
    "#     tq.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 996/996 [01:33<00:00, 10.71it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = CMIDataset(\n",
    "    table_df=train,\n",
    "    valid_ids=get_valid_ids(train_series_dir),\n",
    "    base_dir=train_series_dir,\n",
    "    save_filename=\"train\",\n",
    ")\n",
    "\n",
    "# AutoEncoderのモデルのインスタンス化\n",
    "cnn_model = CNNAutoEncoder().to(\"cuda\")\n",
    "cnn_model.load_state_dict(torch.load(\"./assets/cnn_autoencoder.pth\"))\n",
    "# データセットからデータを取り出す\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "best_model = None\n",
    "minimum_loss = 1000000\n",
    "\n",
    "print(f\"Create Embedding\")\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "epoch_loss = []\n",
    "tq = tqdm(dataloader)\n",
    "\n",
    "embedding_result = []\n",
    "\n",
    "for data in dataloader:\n",
    "    id_ = data[\"id\"][0]\n",
    "    # table_input = data[\"table_input\"]\n",
    "    time_input = data[\"time_input\"].to(\"cuda\")\n",
    "    mask = data[\"mask\"]\n",
    "\n",
    "    # モデルにデータを入力し、出力を取得\n",
    "    cnn_output, embedding = cnn_model(time_input)\n",
    "    # 損失の計算\n",
    "\n",
    "    mean_embedding = embedding.squeeze(0).mean(axis=-1).cpu().detach().numpy()\n",
    "    # mean_embedding = embedding.cpu().detach().numpy()\n",
    "\n",
    "    embedding_result.append({\"id\": id_, \"embedding\": mean_embedding})\n",
    "\n",
    "    tq.update()\n",
    "\n",
    "tq.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>embedding_0</th>\n",
       "      <th>embedding_1</th>\n",
       "      <th>embedding_2</th>\n",
       "      <th>embedding_3</th>\n",
       "      <th>embedding_4</th>\n",
       "      <th>embedding_5</th>\n",
       "      <th>embedding_6</th>\n",
       "      <th>embedding_7</th>\n",
       "      <th>embedding_8</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_118</th>\n",
       "      <th>embedding_119</th>\n",
       "      <th>embedding_120</th>\n",
       "      <th>embedding_121</th>\n",
       "      <th>embedding_122</th>\n",
       "      <th>embedding_123</th>\n",
       "      <th>embedding_124</th>\n",
       "      <th>embedding_125</th>\n",
       "      <th>embedding_126</th>\n",
       "      <th>embedding_127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23dafdab</td>\n",
       "      <td>0.934273</td>\n",
       "      <td>1.058295</td>\n",
       "      <td>1.028002</td>\n",
       "      <td>1.107266</td>\n",
       "      <td>1.511564</td>\n",
       "      <td>1.678031</td>\n",
       "      <td>0.614336</td>\n",
       "      <td>0.847055</td>\n",
       "      <td>0.827912</td>\n",
       "      <td>...</td>\n",
       "      <td>1.049939</td>\n",
       "      <td>1.311329</td>\n",
       "      <td>0.996335</td>\n",
       "      <td>1.217725</td>\n",
       "      <td>0.973498</td>\n",
       "      <td>0.754627</td>\n",
       "      <td>1.093903</td>\n",
       "      <td>0.841220</td>\n",
       "      <td>1.063418</td>\n",
       "      <td>1.293948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e4614ec6</td>\n",
       "      <td>1.292569</td>\n",
       "      <td>1.470513</td>\n",
       "      <td>1.542059</td>\n",
       "      <td>1.298862</td>\n",
       "      <td>1.744134</td>\n",
       "      <td>1.957554</td>\n",
       "      <td>0.864446</td>\n",
       "      <td>1.181660</td>\n",
       "      <td>0.996835</td>\n",
       "      <td>...</td>\n",
       "      <td>1.476123</td>\n",
       "      <td>1.654581</td>\n",
       "      <td>1.056002</td>\n",
       "      <td>1.295083</td>\n",
       "      <td>1.551957</td>\n",
       "      <td>0.754289</td>\n",
       "      <td>1.351622</td>\n",
       "      <td>1.053791</td>\n",
       "      <td>1.531604</td>\n",
       "      <td>1.537732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56ef356c</td>\n",
       "      <td>1.030161</td>\n",
       "      <td>1.136603</td>\n",
       "      <td>1.320513</td>\n",
       "      <td>1.339276</td>\n",
       "      <td>1.893055</td>\n",
       "      <td>1.956167</td>\n",
       "      <td>0.807934</td>\n",
       "      <td>1.109800</td>\n",
       "      <td>1.112787</td>\n",
       "      <td>...</td>\n",
       "      <td>1.311299</td>\n",
       "      <td>1.835630</td>\n",
       "      <td>1.093886</td>\n",
       "      <td>1.421084</td>\n",
       "      <td>1.230976</td>\n",
       "      <td>0.685264</td>\n",
       "      <td>1.468262</td>\n",
       "      <td>1.255411</td>\n",
       "      <td>1.170305</td>\n",
       "      <td>1.344505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dcfcd574</td>\n",
       "      <td>1.437756</td>\n",
       "      <td>1.521565</td>\n",
       "      <td>1.574320</td>\n",
       "      <td>1.582690</td>\n",
       "      <td>1.890268</td>\n",
       "      <td>2.237839</td>\n",
       "      <td>0.957044</td>\n",
       "      <td>1.491451</td>\n",
       "      <td>1.149451</td>\n",
       "      <td>...</td>\n",
       "      <td>1.768229</td>\n",
       "      <td>1.925022</td>\n",
       "      <td>1.165750</td>\n",
       "      <td>1.321340</td>\n",
       "      <td>1.601160</td>\n",
       "      <td>0.861113</td>\n",
       "      <td>1.609951</td>\n",
       "      <td>1.270303</td>\n",
       "      <td>1.577081</td>\n",
       "      <td>1.733535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>338146bd</td>\n",
       "      <td>0.833982</td>\n",
       "      <td>0.835131</td>\n",
       "      <td>1.005347</td>\n",
       "      <td>1.011853</td>\n",
       "      <td>1.326406</td>\n",
       "      <td>1.422274</td>\n",
       "      <td>0.602682</td>\n",
       "      <td>0.865930</td>\n",
       "      <td>0.832643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.994025</td>\n",
       "      <td>1.280672</td>\n",
       "      <td>0.815593</td>\n",
       "      <td>0.957112</td>\n",
       "      <td>0.948529</td>\n",
       "      <td>0.525334</td>\n",
       "      <td>1.072017</td>\n",
       "      <td>0.860638</td>\n",
       "      <td>0.921265</td>\n",
       "      <td>1.005224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2a9e0dee</td>\n",
       "      <td>1.118476</td>\n",
       "      <td>1.154102</td>\n",
       "      <td>1.328735</td>\n",
       "      <td>1.243005</td>\n",
       "      <td>1.651012</td>\n",
       "      <td>1.804135</td>\n",
       "      <td>0.703245</td>\n",
       "      <td>1.077119</td>\n",
       "      <td>0.960325</td>\n",
       "      <td>...</td>\n",
       "      <td>1.295312</td>\n",
       "      <td>1.530142</td>\n",
       "      <td>1.013229</td>\n",
       "      <td>1.196613</td>\n",
       "      <td>1.293185</td>\n",
       "      <td>0.606831</td>\n",
       "      <td>1.258096</td>\n",
       "      <td>0.982478</td>\n",
       "      <td>1.243394</td>\n",
       "      <td>1.284215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0eddd8e5</td>\n",
       "      <td>1.003418</td>\n",
       "      <td>1.115285</td>\n",
       "      <td>1.469960</td>\n",
       "      <td>1.305835</td>\n",
       "      <td>2.142858</td>\n",
       "      <td>2.006252</td>\n",
       "      <td>0.750761</td>\n",
       "      <td>1.160900</td>\n",
       "      <td>1.059262</td>\n",
       "      <td>...</td>\n",
       "      <td>1.395912</td>\n",
       "      <td>1.999641</td>\n",
       "      <td>1.101297</td>\n",
       "      <td>1.405424</td>\n",
       "      <td>1.463978</td>\n",
       "      <td>0.790238</td>\n",
       "      <td>1.587342</td>\n",
       "      <td>1.133078</td>\n",
       "      <td>1.314270</td>\n",
       "      <td>1.498254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a49eda7f</td>\n",
       "      <td>1.112953</td>\n",
       "      <td>1.273634</td>\n",
       "      <td>1.532017</td>\n",
       "      <td>1.440813</td>\n",
       "      <td>1.984239</td>\n",
       "      <td>1.999086</td>\n",
       "      <td>0.782063</td>\n",
       "      <td>1.181599</td>\n",
       "      <td>1.059615</td>\n",
       "      <td>...</td>\n",
       "      <td>1.443727</td>\n",
       "      <td>1.882844</td>\n",
       "      <td>1.108292</td>\n",
       "      <td>1.392762</td>\n",
       "      <td>1.356991</td>\n",
       "      <td>0.621868</td>\n",
       "      <td>1.475014</td>\n",
       "      <td>1.189176</td>\n",
       "      <td>1.345740</td>\n",
       "      <td>1.492343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fa34f945</td>\n",
       "      <td>0.885967</td>\n",
       "      <td>0.950511</td>\n",
       "      <td>0.895033</td>\n",
       "      <td>1.111232</td>\n",
       "      <td>1.495834</td>\n",
       "      <td>1.656162</td>\n",
       "      <td>0.655794</td>\n",
       "      <td>0.761335</td>\n",
       "      <td>0.848918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.853265</td>\n",
       "      <td>1.006434</td>\n",
       "      <td>0.973718</td>\n",
       "      <td>1.090717</td>\n",
       "      <td>0.844414</td>\n",
       "      <td>0.705840</td>\n",
       "      <td>1.027594</td>\n",
       "      <td>0.745894</td>\n",
       "      <td>0.964948</td>\n",
       "      <td>1.118776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>526f719b</td>\n",
       "      <td>0.957307</td>\n",
       "      <td>0.889254</td>\n",
       "      <td>1.175763</td>\n",
       "      <td>1.011990</td>\n",
       "      <td>1.275229</td>\n",
       "      <td>1.539330</td>\n",
       "      <td>0.532177</td>\n",
       "      <td>0.921299</td>\n",
       "      <td>0.885462</td>\n",
       "      <td>...</td>\n",
       "      <td>1.122689</td>\n",
       "      <td>1.329937</td>\n",
       "      <td>0.939272</td>\n",
       "      <td>0.975884</td>\n",
       "      <td>1.162482</td>\n",
       "      <td>0.528119</td>\n",
       "      <td>1.144915</td>\n",
       "      <td>0.932701</td>\n",
       "      <td>1.067682</td>\n",
       "      <td>1.111611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>996 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  embedding_0  embedding_1  embedding_2  embedding_3  embedding_4  \\\n",
       "0   23dafdab     0.934273     1.058295     1.028002     1.107266     1.511564   \n",
       "0   e4614ec6     1.292569     1.470513     1.542059     1.298862     1.744134   \n",
       "0   56ef356c     1.030161     1.136603     1.320513     1.339276     1.893055   \n",
       "0   dcfcd574     1.437756     1.521565     1.574320     1.582690     1.890268   \n",
       "0   338146bd     0.833982     0.835131     1.005347     1.011853     1.326406   \n",
       "..       ...          ...          ...          ...          ...          ...   \n",
       "0   2a9e0dee     1.118476     1.154102     1.328735     1.243005     1.651012   \n",
       "0   0eddd8e5     1.003418     1.115285     1.469960     1.305835     2.142858   \n",
       "0   a49eda7f     1.112953     1.273634     1.532017     1.440813     1.984239   \n",
       "0   fa34f945     0.885967     0.950511     0.895033     1.111232     1.495834   \n",
       "0   526f719b     0.957307     0.889254     1.175763     1.011990     1.275229   \n",
       "\n",
       "    embedding_5  embedding_6  embedding_7  embedding_8  ...  embedding_118  \\\n",
       "0      1.678031     0.614336     0.847055     0.827912  ...       1.049939   \n",
       "0      1.957554     0.864446     1.181660     0.996835  ...       1.476123   \n",
       "0      1.956167     0.807934     1.109800     1.112787  ...       1.311299   \n",
       "0      2.237839     0.957044     1.491451     1.149451  ...       1.768229   \n",
       "0      1.422274     0.602682     0.865930     0.832643  ...       0.994025   \n",
       "..          ...          ...          ...          ...  ...            ...   \n",
       "0      1.804135     0.703245     1.077119     0.960325  ...       1.295312   \n",
       "0      2.006252     0.750761     1.160900     1.059262  ...       1.395912   \n",
       "0      1.999086     0.782063     1.181599     1.059615  ...       1.443727   \n",
       "0      1.656162     0.655794     0.761335     0.848918  ...       0.853265   \n",
       "0      1.539330     0.532177     0.921299     0.885462  ...       1.122689   \n",
       "\n",
       "    embedding_119  embedding_120  embedding_121  embedding_122  embedding_123  \\\n",
       "0        1.311329       0.996335       1.217725       0.973498       0.754627   \n",
       "0        1.654581       1.056002       1.295083       1.551957       0.754289   \n",
       "0        1.835630       1.093886       1.421084       1.230976       0.685264   \n",
       "0        1.925022       1.165750       1.321340       1.601160       0.861113   \n",
       "0        1.280672       0.815593       0.957112       0.948529       0.525334   \n",
       "..            ...            ...            ...            ...            ...   \n",
       "0        1.530142       1.013229       1.196613       1.293185       0.606831   \n",
       "0        1.999641       1.101297       1.405424       1.463978       0.790238   \n",
       "0        1.882844       1.108292       1.392762       1.356991       0.621868   \n",
       "0        1.006434       0.973718       1.090717       0.844414       0.705840   \n",
       "0        1.329937       0.939272       0.975884       1.162482       0.528119   \n",
       "\n",
       "    embedding_124  embedding_125  embedding_126  embedding_127  \n",
       "0        1.093903       0.841220       1.063418       1.293948  \n",
       "0        1.351622       1.053791       1.531604       1.537732  \n",
       "0        1.468262       1.255411       1.170305       1.344505  \n",
       "0        1.609951       1.270303       1.577081       1.733535  \n",
       "0        1.072017       0.860638       0.921265       1.005224  \n",
       "..            ...            ...            ...            ...  \n",
       "0        1.258096       0.982478       1.243394       1.284215  \n",
       "0        1.587342       1.133078       1.314270       1.498254  \n",
       "0        1.475014       1.189176       1.345740       1.492343  \n",
       "0        1.027594       0.745894       0.964948       1.118776  \n",
       "0        1.144915       0.932701       1.067682       1.111611  \n",
       "\n",
       "[996 rows x 129 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_df_all = None\n",
    "\n",
    "for row in embedding_result:\n",
    "    id_ = row[\"id\"]\n",
    "    embedding = row[\"embedding\"]\n",
    "    embedding_cols = [f\"embedding_{i}\" for i in range(embedding.shape[-1])]\n",
    "    embedding_df = pd.DataFrame(embedding.reshape(1, -1), columns=embedding_cols)\n",
    "    embedding_df[\"id\"] = id_\n",
    "\n",
    "    if embedding_df_all is None:\n",
    "        embedding_df_all = embedding_df\n",
    "    else:\n",
    "        embedding_df_all = pd.concat([embedding_df_all, embedding_df], axis=0)\n",
    "\n",
    "embedding_df_all = embedding_df_all[[\"id\"] + embedding_cols]\n",
    "embedding_df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(embedding_df_all, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Tabnet***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New: TabNet\n",
    "\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_tabnet.callbacks import Callback\n",
    "import os\n",
    "import torch\n",
    "from pytorch_tabnet.callbacks import Callback\n",
    "\n",
    "\n",
    "class TabNetWrapper(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.model = TabNetRegressor(**kwargs)\n",
    "        self.kwargs = kwargs\n",
    "        self.imputer = SimpleImputer(strategy=\"median\")\n",
    "        self.best_model_path = \"best_tabnet_model.pt\"\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Handle missing values\n",
    "        X_imputed = self.imputer.fit_transform(X)\n",
    "\n",
    "        if hasattr(y, \"values\"):\n",
    "            y = y.values\n",
    "\n",
    "        # Create internal validation set\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "            X_imputed, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "\n",
    "        # Train TabNet model\n",
    "        history = self.model.fit(\n",
    "            X_train=X_train,\n",
    "            y_train=y_train.reshape(-1, 1),\n",
    "            eval_set=[(X_valid, y_valid.reshape(-1, 1))],\n",
    "            eval_name=[\"valid\"],\n",
    "            eval_metric=[\"mse\"],\n",
    "            max_epochs=200,\n",
    "            patience=20,\n",
    "            batch_size=1024,\n",
    "            virtual_batch_size=128,\n",
    "            num_workers=0,\n",
    "            drop_last=False,\n",
    "            callbacks=[\n",
    "                TabNetPretrainedModelCheckpoint(\n",
    "                    filepath=self.best_model_path,\n",
    "                    monitor=\"valid_mse\",\n",
    "                    mode=\"min\",\n",
    "                    save_best_only=True,\n",
    "                    verbose=True,\n",
    "                )\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        # Load the best model\n",
    "        if os.path.exists(self.best_model_path):\n",
    "            self.model.load_model(self.best_model_path)\n",
    "            os.remove(self.best_model_path)  # Remove temporary file\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_imputed = self.imputer.transform(X)\n",
    "        return self.model.predict(X_imputed).flatten()\n",
    "\n",
    "    def __deepcopy__(self, memo):\n",
    "        # Add deepcopy support for scikit-learn\n",
    "        cls = self.__class__\n",
    "        result = cls.__new__(cls)\n",
    "        memo[id(self)] = result\n",
    "        for k, v in self.__dict__.items():\n",
    "            setattr(result, k, deepcopy(v, memo))\n",
    "        return result\n",
    "\n",
    "\n",
    "# TabNet hyperparameters\n",
    "TabNet_Params = {\n",
    "    \"n_d\": 64,  # Width of the decision prediction layer\n",
    "    \"n_a\": 64,  # Width of the attention embedding for each step\n",
    "    \"n_steps\": 5,  # Number of steps in the architecture\n",
    "    \"gamma\": 1.5,  # Coefficient for feature selection regularization\n",
    "    \"n_independent\": 2,  # Number of independent GLU layer in each GLU block\n",
    "    \"n_shared\": 2,  # Number of shared GLU layer in each GLU block\n",
    "    \"lambda_sparse\": 1e-4,  # Sparsity regularization\n",
    "    \"optimizer_fn\": torch.optim.Adam,\n",
    "    \"optimizer_params\": dict(lr=2e-2, weight_decay=1e-5),\n",
    "    \"mask_type\": \"entmax\",\n",
    "    \"scheduler_params\": dict(mode=\"min\", patience=10, min_lr=1e-5, factor=0.5),\n",
    "    \"scheduler_fn\": torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    \"verbose\": 1,\n",
    "    \"device_name\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "}\n",
    "\n",
    "\n",
    "class TabNetPretrainedModelCheckpoint(Callback):\n",
    "    def __init__(\n",
    "        self, filepath, monitor=\"val_loss\", mode=\"min\", save_best_only=True, verbose=1\n",
    "    ):\n",
    "        super().__init__()  # Initialize parent class\n",
    "        self.filepath = filepath\n",
    "        self.monitor = monitor\n",
    "        self.mode = mode\n",
    "        self.save_best_only = save_best_only\n",
    "        self.verbose = verbose\n",
    "        self.best = float(\"inf\") if mode == \"min\" else -float(\"inf\")\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.model = self.trainer  # Use trainer itself as model\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            return\n",
    "\n",
    "        # Check if current metric is better than best\n",
    "        if (self.mode == \"min\" and current < self.best) or (\n",
    "            self.mode == \"max\" and current > self.best\n",
    "        ):\n",
    "            if self.verbose:\n",
    "                print(\n",
    "                    f\"\\nEpoch {epoch}: {self.monitor} improved from {self.best:.4f} to {current:.4f}\"\n",
    "                )\n",
    "            self.best = current\n",
    "            if self.save_best_only:\n",
    "                self.model.save_model(self.filepath)  # Save the entire model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.78555 | valid_mse: 8.69106 |  0:00:00s\n",
      "\n",
      "Epoch 0: valid_mse improved from inf to 8.6911\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 1  | loss: 1.79328 | valid_mse: 1.17087 |  0:00:00s\n",
      "\n",
      "Epoch 1: valid_mse improved from 8.6911 to 1.1709\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 2  | loss: 1.32625 | valid_mse: 1.39013 |  0:00:00s\n",
      "epoch 3  | loss: 1.07773 | valid_mse: 1.12234 |  0:00:00s\n",
      "\n",
      "Epoch 3: valid_mse improved from 1.1709 to 1.1223\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 4  | loss: 0.82884 | valid_mse: 14.89091|  0:00:00s\n",
      "epoch 5  | loss: 0.76702 | valid_mse: 1.39176 |  0:00:00s\n",
      "epoch 6  | loss: 0.7533  | valid_mse: 1.07529 |  0:00:00s\n",
      "\n",
      "Epoch 6: valid_mse improved from 1.1223 to 1.0753\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 7  | loss: 0.77908 | valid_mse: 1.03437 |  0:00:00s\n",
      "\n",
      "Epoch 7: valid_mse improved from 1.0753 to 1.0344\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 8  | loss: 0.69372 | valid_mse: 1.08825 |  0:00:00s\n",
      "epoch 9  | loss: 0.6581  | valid_mse: 0.93953 |  0:00:00s\n",
      "\n",
      "Epoch 9: valid_mse improved from 1.0344 to 0.9395\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 10 | loss: 0.60029 | valid_mse: 2.36891 |  0:00:00s\n",
      "epoch 11 | loss: 0.60521 | valid_mse: 2.57006 |  0:00:01s\n",
      "epoch 12 | loss: 0.6221  | valid_mse: 1.57347 |  0:00:01s\n",
      "epoch 13 | loss: 0.56686 | valid_mse: 0.76171 |  0:00:01s\n",
      "\n",
      "Epoch 13: valid_mse improved from 0.9395 to 0.7617\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 14 | loss: 0.56951 | valid_mse: 0.63698 |  0:00:01s\n",
      "\n",
      "Epoch 14: valid_mse improved from 0.7617 to 0.6370\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 15 | loss: 0.55907 | valid_mse: 0.56769 |  0:00:01s\n",
      "\n",
      "Epoch 15: valid_mse improved from 0.6370 to 0.5677\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 16 | loss: 0.55289 | valid_mse: 0.59323 |  0:00:01s\n",
      "epoch 17 | loss: 0.54897 | valid_mse: 0.57961 |  0:00:01s\n",
      "epoch 18 | loss: 0.53988 | valid_mse: 0.60116 |  0:00:01s\n",
      "epoch 19 | loss: 0.55501 | valid_mse: 0.57904 |  0:00:01s\n",
      "epoch 20 | loss: 0.5455  | valid_mse: 0.62468 |  0:00:01s\n",
      "epoch 21 | loss: 0.53055 | valid_mse: 0.6955  |  0:00:01s\n",
      "epoch 22 | loss: 0.53947 | valid_mse: 0.58743 |  0:00:01s\n",
      "epoch 23 | loss: 0.54908 | valid_mse: 0.64996 |  0:00:01s\n",
      "epoch 24 | loss: 0.5331  | valid_mse: 0.93529 |  0:00:01s\n",
      "epoch 25 | loss: 0.52462 | valid_mse: 1.24925 |  0:00:02s\n",
      "epoch 26 | loss: 0.52535 | valid_mse: 1.26636 |  0:00:02s\n",
      "epoch 27 | loss: 0.5131  | valid_mse: 1.05029 |  0:00:02s\n",
      "epoch 28 | loss: 0.51375 | valid_mse: 1.39541 |  0:00:02s\n",
      "epoch 29 | loss: 0.49658 | valid_mse: 1.09464 |  0:00:02s\n",
      "epoch 30 | loss: 0.50343 | valid_mse: 0.87626 |  0:00:02s\n",
      "epoch 31 | loss: 0.48643 | valid_mse: 0.7991  |  0:00:02s\n",
      "epoch 32 | loss: 0.48964 | valid_mse: 0.93945 |  0:00:02s\n",
      "epoch 33 | loss: 0.48547 | valid_mse: 1.18077 |  0:00:02s\n",
      "epoch 34 | loss: 0.49059 | valid_mse: 1.42204 |  0:00:02s\n",
      "epoch 35 | loss: 0.49199 | valid_mse: 1.30021 |  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_valid_mse = 0.56769\n",
      "Fold 1 - Train QWK: 0.6897, Validation QWK: 0.3235\n",
      "epoch 0  | loss: 3.36452 | valid_mse: 270.29482|  0:00:00s\n",
      "\n",
      "Epoch 0: valid_mse improved from inf to 270.2948\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 1  | loss: 1.75588 | valid_mse: 42587444.86579|  0:00:00s\n",
      "epoch 2  | loss: 1.42285 | valid_mse: 80.86584|  0:00:00s\n",
      "\n",
      "Epoch 2: valid_mse improved from 270.2948 to 80.8658\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 3  | loss: 1.45627 | valid_mse: 5395340.63807|  0:00:00s\n",
      "epoch 4  | loss: 1.22222 | valid_mse: 3908125.95874|  0:00:00s\n",
      "epoch 5  | loss: 0.99407 | valid_mse: 28220758.69437|  0:00:00s\n",
      "epoch 6  | loss: 0.79201 | valid_mse: 28631331.80472|  0:00:00s\n",
      "epoch 7  | loss: 0.78153 | valid_mse: 18606534.18563|  0:00:00s\n",
      "epoch 8  | loss: 0.69609 | valid_mse: 0.77832 |  0:00:00s\n",
      "\n",
      "Epoch 8: valid_mse improved from 80.8658 to 0.7783\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 9  | loss: 0.67017 | valid_mse: 9.85565 |  0:00:00s\n",
      "epoch 10 | loss: 0.66669 | valid_mse: 5.038   |  0:00:00s\n",
      "epoch 11 | loss: 0.65626 | valid_mse: 9.8137  |  0:00:01s\n",
      "epoch 12 | loss: 0.64114 | valid_mse: 10.5811 |  0:00:01s\n",
      "epoch 13 | loss: 0.60795 | valid_mse: 8.14369 |  0:00:01s\n",
      "epoch 14 | loss: 0.6096  | valid_mse: 6.94981 |  0:00:01s\n",
      "epoch 15 | loss: 0.60076 | valid_mse: 4.74061 |  0:00:01s\n",
      "epoch 16 | loss: 0.5792  | valid_mse: 6.08852 |  0:00:01s\n",
      "epoch 17 | loss: 0.58563 | valid_mse: 5.7357  |  0:00:01s\n",
      "epoch 18 | loss: 0.57892 | valid_mse: 7.37519 |  0:00:01s\n",
      "epoch 19 | loss: 0.56599 | valid_mse: 4.71329 |  0:00:01s\n",
      "epoch 20 | loss: 0.56371 | valid_mse: 0.95109 |  0:00:01s\n",
      "epoch 21 | loss: 0.56221 | valid_mse: 280999.78264|  0:00:01s\n",
      "epoch 22 | loss: 0.5545  | valid_mse: 153187.96577|  0:00:01s\n",
      "epoch 23 | loss: 0.54743 | valid_mse: 329943.99905|  0:00:01s\n",
      "epoch 24 | loss: 0.55844 | valid_mse: 0.84586 |  0:00:01s\n",
      "epoch 25 | loss: 0.54807 | valid_mse: 364941.58197|  0:00:02s\n",
      "epoch 26 | loss: 0.55214 | valid_mse: 246836.54428|  0:00:02s\n",
      "epoch 27 | loss: 0.52831 | valid_mse: 115940.0255|  0:00:02s\n",
      "epoch 28 | loss: 0.52815 | valid_mse: 17334.36935|  0:00:02s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_valid_mse = 0.77832\n",
      "Fold 2 - Train QWK: 0.6804, Validation QWK: 0.3819\n",
      "epoch 0  | loss: 2.66898 | valid_mse: 40.60783|  0:00:00s\n",
      "\n",
      "Epoch 0: valid_mse improved from inf to 40.6078\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 1  | loss: 1.63435 | valid_mse: 6805.57099|  0:00:00s\n",
      "epoch 2  | loss: 1.43131 | valid_mse: 3.58396 |  0:00:00s\n",
      "\n",
      "Epoch 2: valid_mse improved from 40.6078 to 3.5840\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 3  | loss: 1.02281 | valid_mse: 1.67456 |  0:00:00s\n",
      "\n",
      "Epoch 3: valid_mse improved from 3.5840 to 1.6746\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 4  | loss: 0.98708 | valid_mse: 1.41462 |  0:00:00s\n",
      "\n",
      "Epoch 4: valid_mse improved from 1.6746 to 1.4146\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 5  | loss: 0.9083  | valid_mse: 1.69251 |  0:00:00s\n",
      "epoch 6  | loss: 0.71445 | valid_mse: 1.94058 |  0:00:00s\n",
      "epoch 7  | loss: 0.71114 | valid_mse: 0.72172 |  0:00:00s\n",
      "\n",
      "Epoch 7: valid_mse improved from 1.4146 to 0.7217\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 8  | loss: 0.66134 | valid_mse: 46.83558|  0:00:00s\n",
      "epoch 9  | loss: 0.62206 | valid_mse: 47.25956|  0:00:00s\n",
      "epoch 10 | loss: 0.62087 | valid_mse: 43.29172|  0:00:00s\n",
      "epoch 11 | loss: 0.60572 | valid_mse: 10.47831|  0:00:00s\n",
      "epoch 12 | loss: 0.60169 | valid_mse: 0.98099 |  0:00:01s\n",
      "epoch 13 | loss: 0.58847 | valid_mse: 2.09717 |  0:00:01s\n",
      "epoch 14 | loss: 0.57938 | valid_mse: 0.71289 |  0:00:01s\n",
      "\n",
      "Epoch 14: valid_mse improved from 0.7217 to 0.7129\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 15 | loss: 0.56428 | valid_mse: 0.65037 |  0:00:01s\n",
      "\n",
      "Epoch 15: valid_mse improved from 0.7129 to 0.6504\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 16 | loss: 0.56468 | valid_mse: 0.62369 |  0:00:01s\n",
      "\n",
      "Epoch 16: valid_mse improved from 0.6504 to 0.6237\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 17 | loss: 0.56777 | valid_mse: 0.94968 |  0:00:01s\n",
      "epoch 18 | loss: 0.55475 | valid_mse: 0.70403 |  0:00:01s\n",
      "epoch 19 | loss: 0.54532 | valid_mse: 9.97301 |  0:00:01s\n",
      "epoch 20 | loss: 0.55259 | valid_mse: 7.4732  |  0:00:01s\n",
      "epoch 21 | loss: 0.5633  | valid_mse: 4.31331 |  0:00:01s\n",
      "epoch 22 | loss: 0.55284 | valid_mse: 3.67016 |  0:00:01s\n",
      "epoch 23 | loss: 0.54993 | valid_mse: 3.65995 |  0:00:01s\n",
      "epoch 24 | loss: 0.52743 | valid_mse: 5.70287 |  0:00:01s\n",
      "epoch 25 | loss: 0.5667  | valid_mse: 1.6043  |  0:00:01s\n",
      "epoch 26 | loss: 0.5804  | valid_mse: 1.44036 |  0:00:01s\n",
      "epoch 27 | loss: 0.53135 | valid_mse: 1.05216 |  0:00:02s\n",
      "epoch 28 | loss: 0.5352  | valid_mse: 1.27313 |  0:00:02s\n",
      "epoch 29 | loss: 0.54694 | valid_mse: 0.67076 |  0:00:02s\n",
      "epoch 30 | loss: 0.52918 | valid_mse: 0.8098  |  0:00:02s\n",
      "epoch 31 | loss: 0.52966 | valid_mse: 0.6754  |  0:00:02s\n",
      "epoch 32 | loss: 0.53132 | valid_mse: 1.83135 |  0:00:02s\n",
      "epoch 33 | loss: 0.54028 | valid_mse: 0.68895 |  0:00:02s\n",
      "epoch 34 | loss: 0.52526 | valid_mse: 0.56591 |  0:00:02s\n",
      "\n",
      "Epoch 34: valid_mse improved from 0.6237 to 0.5659\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 35 | loss: 0.52562 | valid_mse: 0.55128 |  0:00:02s\n",
      "\n",
      "Epoch 35: valid_mse improved from 0.5659 to 0.5513\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 36 | loss: 0.5185  | valid_mse: 0.53029 |  0:00:02s\n",
      "\n",
      "Epoch 36: valid_mse improved from 0.5513 to 0.5303\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 37 | loss: 0.51729 | valid_mse: 0.57563 |  0:00:02s\n",
      "epoch 38 | loss: 0.50284 | valid_mse: 0.76761 |  0:00:02s\n",
      "epoch 39 | loss: 0.50905 | valid_mse: 0.5959  |  0:00:02s\n",
      "epoch 40 | loss: 0.50987 | valid_mse: 0.57982 |  0:00:02s\n",
      "epoch 41 | loss: 0.50519 | valid_mse: 0.57815 |  0:00:03s\n",
      "epoch 42 | loss: 0.49954 | valid_mse: 0.68522 |  0:00:03s\n",
      "epoch 43 | loss: 0.50065 | valid_mse: 1.45764 |  0:00:03s\n",
      "epoch 44 | loss: 0.49758 | valid_mse: 0.57505 |  0:00:03s\n",
      "epoch 45 | loss: 0.50034 | valid_mse: 0.55528 |  0:00:03s\n",
      "epoch 46 | loss: 0.48856 | valid_mse: 0.5602  |  0:00:03s\n",
      "epoch 47 | loss: 0.4881  | valid_mse: 0.56501 |  0:00:03s\n",
      "epoch 48 | loss: 0.48331 | valid_mse: 0.95684 |  0:00:03s\n",
      "epoch 49 | loss: 0.4834  | valid_mse: 0.64279 |  0:00:03s\n",
      "epoch 50 | loss: 0.48187 | valid_mse: 0.53977 |  0:00:03s\n",
      "epoch 51 | loss: 0.48466 | valid_mse: 0.54008 |  0:00:03s\n",
      "epoch 52 | loss: 0.47987 | valid_mse: 1.08782 |  0:00:03s\n",
      "epoch 53 | loss: 0.48004 | valid_mse: 2.3969  |  0:00:03s\n",
      "epoch 54 | loss: 0.4804  | valid_mse: 0.75002 |  0:00:03s\n",
      "epoch 55 | loss: 0.47496 | valid_mse: 0.53008 |  0:00:03s\n",
      "\n",
      "Epoch 55: valid_mse improved from 0.5303 to 0.5301\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 56 | loss: 0.48393 | valid_mse: 0.54382 |  0:00:04s\n",
      "epoch 57 | loss: 0.47934 | valid_mse: 0.5783  |  0:00:04s\n",
      "epoch 58 | loss: 0.48163 | valid_mse: 0.53099 |  0:00:04s\n",
      "epoch 59 | loss: 0.47329 | valid_mse: 0.5046  |  0:00:04s\n",
      "\n",
      "Epoch 59: valid_mse improved from 0.5301 to 0.5046\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 60 | loss: 0.47765 | valid_mse: 0.49917 |  0:00:04s\n",
      "\n",
      "Epoch 60: valid_mse improved from 0.5046 to 0.4992\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 61 | loss: 0.47104 | valid_mse: 0.51051 |  0:00:04s\n",
      "epoch 62 | loss: 0.48109 | valid_mse: 0.52121 |  0:00:04s\n",
      "epoch 63 | loss: 0.49228 | valid_mse: 0.50504 |  0:00:04s\n",
      "epoch 64 | loss: 0.486   | valid_mse: 0.49893 |  0:00:04s\n",
      "\n",
      "Epoch 64: valid_mse improved from 0.4992 to 0.4989\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 65 | loss: 0.48536 | valid_mse: 0.51464 |  0:00:04s\n",
      "epoch 66 | loss: 0.47173 | valid_mse: 0.55615 |  0:00:04s\n",
      "epoch 67 | loss: 0.47813 | valid_mse: 0.57011 |  0:00:04s\n",
      "epoch 68 | loss: 0.47518 | valid_mse: 0.56972 |  0:00:04s\n",
      "epoch 69 | loss: 0.47133 | valid_mse: 0.56742 |  0:00:04s\n",
      "epoch 70 | loss: 0.47114 | valid_mse: 0.57461 |  0:00:04s\n",
      "epoch 71 | loss: 0.47549 | valid_mse: 0.58181 |  0:00:05s\n",
      "epoch 72 | loss: 0.47344 | valid_mse: 0.58355 |  0:00:05s\n",
      "epoch 73 | loss: 0.47927 | valid_mse: 0.59167 |  0:00:05s\n",
      "epoch 74 | loss: 0.47092 | valid_mse: 0.60303 |  0:00:05s\n",
      "epoch 75 | loss: 0.46476 | valid_mse: 0.59788 |  0:00:05s\n",
      "epoch 76 | loss: 0.47942 | valid_mse: 0.59724 |  0:00:05s\n",
      "epoch 77 | loss: 0.4704  | valid_mse: 0.59621 |  0:00:05s\n",
      "epoch 78 | loss: 0.46828 | valid_mse: 0.58494 |  0:00:05s\n",
      "epoch 79 | loss: 0.46687 | valid_mse: 0.57494 |  0:00:05s\n",
      "epoch 80 | loss: 0.46203 | valid_mse: 0.56777 |  0:00:05s\n",
      "epoch 81 | loss: 0.4558  | valid_mse: 0.5679  |  0:00:05s\n",
      "epoch 82 | loss: 0.46225 | valid_mse: 0.57262 |  0:00:05s\n",
      "epoch 83 | loss: 0.45982 | valid_mse: 0.56704 |  0:00:05s\n",
      "epoch 84 | loss: 0.4634  | valid_mse: 0.56401 |  0:00:05s\n",
      "\n",
      "Early stopping occurred at epoch 84 with best_epoch = 64 and best_valid_mse = 0.49893\n",
      "Fold 3 - Train QWK: 0.6683, Validation QWK: 0.3439\n",
      "epoch 0  | loss: 2.11268 | valid_mse: 3.32999 |  0:00:00s\n",
      "\n",
      "Epoch 0: valid_mse improved from inf to 3.3300\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 1  | loss: 1.68713 | valid_mse: 12.24439|  0:00:00s\n",
      "epoch 2  | loss: 2.04035 | valid_mse: 1.3558  |  0:00:00s\n",
      "\n",
      "Epoch 2: valid_mse improved from 3.3300 to 1.3558\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 3  | loss: 1.09912 | valid_mse: 0.84685 |  0:00:00s\n",
      "\n",
      "Epoch 3: valid_mse improved from 1.3558 to 0.8468\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 4  | loss: 0.99176 | valid_mse: 1.0614  |  0:00:00s\n",
      "epoch 5  | loss: 0.97364 | valid_mse: 2.22418 |  0:00:00s\n",
      "epoch 6  | loss: 0.83286 | valid_mse: 2.06033 |  0:00:00s\n",
      "epoch 7  | loss: 0.81209 | valid_mse: 1.75186 |  0:00:00s\n",
      "epoch 8  | loss: 0.71134 | valid_mse: 1.55723 |  0:00:00s\n",
      "epoch 9  | loss: 0.70297 | valid_mse: 1.16002 |  0:00:00s\n",
      "epoch 10 | loss: 0.65236 | valid_mse: 0.86241 |  0:00:00s\n",
      "epoch 11 | loss: 0.66335 | valid_mse: 0.71063 |  0:00:00s\n",
      "\n",
      "Epoch 11: valid_mse improved from 0.8468 to 0.7106\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 12 | loss: 0.61639 | valid_mse: 0.65207 |  0:00:01s\n",
      "\n",
      "Epoch 12: valid_mse improved from 0.7106 to 0.6521\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 13 | loss: 0.61802 | valid_mse: 0.75863 |  0:00:01s\n",
      "epoch 14 | loss: 0.60331 | valid_mse: 0.7974  |  0:00:01s\n",
      "epoch 15 | loss: 0.58983 | valid_mse: 0.64451 |  0:00:01s\n",
      "\n",
      "Epoch 15: valid_mse improved from 0.6521 to 0.6445\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 16 | loss: 0.56295 | valid_mse: 0.65513 |  0:00:01s\n",
      "epoch 17 | loss: 0.55832 | valid_mse: 0.63638 |  0:00:01s\n",
      "\n",
      "Epoch 17: valid_mse improved from 0.6445 to 0.6364\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 18 | loss: 0.57107 | valid_mse: 0.60347 |  0:00:01s\n",
      "\n",
      "Epoch 18: valid_mse improved from 0.6364 to 0.6035\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 19 | loss: 0.54898 | valid_mse: 0.57557 |  0:00:01s\n",
      "\n",
      "Epoch 19: valid_mse improved from 0.6035 to 0.5756\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 20 | loss: 0.55143 | valid_mse: 0.58446 |  0:00:01s\n",
      "epoch 21 | loss: 0.54131 | valid_mse: 0.5837  |  0:00:01s\n",
      "epoch 22 | loss: 0.53223 | valid_mse: 0.52011 |  0:00:01s\n",
      "\n",
      "Epoch 22: valid_mse improved from 0.5756 to 0.5201\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 23 | loss: 0.53657 | valid_mse: 0.60593 |  0:00:01s\n",
      "epoch 24 | loss: 0.51881 | valid_mse: 0.6712  |  0:00:02s\n",
      "epoch 25 | loss: 0.54298 | valid_mse: 0.60706 |  0:00:02s\n",
      "epoch 26 | loss: 0.52747 | valid_mse: 0.6283  |  0:00:02s\n",
      "epoch 27 | loss: 0.51809 | valid_mse: 0.63959 |  0:00:02s\n",
      "epoch 28 | loss: 0.53184 | valid_mse: 0.69648 |  0:00:02s\n",
      "epoch 29 | loss: 0.51857 | valid_mse: 0.65959 |  0:00:02s\n",
      "epoch 30 | loss: 0.5159  | valid_mse: 0.63444 |  0:00:02s\n",
      "epoch 31 | loss: 0.52164 | valid_mse: 0.57185 |  0:00:02s\n",
      "epoch 32 | loss: 0.51648 | valid_mse: 0.55111 |  0:00:02s\n",
      "epoch 33 | loss: 0.51314 | valid_mse: 0.54525 |  0:00:02s\n",
      "epoch 34 | loss: 0.51894 | valid_mse: 0.54693 |  0:00:02s\n",
      "epoch 35 | loss: 0.50697 | valid_mse: 0.53484 |  0:00:02s\n",
      "epoch 36 | loss: 0.50679 | valid_mse: 0.52015 |  0:00:02s\n",
      "epoch 37 | loss: 0.51412 | valid_mse: 0.52995 |  0:00:02s\n",
      "epoch 38 | loss: 0.5191  | valid_mse: 0.52566 |  0:00:03s\n",
      "epoch 39 | loss: 0.51169 | valid_mse: 0.53797 |  0:00:03s\n",
      "epoch 40 | loss: 0.50992 | valid_mse: 0.58576 |  0:00:03s\n",
      "epoch 41 | loss: 0.51472 | valid_mse: 0.58151 |  0:00:03s\n",
      "epoch 42 | loss: 0.5129  | valid_mse: 0.65086 |  0:00:03s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_valid_mse = 0.52011\n",
      "Fold 4 - Train QWK: 0.6702, Validation QWK: 0.3730\n",
      "epoch 0  | loss: 3.04365 | valid_mse: 15.97106|  0:00:00s\n",
      "\n",
      "Epoch 0: valid_mse improved from inf to 15.9711\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 1  | loss: 1.55121 | valid_mse: 3.38135 |  0:00:00s\n",
      "\n",
      "Epoch 1: valid_mse improved from 15.9711 to 3.3814\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 2  | loss: 1.41075 | valid_mse: 211.22117|  0:00:00s\n",
      "epoch 3  | loss: 1.12592 | valid_mse: 58.72864|  0:00:00s\n",
      "epoch 4  | loss: 1.00645 | valid_mse: 7.38277 |  0:00:00s\n",
      "epoch 5  | loss: 0.82753 | valid_mse: 3.70151 |  0:00:00s\n",
      "epoch 6  | loss: 0.82254 | valid_mse: 3.64679 |  0:00:00s\n",
      "epoch 7  | loss: 0.70811 | valid_mse: 1.68915 |  0:00:00s\n",
      "\n",
      "Epoch 7: valid_mse improved from 3.3814 to 1.6891\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 8  | loss: 0.6892  | valid_mse: 1.46758 |  0:00:00s\n",
      "\n",
      "Epoch 8: valid_mse improved from 1.6891 to 1.4676\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 9  | loss: 0.64035 | valid_mse: 1.08137 |  0:00:00s\n",
      "\n",
      "Epoch 9: valid_mse improved from 1.4676 to 1.0814\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 10 | loss: 0.6043  | valid_mse: 0.88099 |  0:00:00s\n",
      "\n",
      "Epoch 10: valid_mse improved from 1.0814 to 0.8810\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 11 | loss: 0.61826 | valid_mse: 0.7714  |  0:00:00s\n",
      "\n",
      "Epoch 11: valid_mse improved from 0.8810 to 0.7714\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 12 | loss: 0.5832  | valid_mse: 0.67829 |  0:00:01s\n",
      "\n",
      "Epoch 12: valid_mse improved from 0.7714 to 0.6783\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 13 | loss: 0.58303 | valid_mse: 5.23655 |  0:00:01s\n",
      "epoch 14 | loss: 0.58722 | valid_mse: 3.1844  |  0:00:01s\n",
      "epoch 15 | loss: 0.55433 | valid_mse: 1.98033 |  0:00:01s\n",
      "epoch 16 | loss: 0.5615  | valid_mse: 2.46446 |  0:00:01s\n",
      "epoch 17 | loss: 0.56209 | valid_mse: 1.49387 |  0:00:01s\n",
      "epoch 18 | loss: 0.53177 | valid_mse: 1.70692 |  0:00:01s\n",
      "epoch 19 | loss: 0.53279 | valid_mse: 2.04954 |  0:00:01s\n",
      "epoch 20 | loss: 0.52952 | valid_mse: 2.83445 |  0:00:01s\n",
      "epoch 21 | loss: 0.5195  | valid_mse: 3.00905 |  0:00:01s\n",
      "epoch 22 | loss: 0.52319 | valid_mse: 1.61507 |  0:00:01s\n",
      "epoch 23 | loss: 0.52133 | valid_mse: 1.24848 |  0:00:01s\n",
      "epoch 24 | loss: 0.51654 | valid_mse: 0.66908 |  0:00:01s\n",
      "\n",
      "Epoch 24: valid_mse improved from 0.6783 to 0.6691\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 25 | loss: 0.50706 | valid_mse: 0.67373 |  0:00:01s\n",
      "epoch 26 | loss: 0.50313 | valid_mse: 0.68459 |  0:00:01s\n",
      "epoch 27 | loss: 0.51075 | valid_mse: 0.6822  |  0:00:01s\n",
      "epoch 28 | loss: 0.49903 | valid_mse: 0.62632 |  0:00:02s\n",
      "\n",
      "Epoch 28: valid_mse improved from 0.6691 to 0.6263\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 29 | loss: 0.51962 | valid_mse: 0.8737  |  0:00:02s\n",
      "epoch 30 | loss: 0.52645 | valid_mse: 1.00871 |  0:00:02s\n",
      "epoch 31 | loss: 0.50698 | valid_mse: 1.19725 |  0:00:02s\n",
      "epoch 32 | loss: 0.51343 | valid_mse: 1.42224 |  0:00:02s\n",
      "epoch 33 | loss: 0.51824 | valid_mse: 1.04777 |  0:00:02s\n",
      "epoch 34 | loss: 0.49977 | valid_mse: 1.02435 |  0:00:02s\n",
      "epoch 35 | loss: 0.50172 | valid_mse: 0.97272 |  0:00:02s\n",
      "epoch 36 | loss: 0.5063  | valid_mse: 0.77823 |  0:00:02s\n",
      "epoch 37 | loss: 0.50364 | valid_mse: 0.66546 |  0:00:02s\n",
      "epoch 38 | loss: 0.50898 | valid_mse: 0.64685 |  0:00:02s\n",
      "epoch 39 | loss: 0.5013  | valid_mse: 0.66487 |  0:00:02s\n",
      "epoch 40 | loss: 0.50273 | valid_mse: 0.72999 |  0:00:02s\n",
      "epoch 41 | loss: 0.49785 | valid_mse: 0.78357 |  0:00:02s\n",
      "epoch 42 | loss: 0.49112 | valid_mse: 0.72913 |  0:00:03s\n",
      "epoch 43 | loss: 0.4809  | valid_mse: 0.68287 |  0:00:03s\n",
      "epoch 44 | loss: 0.49031 | valid_mse: 0.70395 |  0:00:03s\n",
      "epoch 45 | loss: 0.48366 | valid_mse: 0.67482 |  0:00:03s\n",
      "epoch 46 | loss: 0.48834 | valid_mse: 0.65545 |  0:00:03s\n",
      "epoch 47 | loss: 0.49145 | valid_mse: 0.61145 |  0:00:03s\n",
      "\n",
      "Epoch 47: valid_mse improved from 0.6263 to 0.6115\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 48 | loss: 0.49328 | valid_mse: 0.58081 |  0:00:03s\n",
      "\n",
      "Epoch 48: valid_mse improved from 0.6115 to 0.5808\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 49 | loss: 0.48664 | valid_mse: 0.57779 |  0:00:03s\n",
      "\n",
      "Epoch 49: valid_mse improved from 0.5808 to 0.5778\n",
      "Successfully saved model at best_tabnet_model.pt.zip\n",
      "epoch 50 | loss: 0.48892 | valid_mse: 0.61709 |  0:00:03s\n",
      "epoch 51 | loss: 0.49665 | valid_mse: 0.62927 |  0:00:03s\n",
      "epoch 52 | loss: 0.49063 | valid_mse: 0.60865 |  0:00:03s\n",
      "epoch 53 | loss: 0.49248 | valid_mse: 0.6816  |  0:00:03s\n",
      "epoch 54 | loss: 0.48372 | valid_mse: 0.68654 |  0:00:03s\n",
      "epoch 55 | loss: 0.47865 | valid_mse: 0.67727 |  0:00:03s\n",
      "epoch 56 | loss: 0.47743 | valid_mse: 0.69755 |  0:00:04s\n",
      "epoch 57 | loss: 0.47875 | valid_mse: 0.7565  |  0:00:04s\n",
      "epoch 58 | loss: 0.47523 | valid_mse: 0.85492 |  0:00:04s\n",
      "epoch 59 | loss: 0.4793  | valid_mse: 0.93715 |  0:00:04s\n",
      "epoch 60 | loss: 0.47222 | valid_mse: 0.85627 |  0:00:04s\n",
      "epoch 61 | loss: 0.47078 | valid_mse: 0.84448 |  0:00:04s\n",
      "epoch 62 | loss: 0.46741 | valid_mse: 0.80045 |  0:00:04s\n",
      "epoch 63 | loss: 0.46817 | valid_mse: 0.78968 |  0:00:04s\n",
      "epoch 64 | loss: 0.47147 | valid_mse: 0.75058 |  0:00:04s\n",
      "epoch 65 | loss: 0.46106 | valid_mse: 0.67057 |  0:00:04s\n",
      "epoch 66 | loss: 0.46883 | valid_mse: 0.72749 |  0:00:04s\n",
      "epoch 67 | loss: 0.4669  | valid_mse: 0.70184 |  0:00:04s\n",
      "epoch 68 | loss: 0.46395 | valid_mse: 0.67528 |  0:00:04s\n",
      "epoch 69 | loss: 0.46322 | valid_mse: 0.67943 |  0:00:04s\n",
      "\n",
      "Early stopping occurred at epoch 69 with best_epoch = 49 and best_valid_mse = 0.57779\n",
      "Fold 5 - Train QWK: 0.6562, Validation QWK: 0.3803\n",
      "CV: 0.3605\n",
      "tuned Kappa: 0.440\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import (\n",
    "    VotingRegressor,\n",
    "    RandomForestRegressor,\n",
    "    GradientBoostingRegressor,\n",
    ")\n",
    "\n",
    "\n",
    "def extract_features(df):\n",
    "    return df[double_columns + add_features + embedding_cols]\n",
    "\n",
    "\n",
    "seed = 42\n",
    "oof = []\n",
    "cv_scores = []\n",
    "y = None\n",
    "\n",
    "# Model parameters for LightGBM\n",
    "Params = {\n",
    "    \"learning_rate\": 0.046,\n",
    "    \"max_depth\": 12,\n",
    "    \"num_leaves\": 478,\n",
    "    \"min_data_in_leaf\": 13,\n",
    "    \"feature_fraction\": 0.893,\n",
    "    \"bagging_fraction\": 0.784,\n",
    "    \"bagging_freq\": 4,\n",
    "    \"lambda_l1\": 10,  # Increased from 6.59\n",
    "    \"lambda_l2\": 0.01,  # Increased from 2.68e-06\n",
    "}\n",
    "XGB_Params = {\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"max_depth\": 6,\n",
    "    \"n_estimators\": 200,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"reg_alpha\": 1,  # Increased from 0.1\n",
    "    \"reg_lambda\": 5,  # Increased from 1\n",
    "    \"random_state\": seed,\n",
    "}\n",
    "\n",
    "\n",
    "CatBoost_Params = {\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"depth\": 6,\n",
    "    \"iterations\": 200,\n",
    "    \"random_seed\": seed,\n",
    "    \"verbose\": 0,\n",
    "    \"l2_leaf_reg\": 10,  # Increase this value\n",
    "}\n",
    "\n",
    "for fold in range(5):\n",
    "    Light = LGBMRegressor(**Params, random_state=seed, verbose=-1, n_estimators=300)\n",
    "    XGB_Model = XGBRegressor(**XGB_Params)\n",
    "    CatBoost_Model = CatBoostRegressor(**CatBoost_Params)\n",
    "    TabNet_Model = TabNetWrapper(**TabNet_Params)  # New\n",
    "\n",
    "    model = VotingRegressor(\n",
    "        estimators=[\n",
    "            (\"lightgbm\", Light),\n",
    "            (\"xgboost\", XGB_Model),\n",
    "            (\"catboost\", CatBoost_Model),\n",
    "            (\"tabnet\", TabNet_Model),\n",
    "        ]\n",
    "    )\n",
    "    # model = LGBMRegressor(**Params, random_state=seed, verbose=-1, n_estimators=300)\n",
    "\n",
    "    with open(f\"../divided-datasets/fold_train_ids_{fold}.pkl\", \"rb\") as f:\n",
    "        fold_train_ids = pickle.load(f)\n",
    "\n",
    "    with open(f\"../divided-datasets/fold_valid_ids_{fold}.pkl\", \"rb\") as f:\n",
    "        fold_valid_ids = pickle.load(f)\n",
    "\n",
    "    train_fold = train[train[\"id\"].isin(fold_train_ids)].reset_index(drop=True)\n",
    "    valid_fold = train[train[\"id\"].isin(fold_valid_ids)].reset_index(drop=True)\n",
    "\n",
    "    mode = \"drop\"\n",
    "\n",
    "    if mode == \"impute\":\n",
    "        numeric_cols = train.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
    "        imputer = KNNImputer(n_neighbors=5)\n",
    "        train_fold[numeric_cols] = imputer.fit_transform(train_fold[numeric_cols])\n",
    "        test[numeric_cols] = imputer.transform(test[numeric_cols])\n",
    "    elif mode == \"drop\":\n",
    "        train_fold = train_fold[train_fold[\"sii\"].notnull()].reset_index(drop=True)\n",
    "\n",
    "    train_fold_x = extract_features(train_fold)\n",
    "    valid_fold_x = extract_features(valid_fold)\n",
    "\n",
    "    train_fold_y = train_fold[\"sii\"].astype(int)\n",
    "    valid_fold_y = valid_fold[\"sii\"].astype(int)\n",
    "\n",
    "    model.fit(train_fold_x, train_fold_y)\n",
    "\n",
    "    # save model\n",
    "    with open(f\"./assets/model02_{fold}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "    train_pred = model.predict(train_fold_x)\n",
    "    valid_pred = model.predict(valid_fold_x)\n",
    "\n",
    "    train_kappa = quadratic_weighted_kappa(\n",
    "        train_fold_y, train_pred.round(0).astype(int)\n",
    "    )\n",
    "    val_kappa = quadratic_weighted_kappa(valid_fold_y, valid_pred.round(0).astype(int))\n",
    "    cv_scores.append(val_kappa)\n",
    "\n",
    "    print(\n",
    "        f\"Fold {fold+1} - Train QWK: {train_kappa:.4f}, Validation QWK: {val_kappa:.4f}\"\n",
    "    )\n",
    "\n",
    "    for i, id_ in enumerate(fold_valid_ids):\n",
    "        oof.append({\"id\": id_, \"sii\": valid_pred[i]})\n",
    "\n",
    "    if y is None:\n",
    "        y = valid_fold[[\"id\", \"sii\"]]\n",
    "    else:\n",
    "        y = pd.concat([y, valid_fold[[\"id\", \"sii\"]]], axis=0).reset_index(drop=True)\n",
    "\n",
    "oof = pd.DataFrame(oof)\n",
    "\n",
    "KappaOPtimizer = minimize(\n",
    "    evaluate_predictions,\n",
    "    x0=[0.5, 1.5, 2.5],\n",
    "    args=(y[\"sii\"].astype(int), oof[\"sii\"]),\n",
    "    method=\"Nelder-Mead\",\n",
    ")\n",
    "\n",
    "oof_tuned = threshold_Rounder(oof[\"sii\"], KappaOPtimizer.x)\n",
    "tKappa = quadratic_weighted_kappa(y[\"sii\"], oof_tuned)\n",
    "print(f\"CV: {np.mean(cv_scores):.4f}\")\n",
    "print(f\"tuned Kappa: {tKappa:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof.to_csv(\"./oof/oof.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
