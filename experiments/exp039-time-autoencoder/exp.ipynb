{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from src.dataloader_ import *\n",
    "from src.network_ import *\n",
    "from src.utils import *\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "\n",
    "train_series_dir = \"../../inputs/series_train.parquet/\"\n",
    "test_series_dir = \"../../inputs/series_test.parquet/\"\n",
    "\n",
    "data_dic_path = \"../../inputs/data_dictionary.csv\"\n",
    "sample_submission_path = \"../../inputs/sample_submission.csv\"\n",
    "train_path = \"../../inputs/train.csv\"\n",
    "test_path = \"../../inputs/test.csv\"\n",
    "\n",
    "train = pd.read_csv(train_path)\n",
    "test = pd.read_csv(test_path)\n",
    "sample_submission = pd.read_csv(sample_submission_path)\n",
    "data_dic = pd.read_csv(data_dic_path)\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def seed_torch(seed=1029):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "nb_name = os.path.basename(os.getcwd())  # notebook name\n",
    "seed_torch(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 24, 60, 15) (31, 24, 60, 15)\n",
      "(31, 24, 15) (31, 24, 15) (31, 24, 30)\n",
      "(744, 30)\n",
      "torch.Size([1, 744, 30])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def read_parquet(base_dir, id_):\n",
    "    path = os.path.join(base_dir, f\"id={id_}\", \"part-0.parquet\")\n",
    "    return pd.read_parquet(path)\n",
    "\n",
    "\n",
    "def get_valid_ids(base_dir):\n",
    "    return [f.split(\"=\")[1].split(\".\")[0] for f in os.listdir(base_dir)]\n",
    "\n",
    "\n",
    "p = read_parquet(base_dir=\"../../inputs/series_train.parquet/\", id_=\"ffcd4dbd\")\n",
    "# p = read_parquet(base_dir=\"../../inputs/series_train.parquet/\", id_=\"10e46254\")\n",
    "\n",
    "scale_columns = [\n",
    "    \"X\",\n",
    "    \"Y\",\n",
    "    \"Z\",\n",
    "    \"enmo\",\n",
    "    \"anglez\",\n",
    "    \"light\",\n",
    "    \"battery_voltage\",\n",
    "]\n",
    "\n",
    "masked_columns = [\n",
    "    \"masked_X\",\n",
    "    \"masked_Y\",\n",
    "    \"masked_Z\",\n",
    "    \"masked_enmo\",\n",
    "    \"masked_anglez\",\n",
    "    \"masked_light\",\n",
    "]\n",
    "\n",
    "original_columns = [\"battery_voltage\", \"non-wear_flag\"]\n",
    "\n",
    "p[\"non-wear_flag\"] = 1 - p[\"non-wear_flag\"]\n",
    "scaler_features = p[scale_columns].values\n",
    "scaler = StandardScaler()\n",
    "p[scale_columns] = scaler.fit_transform(scaler_features)\n",
    "\n",
    "for mask_col in masked_columns:\n",
    "    p[mask_col] = p[mask_col.replace(\"masked_\", \"\")] * p[\"non-wear_flag\"]\n",
    "\n",
    "p = p.fillna(0.0)\n",
    "\n",
    "groups = p.groupby(\"relative_date_PCIAT\")\n",
    "# グループごとにデータフレームのリストに分割\n",
    "chunks = [group.reset_index(drop=True) for _, group in groups]\n",
    "\n",
    "use_cols = masked_columns + original_columns + scale_columns\n",
    "watch_day = len(chunks)\n",
    "active_logs = np.zeros((31, 17280, len(use_cols)), dtype=np.float32)\n",
    "active_mask = np.zeros((31), dtype=np.int32)\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    if i == 0:  #\n",
    "        active_logs[i, -len(chunk) :, :] = chunk[use_cols].values\n",
    "    elif i == watch_day:\n",
    "        active_logs[i, : len(chunk), :] = chunk[use_cols].values\n",
    "    else:\n",
    "        array = chunk[use_cols].values\n",
    "        active_logs[i, : len(array), :] = array\n",
    "\n",
    "    active_mask[i] = 1\n",
    "\n",
    "    if i == 30:\n",
    "        break\n",
    "\n",
    "active_logs = active_logs.reshape(31, 24, 60, 12, 15)  # 12は1時間の分割数\n",
    "active_logs_mean = active_logs.mean(axis=3)  # 1時間の分割数で平均を取る # 31, 1440, 15\n",
    "# active_logs_var = active_logs.var(axis=3)  # 1時間の分割数で分散を取る # 31, 1440, 15\n",
    "active_logs = np.concatenate([active_logs_mean], axis=-1)  # (31, 24, 30)\n",
    "# print(active_logs_mean.shape, active_logs_var.shape, active_logs.shape)\n",
    "\n",
    "print(active_logs_mean.shape, active_logs.shape)\n",
    "\n",
    "active_logs_mean = active_logs.mean(axis=2)  # 1時間の分割数で平均を取る # 31, 1440, 15\n",
    "active_logs_var = active_logs.var(axis=2)  # 1時間の分割数で分散を取る # 31, 1440, 15\n",
    "active_logs = np.concatenate(\n",
    "    [active_logs_mean, active_logs_var], axis=-1\n",
    ")  # (31, 24, 30)\n",
    "print(active_logs_mean.shape, active_logs_var.shape, active_logs.shape)\n",
    "active_logs = active_logs.reshape(-1, 30)\n",
    "print(active_logs.shape)\n",
    "\n",
    "# active_logs = active_logs.unsqueeze(0)\n",
    "active_logs = torch.tensor(active_logs, dtype=torch.float32).unsqueeze(0).to(\"cuda\")\n",
    "print(active_logs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class TransformerAutoEncoder(nn.Module):\n",
    "    def __init__(self, d_model=128, nhead=4, num_layers=2):\n",
    "        super(TransformerAutoEncoder, self).__init__()\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead)\n",
    "        self.encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "        self.decoder_layer = nn.TransformerDecoderLayer(d_model=d_model, nhead=nhead)\n",
    "        self.decoder = nn.TransformerDecoder(self.decoder_layer, num_layers=num_layers)\n",
    "        self.embedding = nn.Linear(30, d_model)\n",
    "        self.output_layer = nn.Linear(d_model, 30)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  # (batch, day*time, d_model)\n",
    "        encoded = self.encoder(x.permute(1, 0, 2))  # (day*time, batch, d_model)\n",
    "        decoded = self.decoder(encoded, encoded)  # (day*time, batch, d_model)\n",
    "        return (\n",
    "            self.output_layer(decoded.permute(1, 0, 2)),\n",
    "            encoded,\n",
    "        )  # (batch, day*time, hidden)\n",
    "\n",
    "\n",
    "# Example\n",
    "model = TransformerAutoEncoder().to(\"cuda\")\n",
    "input_data = torch.randn(1, 744, 30).to(\"cuda\")\n",
    "output = model(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各モデルのインスタンス化\n",
    "# transformer_model = TransformerAutoEncoder()\n",
    "\n",
    "# # 正規分布からランダムに(1, 31, 17280, 15)の形状でデータを生成\n",
    "# input_data = torch.randn(1, 31, 17280, 15)\n",
    "\n",
    "# # 各モデルにデータを入力し、出力形状を確認\n",
    "# print(\"Input shape:\", input_data.shape)\n",
    "\n",
    "# # Transformerモデル\n",
    "# transformer_output = transformer_model(input_data)\n",
    "# print(\"Transformer Model output shape:\", transformer_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Basic_Demos-Enroll_Season</th>\n",
       "      <th>Basic_Demos-Age</th>\n",
       "      <th>Basic_Demos-Sex</th>\n",
       "      <th>CGAS-Season</th>\n",
       "      <th>CGAS-CGAS_Score</th>\n",
       "      <th>Physical-Season</th>\n",
       "      <th>Physical-BMI</th>\n",
       "      <th>Physical-Height</th>\n",
       "      <th>Physical-Weight</th>\n",
       "      <th>...</th>\n",
       "      <th>PCIAT-PCIAT_18</th>\n",
       "      <th>PCIAT-PCIAT_19</th>\n",
       "      <th>PCIAT-PCIAT_20</th>\n",
       "      <th>PCIAT-PCIAT_Total</th>\n",
       "      <th>SDS-Season</th>\n",
       "      <th>SDS-SDS_Total_Raw</th>\n",
       "      <th>SDS-SDS_Total_T</th>\n",
       "      <th>PreInt_EduHx-Season</th>\n",
       "      <th>PreInt_EduHx-computerinternet_hoursday</th>\n",
       "      <th>sii</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00008ff9</td>\n",
       "      <td>Fall</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>16.877316</td>\n",
       "      <td>46.0</td>\n",
       "      <td>50.8</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fall</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fd460</td>\n",
       "      <td>Summer</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fall</td>\n",
       "      <td>14.035590</td>\n",
       "      <td>48.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>46.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Summer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00105258</td>\n",
       "      <td>Summer</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Fall</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>16.648696</td>\n",
       "      <td>56.5</td>\n",
       "      <td>75.6</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>38.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00115b9f</td>\n",
       "      <td>Winter</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Summer</td>\n",
       "      <td>18.292347</td>\n",
       "      <td>56.0</td>\n",
       "      <td>81.6</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Summer</td>\n",
       "      <td>31.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0016bb22</td>\n",
       "      <td>Spring</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>Summer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3955</th>\n",
       "      <td>ff8a2de4</td>\n",
       "      <td>Fall</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>Spring</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>16.362460</td>\n",
       "      <td>59.5</td>\n",
       "      <td>82.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>35.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3956</th>\n",
       "      <td>ffa9794a</td>\n",
       "      <td>Winter</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spring</td>\n",
       "      <td>18.764678</td>\n",
       "      <td>53.5</td>\n",
       "      <td>76.4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Winter</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3957</th>\n",
       "      <td>ffcd4dbd</td>\n",
       "      <td>Fall</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>Spring</td>\n",
       "      <td>68.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>21.441500</td>\n",
       "      <td>60.0</td>\n",
       "      <td>109.8</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>56.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3958</th>\n",
       "      <td>ffed1dd5</td>\n",
       "      <td>Spring</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>Spring</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>12.235895</td>\n",
       "      <td>70.7</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Spring</td>\n",
       "      <td>33.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>Spring</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3959</th>\n",
       "      <td>ffef538e</td>\n",
       "      <td>Spring</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Winter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spring</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3960 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id Basic_Demos-Enroll_Season  Basic_Demos-Age  Basic_Demos-Sex  \\\n",
       "0     00008ff9                      Fall                5                0   \n",
       "1     000fd460                    Summer                9                0   \n",
       "2     00105258                    Summer               10                1   \n",
       "3     00115b9f                    Winter                9                0   \n",
       "4     0016bb22                    Spring               18                1   \n",
       "...        ...                       ...              ...              ...   \n",
       "3955  ff8a2de4                      Fall               13                0   \n",
       "3956  ffa9794a                    Winter               10                0   \n",
       "3957  ffcd4dbd                      Fall               11                0   \n",
       "3958  ffed1dd5                    Spring               13                0   \n",
       "3959  ffef538e                    Spring               11                0   \n",
       "\n",
       "     CGAS-Season  CGAS-CGAS_Score Physical-Season  Physical-BMI  \\\n",
       "0         Winter             51.0            Fall     16.877316   \n",
       "1            NaN              NaN            Fall     14.035590   \n",
       "2           Fall             71.0            Fall     16.648696   \n",
       "3           Fall             71.0          Summer     18.292347   \n",
       "4         Summer              NaN             NaN           NaN   \n",
       "...          ...              ...             ...           ...   \n",
       "3955      Spring             60.0            Fall     16.362460   \n",
       "3956         NaN              NaN          Spring     18.764678   \n",
       "3957      Spring             68.0          Winter     21.441500   \n",
       "3958      Spring             70.0          Winter     12.235895   \n",
       "3959         NaN              NaN          Winter           NaN   \n",
       "\n",
       "      Physical-Height  Physical-Weight  ...  PCIAT-PCIAT_18  PCIAT-PCIAT_19  \\\n",
       "0                46.0             50.8  ...             4.0             2.0   \n",
       "1                48.0             46.0  ...             0.0             0.0   \n",
       "2                56.5             75.6  ...             2.0             1.0   \n",
       "3                56.0             81.6  ...             3.0             4.0   \n",
       "4                 NaN              NaN  ...             NaN             NaN   \n",
       "...               ...              ...  ...             ...             ...   \n",
       "3955             59.5             82.4  ...             1.0             1.0   \n",
       "3956             53.5             76.4  ...             NaN             NaN   \n",
       "3957             60.0            109.8  ...             1.0             0.0   \n",
       "3958             70.7             87.0  ...             1.0             1.0   \n",
       "3959              NaN              NaN  ...             NaN             NaN   \n",
       "\n",
       "      PCIAT-PCIAT_20  PCIAT-PCIAT_Total SDS-Season  SDS-SDS_Total_Raw  \\\n",
       "0                4.0               55.0        NaN                NaN   \n",
       "1                0.0                0.0       Fall               46.0   \n",
       "2                1.0               28.0       Fall               38.0   \n",
       "3                1.0               44.0     Summer               31.0   \n",
       "4                NaN                NaN        NaN                NaN   \n",
       "...              ...                ...        ...                ...   \n",
       "3955             0.0               32.0     Winter               35.0   \n",
       "3956             NaN                NaN        NaN                NaN   \n",
       "3957             1.0               31.0     Winter               56.0   \n",
       "3958             1.0               19.0     Spring               33.0   \n",
       "3959             NaN                NaN        NaN                NaN   \n",
       "\n",
       "      SDS-SDS_Total_T  PreInt_EduHx-Season  \\\n",
       "0                 NaN                 Fall   \n",
       "1                64.0               Summer   \n",
       "2                54.0               Summer   \n",
       "3                45.0               Winter   \n",
       "4                 NaN                  NaN   \n",
       "...               ...                  ...   \n",
       "3955             50.0                 Fall   \n",
       "3956              NaN               Winter   \n",
       "3957             77.0                 Fall   \n",
       "3958             47.0               Spring   \n",
       "3959              NaN               Spring   \n",
       "\n",
       "     PreInt_EduHx-computerinternet_hoursday  sii  \n",
       "0                                       3.0  2.0  \n",
       "1                                       0.0  0.0  \n",
       "2                                       2.0  0.0  \n",
       "3                                       0.0  1.0  \n",
       "4                                       NaN  NaN  \n",
       "...                                     ...  ...  \n",
       "3955                                    1.0  1.0  \n",
       "3956                                    0.0  NaN  \n",
       "3957                                    0.0  1.0  \n",
       "3958                                    1.0  0.0  \n",
       "3959                                    1.0  NaN  \n",
       "\n",
       "[3960 rows x 82 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テーブルデータセット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_features = [\n",
    "    \"BMI_Age\",\n",
    "    \"Internet_Hours_Age\",\n",
    "    \"BMI_Internet_Hours\",\n",
    "    \"BFP_BMI\",\n",
    "    \"FFMI_BFP\",\n",
    "    \"FMI_BFP\",\n",
    "    \"LST_TBW\",\n",
    "    \"BFP_BMR\",\n",
    "    \"BFP_DEE\",\n",
    "    \"BMR_Weight\",\n",
    "    \"DEE_Weight\",\n",
    "    \"SMM_Height\",\n",
    "    \"Muscle_to_Fat\",\n",
    "    \"Hydration_Status\",\n",
    "    \"ICW_TBW\",\n",
    "]\n",
    "\n",
    "\n",
    "def feature_engineering(df):\n",
    "    # season_cols = [col for col in df.columns if \"Season\" in col]\n",
    "    # df = df.drop(season_cols, axis=1)\n",
    "    df[\"BMI_Age\"] = df[\"Physical-BMI\"] * df[\"Basic_Demos-Age\"]\n",
    "    df[\"Internet_Hours_Age\"] = (\n",
    "        df[\"PreInt_EduHx-computerinternet_hoursday\"] * df[\"Basic_Demos-Age\"]\n",
    "    )\n",
    "    df[\"BMI_Internet_Hours\"] = (\n",
    "        df[\"Physical-BMI\"] * df[\"PreInt_EduHx-computerinternet_hoursday\"]\n",
    "    )\n",
    "    df[\"BFP_BMI\"] = df[\"BIA-BIA_Fat\"] / df[\"BIA-BIA_BMI\"]\n",
    "    df[\"FFMI_BFP\"] = df[\"BIA-BIA_FFMI\"] / df[\"BIA-BIA_Fat\"]\n",
    "    df[\"FMI_BFP\"] = df[\"BIA-BIA_FMI\"] / df[\"BIA-BIA_Fat\"]\n",
    "    df[\"LST_TBW\"] = df[\"BIA-BIA_LST\"] / df[\"BIA-BIA_TBW\"]\n",
    "    df[\"BFP_BMR\"] = df[\"BIA-BIA_Fat\"] * df[\"BIA-BIA_BMR\"]\n",
    "    df[\"BFP_DEE\"] = df[\"BIA-BIA_Fat\"] * df[\"BIA-BIA_DEE\"]\n",
    "    df[\"BMR_Weight\"] = df[\"BIA-BIA_BMR\"] / df[\"Physical-Weight\"]\n",
    "    df[\"DEE_Weight\"] = df[\"BIA-BIA_DEE\"] / df[\"Physical-Weight\"]\n",
    "    df[\"SMM_Height\"] = df[\"BIA-BIA_SMM\"] / df[\"Physical-Height\"]\n",
    "    df[\"Muscle_to_Fat\"] = df[\"BIA-BIA_SMM\"] / df[\"BIA-BIA_FMI\"]\n",
    "    df[\"Hydration_Status\"] = df[\"BIA-BIA_TBW\"] / df[\"Physical-Weight\"]\n",
    "    df[\"ICW_TBW\"] = df[\"BIA-BIA_ICW\"] / df[\"BIA-BIA_TBW\"]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "train = feature_engineering(train)\n",
    "train = train.replace([np.inf, -np.inf], np.nan)\n",
    "for add_ in add_features:\n",
    "    train[add_] = train[add_].fillna(0.0)\n",
    "train = train.dropna(thresh=10, axis=0)\n",
    "\n",
    "test = feature_engineering(test)\n",
    "test = test.replace([np.inf, -np.inf], np.nan)\n",
    "for add_ in add_features:\n",
    "    test[add_] = test[add_].fillna(0.0)\n",
    "test = test.dropna(thresh=10, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create new scaler\n"
     ]
    }
   ],
   "source": [
    "# onehotEncoderの作成\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "double_columns = [\n",
    "    \"FGC-FGC_SRR_Zone\",\n",
    "    \"BIA-BIA_SMM\",\n",
    "    \"Physical-Waist_Circumference\",\n",
    "    \"BIA-BIA_FFMI\",\n",
    "    \"FGC-FGC_CU\",\n",
    "    \"PreInt_EduHx-computerinternet_hoursday\",\n",
    "    \"BIA-BIA_ECW\",\n",
    "    \"FGC-FGC_CU_Zone\",\n",
    "    \"FGC-FGC_SRL_Zone\",\n",
    "    \"BIA-BIA_DEE\",\n",
    "    \"Physical-Weight\",\n",
    "    \"Fitness_Endurance-Time_Mins\",\n",
    "    \"FGC-FGC_SRR\",\n",
    "    \"SDS-SDS_Total_T\",\n",
    "    \"FGC-FGC_PU\",\n",
    "    \"BIA-BIA_FFM\",\n",
    "    \"FGC-FGC_TL_Zone\",\n",
    "    \"Physical-BMI\",\n",
    "    \"Physical-Systolic_BP\",\n",
    "    \"Physical-HeartRate\",\n",
    "    \"BIA-BIA_ICW\",\n",
    "    \"Physical-Height\",\n",
    "    \"FGC-FGC_SRL\",\n",
    "    \"BIA-BIA_BMC\",\n",
    "    \"Fitness_Endurance-Time_Sec\",\n",
    "    \"BIA-BIA_Frame_num\",\n",
    "    \"Basic_Demos-Age\",\n",
    "    \"FGC-FGC_GSND_Zone\",\n",
    "    \"Basic_Demos-Sex\",\n",
    "    \"FGC-FGC_GSND\",\n",
    "    \"BIA-BIA_LST\",\n",
    "    \"FGC-FGC_TL\",\n",
    "    \"BIA-BIA_BMI\",\n",
    "    \"BIA-BIA_FMI\",\n",
    "    \"PAQ_C-PAQ_C_Total\",\n",
    "    \"BIA-BIA_Activity_Level_num\",\n",
    "    \"FGC-FGC_GSD\",\n",
    "    \"BIA-BIA_BMR\",\n",
    "    \"BIA-BIA_Fat\",\n",
    "    \"SDS-SDS_Total_Raw\",\n",
    "    \"CGAS-CGAS_Score\",\n",
    "    \"FGC-FGC_PU_Zone\",\n",
    "    \"BIA-BIA_LDM\",\n",
    "    \"Fitness_Endurance-Max_Stage\",\n",
    "    \"PAQ_A-PAQ_A_Total\",\n",
    "    \"BIA-BIA_TBW\",\n",
    "    \"FGC-FGC_GSD_Zone\",\n",
    "    \"Physical-Diastolic_BP\",\n",
    "]\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def create_dataset_(df, scaler=None, train=True):\n",
    "\n",
    "    if scaler is None:\n",
    "        print(\"create new scaler\")\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(df[double_columns + add_features])\n",
    "        with open(\"./assets/scaler.pkl\", \"wb\") as f:\n",
    "            pickle.dump(scaler, f)\n",
    "\n",
    "    double_feature = scaler.transform(df[double_columns + add_features])\n",
    "    # 欠損値の補完\n",
    "    double_feature = np.nan_to_num(double_feature)\n",
    "\n",
    "    ids = df[\"id\"].values.reshape(-1, 1)\n",
    "    X = double_feature\n",
    "\n",
    "    # DataFrameの作成\n",
    "    ids_df = pd.DataFrame(ids, columns=[\"id\"])\n",
    "    X_df = pd.DataFrame(X, columns=[f\"feature_{i}\" for i in range(X.shape[1])])\n",
    "\n",
    "    if train:\n",
    "        y = df[\"sii\"].fillna(-1).values.reshape(-1, 1)\n",
    "        y_df = pd.DataFrame(y, columns=[\"sii\"])\n",
    "        df = pd.concat([ids_df, X_df, y_df], axis=1)\n",
    "    else:\n",
    "        df = pd.concat([ids_df, X_df], axis=1)\n",
    "    return df, scaler\n",
    "\n",
    "\n",
    "train, scaler = create_dataset_(train)\n",
    "test = create_dataset_(test, scaler=scaler, train=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_55</th>\n",
       "      <th>feature_56</th>\n",
       "      <th>feature_57</th>\n",
       "      <th>feature_58</th>\n",
       "      <th>feature_59</th>\n",
       "      <th>feature_60</th>\n",
       "      <th>feature_61</th>\n",
       "      <th>feature_62</th>\n",
       "      <th>id</th>\n",
       "      <th>sii</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.277596</td>\n",
       "      <td>-0.176702</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.209436</td>\n",
       "      <td>-0.953788</td>\n",
       "      <td>1.771623</td>\n",
       "      <td>-0.171600</td>\n",
       "      <td>-0.953742</td>\n",
       "      <td>-1.274301</td>\n",
       "      <td>-0.201970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015691</td>\n",
       "      <td>0.015630</td>\n",
       "      <td>0.531031</td>\n",
       "      <td>0.540327</td>\n",
       "      <td>0.113954</td>\n",
       "      <td>0.083339</td>\n",
       "      <td>0.251650</td>\n",
       "      <td>1.296492</td>\n",
       "      <td>00008ff9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.782720</td>\n",
       "      <td>-0.225858</td>\n",
       "      <td>-0.948658</td>\n",
       "      <td>-0.380787</td>\n",
       "      <td>-0.699663</td>\n",
       "      <td>-0.968830</td>\n",
       "      <td>-0.202128</td>\n",
       "      <td>-0.953742</td>\n",
       "      <td>0.784744</td>\n",
       "      <td>-0.199625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015270</td>\n",
       "      <td>0.015181</td>\n",
       "      <td>0.629987</td>\n",
       "      <td>0.643793</td>\n",
       "      <td>0.021863</td>\n",
       "      <td>0.304658</td>\n",
       "      <td>0.209698</td>\n",
       "      <td>1.388511</td>\n",
       "      <td>000fd460</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.782720</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.740376</td>\n",
       "      <td>0.858138</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.048502</td>\n",
       "      <td>0.784744</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014948</td>\n",
       "      <td>0.014837</td>\n",
       "      <td>-0.374560</td>\n",
       "      <td>-0.406553</td>\n",
       "      <td>-0.263102</td>\n",
       "      <td>-0.139659</td>\n",
       "      <td>-0.235959</td>\n",
       "      <td>-0.993169</td>\n",
       "      <td>00105258</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.277596</td>\n",
       "      <td>-0.094130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.165178</td>\n",
       "      <td>0.570959</td>\n",
       "      <td>-0.968830</td>\n",
       "      <td>-0.071440</td>\n",
       "      <td>1.048502</td>\n",
       "      <td>-1.274301</td>\n",
       "      <td>-0.049816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016791</td>\n",
       "      <td>0.016926</td>\n",
       "      <td>0.309486</td>\n",
       "      <td>0.353385</td>\n",
       "      <td>0.156596</td>\n",
       "      <td>0.079541</td>\n",
       "      <td>0.191155</td>\n",
       "      <td>1.031686</td>\n",
       "      <td>00115b9f</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014948</td>\n",
       "      <td>0.014837</td>\n",
       "      <td>-0.374560</td>\n",
       "      <td>-0.406553</td>\n",
       "      <td>-0.263102</td>\n",
       "      <td>-0.139659</td>\n",
       "      <td>-0.235959</td>\n",
       "      <td>-0.993169</td>\n",
       "      <td>0016bb22</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0  -1.277596  -0.176702   0.000000  -0.209436  -0.953788   1.771623   \n",
       "1   0.782720  -0.225858  -0.948658  -0.380787  -0.699663  -0.968830   \n",
       "2   0.782720   0.000000   0.000000   0.000000   0.740376   0.858138   \n",
       "3  -1.277596  -0.094130   0.000000  -0.165178   0.570959  -0.968830   \n",
       "4   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "\n",
       "   feature_6  feature_7  feature_8  feature_9  ...  feature_55  feature_56  \\\n",
       "0  -0.171600  -0.953742  -1.274301  -0.201970  ...    0.015691    0.015630   \n",
       "1  -0.202128  -0.953742   0.784744  -0.199625  ...    0.015270    0.015181   \n",
       "2   0.000000   1.048502   0.784744   0.000000  ...    0.014948    0.014837   \n",
       "3  -0.071440   1.048502  -1.274301  -0.049816  ...    0.016791    0.016926   \n",
       "4   0.000000   0.000000   0.000000   0.000000  ...    0.014948    0.014837   \n",
       "\n",
       "   feature_57  feature_58  feature_59  feature_60  feature_61  feature_62  \\\n",
       "0    0.531031    0.540327    0.113954    0.083339    0.251650    1.296492   \n",
       "1    0.629987    0.643793    0.021863    0.304658    0.209698    1.388511   \n",
       "2   -0.374560   -0.406553   -0.263102   -0.139659   -0.235959   -0.993169   \n",
       "3    0.309486    0.353385    0.156596    0.079541    0.191155    1.031686   \n",
       "4   -0.374560   -0.406553   -0.263102   -0.139659   -0.235959   -0.993169   \n",
       "\n",
       "         id  sii  \n",
       "0  00008ff9  2.0  \n",
       "1  000fd460  0.0  \n",
       "2  00105258  0.0  \n",
       "3  00115b9f  1.0  \n",
       "4  0016bb22 -1.0  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imputer = KNNImputer(n_neighbors=5)\n",
    "sii_imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "numeric_cols = test.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
    "numeric_feature_cols = numeric_cols.copy()\n",
    "# numeric_feature_cols = numeric_feature_cols.drop(\"sii\")\n",
    "\n",
    "numeric_sii_cols = train.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
    "\n",
    "sii_inputed = sii_imputer.fit_transform(train[numeric_sii_cols])\n",
    "feature_imputer.fit(test[numeric_feature_cols])\n",
    "feature_inputed = feature_imputer.fit_transform(train[numeric_feature_cols])\n",
    "\n",
    "train_imputed = pd.DataFrame(feature_inputed, columns=numeric_feature_cols)\n",
    "\n",
    "for col in train.columns:\n",
    "    if col not in numeric_cols:\n",
    "        train_imputed[col] = train[col]\n",
    "\n",
    "train_imputed[\"sii\"] = train[\"sii\"]\n",
    "train = train_imputed\n",
    "\n",
    "# train = train[train[\"sii\"] > -1].reset_index(drop=True)\n",
    "train = train[train[\"sii\"].notnull()].reset_index(drop=True)\n",
    "\n",
    "# sii_impute = pd.DataFrame(sii_inputed, columns=numeric_sii_cols)\n",
    "# sii_impute[\"sii\"] = sii_impute[\"sii\"].round().astype(int)\n",
    "# train[\"sii\"] = sii_impute[\"sii\"]\n",
    "\n",
    "with open(\"feature_imputer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(feature_imputer, f)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CMIDataset(Dataset):\n",
    "    def __init__(self, table_df, valid_ids, base_dir, save_filename):\n",
    "        self.base_dir = base_dir\n",
    "        self.table_df = table_df\n",
    "        self.valid_ids = valid_ids\n",
    "        self.save_filename = save_filename\n",
    "        self.scale_columns = [\n",
    "            \"X\",\n",
    "            \"Y\",\n",
    "            \"Z\",\n",
    "            \"enmo\",\n",
    "            \"anglez\",\n",
    "            \"light\",\n",
    "            \"battery_voltage\",\n",
    "        ]\n",
    "\n",
    "        self.masked_columns = [\n",
    "            \"masked_X\",\n",
    "            \"masked_Y\",\n",
    "            \"masked_Z\",\n",
    "            \"masked_enmo\",\n",
    "            \"masked_anglez\",\n",
    "            \"masked_light\",\n",
    "        ]\n",
    "\n",
    "        self.original_columns = [\"battery_voltage\", \"non-wear_flag\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # テーブルデータの抽出\n",
    "        id_ = self.valid_ids[idx]\n",
    "\n",
    "        save_dir = f\"/home/tatsuya/code/projects/kaggle/ChildMindInstitute2024/precreated_dataset/{self.save_filename}/\"\n",
    "        save_path = os.path.join(save_dir, id_)\n",
    "\n",
    "        table = self.table_df.loc[self.table_df[\"id\"] == self.valid_ids[idx], :]\n",
    "        table_feature = table.drop(columns=[\"id\", \"sii\"]).values\n",
    "        sii = table[\"sii\"].values\n",
    "\n",
    "        # 時系列データの抽出\n",
    "        use_cols = self.masked_columns + self.original_columns + self.scale_columns\n",
    "        p = read_parquet(self.base_dir, self.valid_ids[idx])\n",
    "\n",
    "        if p is not None:\n",
    "            p[\"non-wear_flag\"] = 1 - p[\"non-wear_flag\"]\n",
    "            scaler_features = p[scale_columns].values\n",
    "            scaler = StandardScaler()\n",
    "            p[scale_columns] = scaler.fit_transform(scaler_features)\n",
    "\n",
    "            for mask_col in masked_columns:\n",
    "                p[mask_col] = p[mask_col.replace(\"masked_\", \"\")] * p[\"non-wear_flag\"]\n",
    "\n",
    "            p = p.fillna(0.0)\n",
    "\n",
    "            groups = p.groupby(\"relative_date_PCIAT\")\n",
    "            # グループごとにデータフレームのリストに分割\n",
    "            chunks = [group.reset_index(drop=True) for _, group in groups]\n",
    "\n",
    "            use_cols = masked_columns + original_columns + scale_columns\n",
    "            watch_day = len(chunks)\n",
    "            active_logs = np.zeros((31, 17280, len(use_cols)), dtype=np.float32)\n",
    "            active_mask = np.zeros((31), dtype=np.int32)\n",
    "\n",
    "            for i, chunk in enumerate(chunks):\n",
    "                if i == 0:  #\n",
    "                    active_logs[i, -len(chunk) :, :] = chunk[use_cols].values\n",
    "                elif i == watch_day:\n",
    "                    active_logs[i, : len(chunk), :] = chunk[use_cols].values\n",
    "                else:\n",
    "                    array = chunk[use_cols].values\n",
    "                    active_logs[i, : len(array), :] = array\n",
    "\n",
    "                active_mask[i] = 1\n",
    "\n",
    "                if i == 30:\n",
    "                    break\n",
    "\n",
    "            active_logs = active_logs.reshape(31, 24, 60, 12, 15)  # 12は1時間の分割数\n",
    "            active_logs_mean = active_logs.mean(\n",
    "                axis=3\n",
    "            )  # 1時間の分割数で平均を取る # 31, 1440, 15\n",
    "            # active_logs_var = active_logs.var(axis=3)  # 1時間の分割数で分散を取る # 31, 1440, 15\n",
    "            active_logs = np.concatenate([active_logs_mean], axis=-1)  # (31, 24, 30)\n",
    "            # print(active_logs_mean.shape, active_logs_var.shape, active_logs.shape)\n",
    "\n",
    "            # print(active_logs_mean.shape, active_logs.shape)\n",
    "\n",
    "            active_logs_mean = active_logs.mean(\n",
    "                axis=2\n",
    "            )  # 1時間の分割数で平均を取る # 31, 1440, 15\n",
    "            active_logs_var = active_logs.var(\n",
    "                axis=2\n",
    "            )  # 1時間の分割数で分散を取る # 31, 1440, 15\n",
    "            active_logs = np.concatenate(\n",
    "                [active_logs_mean, active_logs_var], axis=-1\n",
    "            )  # (31, 24, 30)\n",
    "            # print(active_logs_mean.shape, active_logs_var.shape, active_logs.shape)\n",
    "            active_logs = active_logs.reshape(-1, 30)\n",
    "\n",
    "        else:\n",
    "            active_logs = np.zeros((744, 30), dtype=np.float32)\n",
    "            active_mask = np.zeros((744), dtype=np.int32)\n",
    "\n",
    "        dataset_ = {\n",
    "            \"id\": id_,\n",
    "            \"table_input\": torch.tensor(table_feature, dtype=torch.float32),\n",
    "            \"time_input\": torch.tensor(active_logs, dtype=torch.float32),\n",
    "            \"mask\": torch.tensor(active_mask, dtype=torch.int32),\n",
    "            \"output\": torch.tensor(sii, dtype=torch.float32),\n",
    "        }\n",
    "\n",
    "        return dataset_\n",
    "\n",
    "\n",
    "def read_parquet(base_dir, id_):\n",
    "    path = os.path.join(base_dir, f\"id={id_}\", \"part-0.parquet\")\n",
    "    if not os.path.exists(path):\n",
    "        return None\n",
    "    return pd.read_parquet(path)\n",
    "\n",
    "\n",
    "dataset = CMIDataset(\n",
    "    table_df=train,\n",
    "    valid_ids=get_valid_ids(train_series_dir),\n",
    "    base_dir=train_series_dir,\n",
    "    save_filename=\"train\",\n",
    ")\n",
    "\n",
    "# AutoEncoderのモデルのインスタンス化\n",
    "transformer_model = TransformerAutoEncoder().to(\"cuda\")\n",
    "transformer_model.load_state_dict(torch.load(\"./assets/transformer_autoencoder.pth\"))\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(transformer_model.parameters(), lr=0.0001)\n",
    "# データセットからデータを取り出す\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "best_model = None\n",
    "minimum_loss = 1000000\n",
    "\n",
    "# for epoch in range(10):\n",
    "#     print(f\"Epoch {epoch}\")\n",
    "#     dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "#     epoch_loss = []\n",
    "#     tq = tqdm(dataloader)\n",
    "#     for data in dataloader:\n",
    "#         optimizer.zero_grad()\n",
    "#         table_input = data[\"table_input\"]\n",
    "#         time_input = data[\"time_input\"].to(\"cuda\")\n",
    "#         mask = data[\"mask\"]\n",
    "\n",
    "#         # モデルにデータを入力し、出力を取得\n",
    "#         transformer_output, embedding = transformer_model(time_input)\n",
    "#         # 損失の計算\n",
    "#         loss = criterion(transformer_output, time_input)\n",
    "#         loss.backward()\n",
    "\n",
    "#         optimizer.step()\n",
    "\n",
    "#         epoch_loss.append(loss.item())\n",
    "\n",
    "#         tq.set_postfix(loss=np.mean(epoch_loss))\n",
    "#         tq.update()\n",
    "\n",
    "#     if np.mean(epoch_loss) < minimum_loss:\n",
    "#         minimum_loss = np.mean(epoch_loss)\n",
    "#         best_model = transformer_model\n",
    "#         transformer_model.eval()\n",
    "#         torch.save(\n",
    "#             transformer_model.state_dict(), \"./assets/transformer_autoencoder.pth\"\n",
    "#         )\n",
    "#         model.train()\n",
    "\n",
    "#     print(f\"Epoch {epoch} Loss: {np.mean(epoch_loss)}\")\n",
    "#     tq.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 996/996 [01:43<00:00,  9.62it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = CMIDataset(\n",
    "    table_df=train,\n",
    "    valid_ids=get_valid_ids(train_series_dir),\n",
    "    base_dir=train_series_dir,\n",
    "    save_filename=\"train\",\n",
    ")\n",
    "\n",
    "# AutoEncoderのモデルのインスタンス化\n",
    "transformer_model = TransformerAutoEncoder().to(\"cuda\")\n",
    "transformer_model.load_state_dict(torch.load(\"./assets/transformer_autoencoder.pth\"))\n",
    "# データセットからデータを取り出す\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "best_model = None\n",
    "minimum_loss = 1000000\n",
    "\n",
    "print(f\"Create Embedding\")\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "epoch_loss = []\n",
    "tq = tqdm(dataloader)\n",
    "\n",
    "embedding_result = []\n",
    "\n",
    "for data in dataloader:\n",
    "    id_ = data[\"id\"][0]\n",
    "    table_input = data[\"table_input\"]\n",
    "    time_input = data[\"time_input\"].to(\"cuda\")\n",
    "    mask = data[\"mask\"]\n",
    "\n",
    "    # モデルにデータを入力し、出力を取得\n",
    "    transformer_output, embedding = transformer_model(time_input)\n",
    "    # 損失の計算\n",
    "\n",
    "    mean_embedding = transformer_output.squeeze(0).mean(axis=0).cpu().detach().numpy()\n",
    "\n",
    "    embedding_result.append({\"id\": id_, \"embedding\": mean_embedding})\n",
    "\n",
    "    tq.update()\n",
    "\n",
    "tq.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>embedding_0</th>\n",
       "      <th>embedding_1</th>\n",
       "      <th>embedding_2</th>\n",
       "      <th>embedding_3</th>\n",
       "      <th>embedding_4</th>\n",
       "      <th>embedding_5</th>\n",
       "      <th>embedding_6</th>\n",
       "      <th>embedding_7</th>\n",
       "      <th>embedding_8</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_20</th>\n",
       "      <th>embedding_21</th>\n",
       "      <th>embedding_22</th>\n",
       "      <th>embedding_23</th>\n",
       "      <th>embedding_24</th>\n",
       "      <th>embedding_25</th>\n",
       "      <th>embedding_26</th>\n",
       "      <th>embedding_27</th>\n",
       "      <th>embedding_28</th>\n",
       "      <th>embedding_29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23dafdab</td>\n",
       "      <td>0.068926</td>\n",
       "      <td>-0.014595</td>\n",
       "      <td>-0.103462</td>\n",
       "      <td>0.059614</td>\n",
       "      <td>-0.092798</td>\n",
       "      <td>0.003341</td>\n",
       "      <td>0.028464</td>\n",
       "      <td>0.334155</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408365</td>\n",
       "      <td>0.016664</td>\n",
       "      <td>-0.004178</td>\n",
       "      <td>0.240146</td>\n",
       "      <td>0.133450</td>\n",
       "      <td>0.120292</td>\n",
       "      <td>0.390237</td>\n",
       "      <td>0.074538</td>\n",
       "      <td>0.395821</td>\n",
       "      <td>0.046863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e4614ec6</td>\n",
       "      <td>0.040451</td>\n",
       "      <td>-0.000657</td>\n",
       "      <td>-0.108506</td>\n",
       "      <td>0.038684</td>\n",
       "      <td>-0.103874</td>\n",
       "      <td>0.040764</td>\n",
       "      <td>0.033631</td>\n",
       "      <td>0.593819</td>\n",
       "      <td>0.014481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.556205</td>\n",
       "      <td>0.026471</td>\n",
       "      <td>-0.003477</td>\n",
       "      <td>0.263422</td>\n",
       "      <td>0.344161</td>\n",
       "      <td>0.184349</td>\n",
       "      <td>0.346207</td>\n",
       "      <td>0.144879</td>\n",
       "      <td>0.561640</td>\n",
       "      <td>0.039844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56ef356c</td>\n",
       "      <td>0.043411</td>\n",
       "      <td>-0.062176</td>\n",
       "      <td>-0.008028</td>\n",
       "      <td>0.016733</td>\n",
       "      <td>-0.015377</td>\n",
       "      <td>0.038122</td>\n",
       "      <td>0.121043</td>\n",
       "      <td>0.585679</td>\n",
       "      <td>0.012155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.549246</td>\n",
       "      <td>0.020205</td>\n",
       "      <td>-0.000845</td>\n",
       "      <td>0.335549</td>\n",
       "      <td>0.302984</td>\n",
       "      <td>0.280522</td>\n",
       "      <td>0.281905</td>\n",
       "      <td>0.230765</td>\n",
       "      <td>0.542607</td>\n",
       "      <td>0.038612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dcfcd574</td>\n",
       "      <td>0.060240</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.038648</td>\n",
       "      <td>0.033649</td>\n",
       "      <td>0.050442</td>\n",
       "      <td>0.042230</td>\n",
       "      <td>0.024044</td>\n",
       "      <td>0.637869</td>\n",
       "      <td>0.022044</td>\n",
       "      <td>...</td>\n",
       "      <td>0.616247</td>\n",
       "      <td>0.028653</td>\n",
       "      <td>-0.006301</td>\n",
       "      <td>0.325850</td>\n",
       "      <td>0.336815</td>\n",
       "      <td>0.299664</td>\n",
       "      <td>0.353395</td>\n",
       "      <td>0.254361</td>\n",
       "      <td>0.609780</td>\n",
       "      <td>0.045767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>338146bd</td>\n",
       "      <td>0.018953</td>\n",
       "      <td>-0.029893</td>\n",
       "      <td>-0.019406</td>\n",
       "      <td>0.016911</td>\n",
       "      <td>-0.011566</td>\n",
       "      <td>0.043179</td>\n",
       "      <td>0.013116</td>\n",
       "      <td>0.422765</td>\n",
       "      <td>0.008286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.383302</td>\n",
       "      <td>0.030628</td>\n",
       "      <td>-0.013255</td>\n",
       "      <td>0.244304</td>\n",
       "      <td>0.231728</td>\n",
       "      <td>0.205477</td>\n",
       "      <td>0.250690</td>\n",
       "      <td>0.164476</td>\n",
       "      <td>0.377592</td>\n",
       "      <td>0.047318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2a9e0dee</td>\n",
       "      <td>0.017817</td>\n",
       "      <td>-0.046227</td>\n",
       "      <td>0.033119</td>\n",
       "      <td>0.018138</td>\n",
       "      <td>0.043048</td>\n",
       "      <td>0.027544</td>\n",
       "      <td>0.042394</td>\n",
       "      <td>0.559078</td>\n",
       "      <td>0.016423</td>\n",
       "      <td>...</td>\n",
       "      <td>0.441594</td>\n",
       "      <td>0.028671</td>\n",
       "      <td>-0.005370</td>\n",
       "      <td>0.259207</td>\n",
       "      <td>0.292630</td>\n",
       "      <td>0.230658</td>\n",
       "      <td>0.313412</td>\n",
       "      <td>0.179261</td>\n",
       "      <td>0.442187</td>\n",
       "      <td>0.048967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0eddd8e5</td>\n",
       "      <td>0.038019</td>\n",
       "      <td>-0.008936</td>\n",
       "      <td>-0.016173</td>\n",
       "      <td>0.018726</td>\n",
       "      <td>0.006175</td>\n",
       "      <td>0.026303</td>\n",
       "      <td>0.026175</td>\n",
       "      <td>0.591558</td>\n",
       "      <td>0.020305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463614</td>\n",
       "      <td>0.026121</td>\n",
       "      <td>-0.012250</td>\n",
       "      <td>0.250090</td>\n",
       "      <td>0.291128</td>\n",
       "      <td>0.265269</td>\n",
       "      <td>0.268364</td>\n",
       "      <td>0.230747</td>\n",
       "      <td>0.470925</td>\n",
       "      <td>0.029657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a49eda7f</td>\n",
       "      <td>0.023885</td>\n",
       "      <td>-0.039054</td>\n",
       "      <td>-0.014444</td>\n",
       "      <td>0.000602</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.005968</td>\n",
       "      <td>0.029405</td>\n",
       "      <td>0.664535</td>\n",
       "      <td>0.008971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500385</td>\n",
       "      <td>0.021962</td>\n",
       "      <td>-0.015175</td>\n",
       "      <td>0.358273</td>\n",
       "      <td>0.295093</td>\n",
       "      <td>0.297389</td>\n",
       "      <td>0.334659</td>\n",
       "      <td>0.271645</td>\n",
       "      <td>0.484378</td>\n",
       "      <td>0.047824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fa34f945</td>\n",
       "      <td>-0.068364</td>\n",
       "      <td>-0.069794</td>\n",
       "      <td>-0.041300</td>\n",
       "      <td>0.108960</td>\n",
       "      <td>-0.026806</td>\n",
       "      <td>0.067783</td>\n",
       "      <td>0.004556</td>\n",
       "      <td>0.263245</td>\n",
       "      <td>0.003036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.348257</td>\n",
       "      <td>0.035965</td>\n",
       "      <td>-0.003825</td>\n",
       "      <td>0.266872</td>\n",
       "      <td>0.101013</td>\n",
       "      <td>0.036425</td>\n",
       "      <td>0.368149</td>\n",
       "      <td>-0.010114</td>\n",
       "      <td>0.344275</td>\n",
       "      <td>0.052673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>526f719b</td>\n",
       "      <td>0.048418</td>\n",
       "      <td>-0.037592</td>\n",
       "      <td>0.013645</td>\n",
       "      <td>0.018400</td>\n",
       "      <td>-0.002267</td>\n",
       "      <td>0.012561</td>\n",
       "      <td>0.072507</td>\n",
       "      <td>0.520360</td>\n",
       "      <td>0.006360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.371377</td>\n",
       "      <td>0.021114</td>\n",
       "      <td>-0.004505</td>\n",
       "      <td>0.171238</td>\n",
       "      <td>0.241856</td>\n",
       "      <td>0.211704</td>\n",
       "      <td>0.303007</td>\n",
       "      <td>0.175609</td>\n",
       "      <td>0.357430</td>\n",
       "      <td>0.037011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>996 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  embedding_0  embedding_1  embedding_2  embedding_3  embedding_4  \\\n",
       "0   23dafdab     0.068926    -0.014595    -0.103462     0.059614    -0.092798   \n",
       "0   e4614ec6     0.040451    -0.000657    -0.108506     0.038684    -0.103874   \n",
       "0   56ef356c     0.043411    -0.062176    -0.008028     0.016733    -0.015377   \n",
       "0   dcfcd574     0.060240     0.000210     0.038648     0.033649     0.050442   \n",
       "0   338146bd     0.018953    -0.029893    -0.019406     0.016911    -0.011566   \n",
       "..       ...          ...          ...          ...          ...          ...   \n",
       "0   2a9e0dee     0.017817    -0.046227     0.033119     0.018138     0.043048   \n",
       "0   0eddd8e5     0.038019    -0.008936    -0.016173     0.018726     0.006175   \n",
       "0   a49eda7f     0.023885    -0.039054    -0.014444     0.000602     0.000083   \n",
       "0   fa34f945    -0.068364    -0.069794    -0.041300     0.108960    -0.026806   \n",
       "0   526f719b     0.048418    -0.037592     0.013645     0.018400    -0.002267   \n",
       "\n",
       "    embedding_5  embedding_6  embedding_7  embedding_8  ...  embedding_20  \\\n",
       "0      0.003341     0.028464     0.334155     0.004455  ...      0.408365   \n",
       "0      0.040764     0.033631     0.593819     0.014481  ...      0.556205   \n",
       "0      0.038122     0.121043     0.585679     0.012155  ...      0.549246   \n",
       "0      0.042230     0.024044     0.637869     0.022044  ...      0.616247   \n",
       "0      0.043179     0.013116     0.422765     0.008286  ...      0.383302   \n",
       "..          ...          ...          ...          ...  ...           ...   \n",
       "0      0.027544     0.042394     0.559078     0.016423  ...      0.441594   \n",
       "0      0.026303     0.026175     0.591558     0.020305  ...      0.463614   \n",
       "0      0.005968     0.029405     0.664535     0.008971  ...      0.500385   \n",
       "0      0.067783     0.004556     0.263245     0.003036  ...      0.348257   \n",
       "0      0.012561     0.072507     0.520360     0.006360  ...      0.371377   \n",
       "\n",
       "    embedding_21  embedding_22  embedding_23  embedding_24  embedding_25  \\\n",
       "0       0.016664     -0.004178      0.240146      0.133450      0.120292   \n",
       "0       0.026471     -0.003477      0.263422      0.344161      0.184349   \n",
       "0       0.020205     -0.000845      0.335549      0.302984      0.280522   \n",
       "0       0.028653     -0.006301      0.325850      0.336815      0.299664   \n",
       "0       0.030628     -0.013255      0.244304      0.231728      0.205477   \n",
       "..           ...           ...           ...           ...           ...   \n",
       "0       0.028671     -0.005370      0.259207      0.292630      0.230658   \n",
       "0       0.026121     -0.012250      0.250090      0.291128      0.265269   \n",
       "0       0.021962     -0.015175      0.358273      0.295093      0.297389   \n",
       "0       0.035965     -0.003825      0.266872      0.101013      0.036425   \n",
       "0       0.021114     -0.004505      0.171238      0.241856      0.211704   \n",
       "\n",
       "    embedding_26  embedding_27  embedding_28  embedding_29  \n",
       "0       0.390237      0.074538      0.395821      0.046863  \n",
       "0       0.346207      0.144879      0.561640      0.039844  \n",
       "0       0.281905      0.230765      0.542607      0.038612  \n",
       "0       0.353395      0.254361      0.609780      0.045767  \n",
       "0       0.250690      0.164476      0.377592      0.047318  \n",
       "..           ...           ...           ...           ...  \n",
       "0       0.313412      0.179261      0.442187      0.048967  \n",
       "0       0.268364      0.230747      0.470925      0.029657  \n",
       "0       0.334659      0.271645      0.484378      0.047824  \n",
       "0       0.368149     -0.010114      0.344275      0.052673  \n",
       "0       0.303007      0.175609      0.357430      0.037011  \n",
       "\n",
       "[996 rows x 31 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_df_all = None\n",
    "\n",
    "for row in embedding_result:\n",
    "    id_ = row[\"id\"]\n",
    "    embedding = row[\"embedding\"]\n",
    "    embedding_cols = [f\"embedding_{i}\" for i in range(embedding.shape[0])]\n",
    "    embedding_df = pd.DataFrame(embedding.reshape(1, -1), columns=embedding_cols)\n",
    "    embedding_df[\"id\"] = id_\n",
    "\n",
    "    if embedding_df_all is None:\n",
    "        embedding_df_all = embedding_df\n",
    "    else:\n",
    "        embedding_df_all = pd.concat([embedding_df_all, embedding_df], axis=0)\n",
    "\n",
    "embedding_df_all = embedding_df_all[[\"id\"] + embedding_cols]\n",
    "embedding_df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "\n",
    "\n",
    "def quadratic_weighted_kappa(y_true, y_pred):\n",
    "    return cohen_kappa_score(y_true, y_pred, weights=\"quadratic\")\n",
    "\n",
    "\n",
    "def threshold_Rounder(oof_non_rounded, thresholds):\n",
    "    return np.where(\n",
    "        oof_non_rounded < thresholds[0],\n",
    "        0,\n",
    "        np.where(\n",
    "            oof_non_rounded < thresholds[1],\n",
    "            1,\n",
    "            np.where(oof_non_rounded < thresholds[2], 2, 3),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "def evaluate_predictions(thresholds, y_true, oof_non_rounded):\n",
    "    rounded_p = threshold_Rounder(oof_non_rounded, thresholds)\n",
    "    return -quadratic_weighted_kappa(y_true, rounded_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train[\"sii\"] != -1].reset_index(drop=True)\n",
    "train = train.merge(embedding_df_all, on=\"id\", how=\"left\")\n",
    "train.fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Folds: 100%|██████████| 4/4 [00:03<00:00,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train QWK --> 0.7556\n",
      "CV: 0.3888\n",
      "tuned Kappa: 0.452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy.optimize import minimize\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator, FormatStrFormatter, PercentFormatter\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from keras.models import Model\n",
    "# from keras.layers import Input, Dense\n",
    "# from keras.optimizers import Adam\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from colorama import Fore, Style\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import (\n",
    "    VotingRegressor,\n",
    "    RandomForestRegressor,\n",
    "    GradientBoostingRegressor,\n",
    ")\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "\n",
    "def quadratic_weighted_kappa(y_true, y_pred):\n",
    "    return cohen_kappa_score(y_true, y_pred, weights=\"quadratic\")\n",
    "\n",
    "\n",
    "def threshold_Rounder(oof_non_rounded, thresholds):\n",
    "    return np.where(\n",
    "        oof_non_rounded < thresholds[0],\n",
    "        0,\n",
    "        np.where(\n",
    "            oof_non_rounded < thresholds[1],\n",
    "            1,\n",
    "            np.where(oof_non_rounded < thresholds[2], 2, 3),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "def evaluate_predictions(thresholds, y_true, oof_non_rounded):\n",
    "    rounded_p = threshold_Rounder(oof_non_rounded, thresholds)\n",
    "    return -quadratic_weighted_kappa(y_true, rounded_p)\n",
    "\n",
    "\n",
    "def TrainML(model_class, test_data):\n",
    "    X = train.drop([\"sii\", \"id\"], axis=1)\n",
    "    y = train[\"sii\"]\n",
    "\n",
    "    n_splits = 4\n",
    "    SKF = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    train_S = []\n",
    "    test_S = []\n",
    "\n",
    "    oof_non_rounded = np.zeros(len(y), dtype=float)\n",
    "    oof_rounded = np.zeros(len(y), dtype=int)\n",
    "    test_preds = np.zeros((len(test_data), n_splits))\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(\n",
    "        tqdm(SKF.split(X, y), desc=\"Training Folds\", total=n_splits)\n",
    "    ):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        model = clone(model_class)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_val_pred = model.predict(X_val)\n",
    "\n",
    "        oof_non_rounded[test_idx] = y_val_pred\n",
    "        y_val_pred_rounded = y_val_pred.round(0).astype(int)\n",
    "        oof_rounded[test_idx] = y_val_pred_rounded\n",
    "\n",
    "        train_kappa = quadratic_weighted_kappa(\n",
    "            y_train, y_train_pred.round(0).astype(int)\n",
    "        )\n",
    "        val_kappa = quadratic_weighted_kappa(y_val, y_val_pred_rounded)\n",
    "\n",
    "        train_S.append(train_kappa)\n",
    "        test_S.append(val_kappa)\n",
    "\n",
    "        # test_preds[:, fold] = model.predict(test_data.drop(columns=[\"id\"]))\n",
    "\n",
    "        print(\n",
    "            f\"Fold {fold+1} - Train QWK: {train_kappa:.4f}, Validation QWK: {val_kappa:.4f}\"\n",
    "        )\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        voting_model = model\n",
    "        # modelの保存\n",
    "        with open(f\"./assets/voting_model_{fold}.pkl\", \"wb\") as f:\n",
    "            pickle.dump(voting_model, f)\n",
    "\n",
    "    print(f\"Mean Train QWK --> {np.mean(train_S):.4f}\")\n",
    "    print(f\"CV: {np.mean(test_S):.4f}\")\n",
    "\n",
    "    KappaOPtimizer = minimize(\n",
    "        evaluate_predictions,\n",
    "        x0=[0.5, 1.5, 2.5],\n",
    "        args=(y, oof_non_rounded),\n",
    "        method=\"Nelder-Mead\",\n",
    "    )\n",
    "    assert KappaOPtimizer.success, \"Optimization did not converge.\"\n",
    "\n",
    "    oof_tuned = threshold_Rounder(oof_non_rounded, KappaOPtimizer.x)\n",
    "    tKappa = quadratic_weighted_kappa(y, oof_tuned)\n",
    "\n",
    "    print(f\"tuned Kappa: {tKappa:.3f}\")\n",
    "\n",
    "    # tpm = test_preds.mean(axis=1)\n",
    "    # tpTuned = threshold_Rounder(tpm, KappaOPtimizer.x)\n",
    "\n",
    "\n",
    "# Model parameters for LightGBM\n",
    "Params = {\n",
    "    \"learning_rate\": 0.046,\n",
    "    \"max_depth\": 12,\n",
    "    \"num_leaves\": 478,\n",
    "    \"min_data_in_leaf\": 13,\n",
    "    \"feature_fraction\": 0.893,\n",
    "    \"bagging_fraction\": 0.784,\n",
    "    \"bagging_freq\": 4,\n",
    "    \"lambda_l1\": 10,  # Increased from 6.59\n",
    "    \"lambda_l2\": 0.01,  # Increased from 2.68e-06\n",
    "}\n",
    "\n",
    "\n",
    "# XGBoost parameters\n",
    "XGB_Params = {\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"max_depth\": 6,\n",
    "    \"n_estimators\": 200,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"reg_alpha\": 1,  # Increased from 0.1\n",
    "    \"reg_lambda\": 5,  # Increased from 1\n",
    "    \"random_state\": SEED,\n",
    "}\n",
    "\n",
    "\n",
    "CatBoost_Params = {\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"depth\": 6,\n",
    "    \"iterations\": 200,\n",
    "    \"random_seed\": SEED,\n",
    "    \"verbose\": 0,\n",
    "    \"l2_leaf_reg\": 10,  # Increase this value\n",
    "}\n",
    "\n",
    "# Create model instances\n",
    "Light = LGBMRegressor(**Params, random_state=SEED, verbose=-1, n_estimators=300)\n",
    "XGB_Model = XGBRegressor(**XGB_Params)\n",
    "CatBoost_Model = CatBoostRegressor(**CatBoost_Params)\n",
    "\n",
    "# Combine models using Voting Regressor\n",
    "voting_model = VotingRegressor(\n",
    "    estimators=[\n",
    "        (\"lightgbm\", Light),\n",
    "        (\"xgboost\", XGB_Model),\n",
    "        (\"catboost\", CatBoost_Model),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Train the ensemble model\n",
    "TrainML(voting_model, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV: 0.3888\n"
     ]
    }
   ],
   "source": [
    "print(\"CV: 0.3888\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned Kappa: 0.452\n"
     ]
    }
   ],
   "source": [
    "print(\"tuned Kappa: 0.452\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
